<div class="mw-content-ltr mw-parser-output" lang="en" dir="ltr"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Additional storage that enables faster access to main storage</div>
<p class="mw-empty-elt">

</p>
<style data-mw-deduplicate="TemplateStyles:r1236090951">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}</style><div role="note" class="hatnote navigation-not-searchable">"Caching" redirects here. For other uses, see <a href="https://en.wikipedia.org/wiki/Cache_(disambiguation)" class="mw-redirect mw-disambig" title="Cache (disambiguation)">Cache (disambiguation)</a>.</div>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Cache,basic.svg" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Cache%2Cbasic.svg/220px-Cache%2Cbasic.svg.png" decoding="async" width="220" height="96" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Cache%2Cbasic.svg/330px-Cache%2Cbasic.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Cache%2Cbasic.svg/440px-Cache%2Cbasic.svg.png 2x" data-file-width="320" data-file-height="140" /></a><figcaption>Diagram of a CPU memory cache operation</figcaption></figure>
<p>In <a href="https://en.wikipedia.org/wiki/Computing" title="Computing">computing</a>, a <b>cache</b> (<span class="rt-commentedText nowrap"><span class="IPA nopopups noexcerpt" lang="en-fonipa"><a href="https://en.wikipedia.org/wiki/Help:IPA/English" title="Help:IPA/English">/<span style="border-bottom:1px dotted"><span title="&#39;k&#39; in &#39;kind&#39;">k</span><span title="/æ/: &#39;a&#39; in &#39;bad&#39;">æ</span><span title="/ʃ/: &#39;sh&#39; in &#39;shy&#39;">ʃ</span></span>/</a></span>&#32;<span class="noprint"><span class="ext-phonos"><span data-nosnippet="" id="ooui-php-1" class="ext-phonos-PhonosButton noexcerpt ext-phonos-PhonosButton-emptylabel oo-ui-widget oo-ui-widget-enabled oo-ui-buttonElement oo-ui-buttonElement-frameless oo-ui-iconElement oo-ui-buttonWidget" data-ooui="{&quot;_&quot;:&quot;mw.Phonos.PhonosButton&quot;,&quot;href&quot;:&quot;\/\/upload.wikimedia.org\/wikipedia\/commons\/transcoded\/7\/71\/LL-Q1860_%28eng%29-Back_ache-cache.wav\/LL-Q1860_%28eng%29-Back_ache-cache.wav.mp3&quot;,&quot;rel&quot;:[&quot;nofollow&quot;],&quot;framed&quot;:false,&quot;icon&quot;:&quot;volumeUp&quot;,&quot;data&quot;:{&quot;ipa&quot;:&quot;&quot;,&quot;text&quot;:&quot;&quot;,&quot;lang&quot;:&quot;en&quot;,&quot;wikibase&quot;:&quot;&quot;,&quot;file&quot;:&quot;LL-Q1860 (eng)-Back ache-cache.wav&quot;},&quot;classes&quot;:[&quot;ext-phonos-PhonosButton&quot;,&quot;noexcerpt&quot;,&quot;ext-phonos-PhonosButton-emptylabel&quot;]}"><a role="button" tabindex="0" href="https://upload.wikimedia.org/wikipedia/commons/transcoded/7/71/LL-Q1860_%28eng%29-Back_ache-cache.wav/LL-Q1860_%28eng%29-Back_ache-cache.wav.mp3" rel="nofollow" aria-label="Play audio" title="Play audio" class="oo-ui-buttonElement-button"><span class="oo-ui-iconElement-icon oo-ui-icon-volumeUp"></span><span class="oo-ui-labelElement-label"></span><span class="oo-ui-indicatorElement-indicator oo-ui-indicatorElement-noIndicator"></span></a></span><sup class="ext-phonos-attribution noexcerpt navigation-not-searchable"><a href="https://en.wikipedia.org/wiki/File:LL-Q1860_(eng)-Back_ache-cache.wav" title="File:LL-Q1860 (eng)-Back ache-cache.wav">ⓘ</a></sup></span></span></span> <a href="https://en.wikipedia.org/wiki/Help:Pronunciation_respelling_key" title="Help:Pronunciation respelling key"><i title="English pronunciation respelling"><span style="font-size:90%">KASH</span></i></a>)<sup id="cite_ref-1" class="reference"><a href="#cite_note-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup> is a hardware or software component that stores data so that future requests for that data can be served faster; the data stored in a cache might be the result of an earlier computation or a copy of data stored elsewhere. A <b>cache hit</b> occurs when the requested data can be found in a cache, while a <b>cache miss</b> occurs when it cannot. Cache hits are served by reading data from the cache, which is faster than recomputing a result or reading from a slower data store; thus, the more requests that can be served from the cache, the faster the system performs.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2"><span class="cite-bracket">&#91;</span>2<span class="cite-bracket">&#93;</span></a></sup>
</p><p>To be cost-effective, caches must be relatively small. Nevertheless, caches are effective in many areas of computing because typical <a href="https://en.wikipedia.org/wiki/Application_software" title="Application software">computer applications</a> access data with a high degree of <a href="https://en.wikipedia.org/wiki/Locality_of_reference" title="Locality of reference">locality of reference</a>. Such access patterns exhibit temporal locality, where data is requested that has been recently requested, and spatial locality, where data is requested that is stored near data that has already been requested.
</p>
<meta property="mw:PageProp/toc" />
<div class="mw-heading mw-heading2"><h2 id="Motivation">Motivation</h2></span></div>
<p>In memory design, there is an inherent trade-off between capacity and speed because larger capacity implies larger size and thus greater physical distances for signals to travel causing <a href="https://en.wikipedia.org/wiki/Propagation_delay" title="Propagation delay">propagation delays</a>. There is also a tradeoff between high-performance technologies such as <a href="https://en.wikipedia.org/wiki/Static_random-access_memory" title="Static random-access memory">SRAM</a> and cheaper, easily mass-produced commodities such as <a href="https://en.wikipedia.org/wiki/DRAM" class="mw-redirect" title="DRAM">DRAM</a>, <a href="https://en.wikipedia.org/wiki/Flash_memory" title="Flash memory">flash</a>, or <a href="https://en.wikipedia.org/wiki/Hard_disk" class="mw-redirect" title="Hard disk">hard disks</a>.
</p><p>The <a href="https://en.wikipedia.org/wiki/Data_buffer" title="Data buffer">buffering</a> provided by a cache benefits one or both of <a href="https://en.wikipedia.org/wiki/Latency_(engineering)" title="Latency (engineering)">latency</a> and <a href="https://en.wikipedia.org/wiki/Throughput" class="mw-redirect" title="Throughput">throughput</a> (<a href="https://en.wikipedia.org/wiki/Bandwidth_(computing)" title="Bandwidth (computing)">bandwidth</a>).
</p><p>A larger resource incurs a significant latency for access – e.g. it can take hundreds of clock cycles for a modern 4&#160;GHz processor to reach DRAM. This is mitigated by reading large chunks into the cache, in the hope that subsequent reads will be from nearby locations and can be read from the cache. Prediction or explicit <a href="https://en.wikipedia.org/wiki/Cache_prefetching" title="Cache prefetching">prefetching</a> can be used to guess where future reads will come from and make requests ahead of time; if done optimally, the latency is bypassed altogether.
</p><p>The use of a cache also allows for higher throughput from the underlying resource, by assembling multiple fine-grain transfers into larger, more efficient requests. In the case of DRAM circuits, the additional throughput may be gained by using a wider data bus.
</p>
<div class="mw-heading mw-heading2"><h2 id="Operation"><span class="anchor" id="CACHE-HIT"></span><span class="anchor" id="CACHE-MISS"></span>Operation</h2></span></div>
<p>Hardware implements cache as a <a href="https://en.wikipedia.org/wiki/Block_(data_storage)" title="Block (data storage)">block</a> of memory for temporary storage of data likely to be used again. <a href="https://en.wikipedia.org/wiki/Central_processing_unit" title="Central processing unit">Central processing units</a> (CPUs), <a href="https://en.wikipedia.org/wiki/Solid-state_drive" title="Solid-state drive">solid-state drives</a> (SSDs) and hard disk drives (HDDs) frequently include hardware-based cache, while <a href="https://en.wikipedia.org/wiki/Web_browser" title="Web browser">web browsers</a> and <a href="https://en.wikipedia.org/wiki/Web_server" title="Web server">web servers</a> commonly rely on software caching.
</p><p>A cache is made up of a pool of entries. Each entry has associated <i>data</i>, which is a copy of the same data in some <i>backing store</i>. Each entry also has a <i>tag</i>, which specifies the identity of the data in the backing store of which the entry is a copy.
</p><p>When the cache client (a CPU, web browser, <a href="https://en.wikipedia.org/wiki/Operating_system" title="Operating system">operating system</a>) needs to access data presumed to exist in the backing store, it first checks the cache. If an entry can be found with a tag matching that of the desired data, the data in the entry is used instead. This situation is known as a <b>cache hit</b>. For example, a web browser program might check its local cache on disk to see if it has a local copy of the contents of a web page at a particular <a href="https://en.wikipedia.org/wiki/URL" title="URL">URL</a>. In this example, the URL is the tag, and the content of the web page is the data. The percentage of accesses that result in cache hits is known as the <b>hit rate</b> or <b>hit ratio</b> of the cache.
</p><p>The alternative situation, when the cache is checked and found not to contain any entry with the desired tag, is known as a <b>cache miss</b>. This requires a more expensive access of data from the backing store. Once the requested data is retrieved, it is typically copied into the cache, ready for the next access.
</p><p>During a cache miss, some other previously existing cache entry is typically removed in order to make room for the newly retrieved data. The <a href="https://en.wikipedia.org/wiki/Heuristic_(computer_science)" title="Heuristic (computer science)">heuristic</a> used to select the entry to replace is known as the <a href="https://en.wikipedia.org/wiki/Cache_replacement_policies" title="Cache replacement policies">replacement policy</a>. One popular replacement policy, least recently used (LRU), replaces the oldest entry, the entry that was accessed less recently than any other entry. More sophisticated caching algorithms also take into account the frequency of use of entries.
</p>
<div class="mw-heading mw-heading3"><h3 id="Writing_policies"><span class="anchor" id="Dirty"></span><span class="anchor" id="WRITEPOLICIES"></span><span class="anchor" id="WRITE-BACK"></span><span class="anchor" id="WRITE-BEHIND"></span><span class="anchor" id="WRITE-THROUGH"></span><span class="anchor" id="WRITE-AROUND"></span>Writing policies</h3></span></div>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Write-through_with_no-write-allocation.svg" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Write-through_with_no-write-allocation.svg/380px-Write-through_with_no-write-allocation.svg.png" decoding="async" width="380" height="512" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Write-through_with_no-write-allocation.svg/570px-Write-through_with_no-write-allocation.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Write-through_with_no-write-allocation.svg/760px-Write-through_with_no-write-allocation.svg.png 2x" data-file-width="460" data-file-height="620" /></a><figcaption>A write-through cache without write allocation</figcaption></figure>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Write-back_with_write-allocation.svg" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Write-back_with_write-allocation.svg/500px-Write-back_with_write-allocation.svg.png" decoding="async" width="500" height="641" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Write-back_with_write-allocation.svg/750px-Write-back_with_write-allocation.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/c/c2/Write-back_with_write-allocation.svg/1000px-Write-back_with_write-allocation.svg.png 2x" data-file-width="640" data-file-height="820" /></a><figcaption>A write-back cache with write allocation</figcaption></figure>
<p>When a system writes data to cache, it must at some point write that data to the backing store as well. The timing of this write is controlled by what is known as the <i>write policy</i>. There are two basic writing approaches:<sup id="cite_ref-3" class="reference"><a href="#cite_note-3"><span class="cite-bracket">&#91;</span>3<span class="cite-bracket">&#93;</span></a></sup>
</p>
<ul><li><i>Write-through</i>: write is done synchronously both to the cache and to the backing store.</li>
<li><i>Write-back</i>: initially, writing is done only to the cache. The write to the backing store is postponed until the modified content is about to be replaced by another cache block.</li></ul>
<p>A write-back cache is more complex to implement since it needs to track which of its locations have been written over and mark them as <i>dirty</i> for later writing to the backing store. The data in these locations are written back to the backing store only when they are evicted from the cache, a process referred to as a <i>lazy write</i>. For this reason, a read miss in a write-back cache will often require two memory backing store accesses to service: one for the write back, and one to retrieve the needed data. Other policies may also trigger data write-back. The client may make many changes to data in the cache, and then explicitly notify the cache to write back the data.
</p><p>Since no data is returned to the requester on write operations, a decision needs to be made whether or not data would be loaded into the cache on write misses.
</p>
<ul><li><i>Write allocate</i> (also called <i>fetch on write</i>): data at the missed-write location is loaded to cache, followed by a write-hit operation. In this approach, write misses are similar to read misses.</li>
<li><i>No-write allocate</i> (also called <i>write-no-allocate</i> or <i>write around</i>): data at the missed-write location is not loaded to cache, and is written directly to the backing store. In this approach, data is loaded into the cache on read misses only.</li></ul>
<p>Both write-through and write-back policies can use either of these write-miss policies, but usually they are paired.<sup id="cite_ref-HennessyPatterson2011_4-0" class="reference"><a href="#cite_note-HennessyPatterson2011-4"><span class="cite-bracket">&#91;</span>4<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-5" class="reference"><a href="#cite_note-5"><span class="cite-bracket">&#91;</span>5<span class="cite-bracket">&#93;</span></a></sup>
</p>
<ul><li>A write-back cache uses write allocate, hoping for subsequent writes (or even reads) to the same location, which is now cached.</li>
<li>A write-through cache uses no-write allocate. Here, subsequent writes have no advantage, since they still need to be written directly to the backing store.</li></ul>
<p>Entities other than the cache may change the data in the backing store, in which case the copy in the cache may become out-of-date or <i>stale</i>. Alternatively, when the client updates the data in the cache, copies of those data in other caches will become stale. Communication protocols between the cache managers that keep the data consistent are associated with <a href="https://en.wikipedia.org/wiki/Cache_coherence" title="Cache coherence">cache coherence</a>.
</p>
<div class="mw-heading mw-heading3"><h3 id="Prefetch">Prefetch</h3></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Cache_prefetching" title="Cache prefetching">Cache prefetching</a></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Further information: <a href="https://en.wikipedia.org/wiki/Memory_paging#Page_replacement_techniques" title="Memory paging">Memory paging §&#160;Page replacement techniques</a></div>
<p>On a cache read miss, caches with a <i><a href="https://en.wikipedia.org/wiki/Demand_paging" title="Demand paging">demand paging</a> policy</i> read the minimum amount from the backing store. A typical demand-paging virtual memory implementation reads one page of virtual memory (often 4&#160;KB) from disk into the disk cache in RAM. A typical CPU reads a single L2 cache line of 128&#160;bytes from DRAM into the L2 cache, and a single L1 cache line of 64&#160;bytes from the L2 cache into the L1 cache.
</p><p>Caches with a <a href="https://en.wikipedia.org/wiki/Prefetch_input_queue" title="Prefetch input queue">prefetch input queue</a> or more general <i>anticipatory paging policy</i> go further—they not only read the data requested, but guess that the next chunk or two of data will soon be required, and so prefetch that data into the cache ahead of time. Anticipatory paging is especially helpful when the backing store has a long latency to read the first chunk and much shorter times to sequentially read the next few chunks, such as <a href="https://en.wikipedia.org/wiki/Disk_storage" title="Disk storage">disk storage</a> and DRAM.
</p><p>A few operating systems go further with a <a href="https://en.wikipedia.org/wiki/Loader_(computing)" title="Loader (computing)">loader</a> that always pre-loads the entire executable into RAM. A few caches go even further, not only pre-loading an entire file, but also starting to load other related files that may soon be requested, such as the <a href="https://en.wikipedia.org/wiki/Page_cache" title="Page cache">page cache</a> associated with a <a href="https://en.wikipedia.org/wiki/Prefetcher" title="Prefetcher">prefetcher</a> or the <a href="https://en.wikipedia.org/wiki/Web_cache" title="Web cache">web cache</a> associated with <a href="https://en.wikipedia.org/wiki/Link_prefetching" title="Link prefetching">link prefetching</a>.
</p>
<div class="mw-heading mw-heading2"><h2 id="Examples_of_hardware_caches"><span class="anchor" id="HARDWARE"></span>Examples of hardware caches</h2></span></div>
<div class="mw-heading mw-heading3"><h3 id="CPU_cache">CPU cache</h3></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/CPU_cache" title="CPU cache">CPU cache</a></div>
<p>Small memories on or close to the CPU can operate faster than the much larger <a href="https://en.wikipedia.org/wiki/Main_memory" class="mw-redirect" title="Main memory">main memory</a>.<sup id="cite_ref-6" class="reference"><a href="#cite_note-6"><span class="cite-bracket">&#91;</span>6<span class="cite-bracket">&#93;</span></a></sup> Most CPUs since the 1980s have used one or more caches, sometimes <a href="https://en.wikipedia.org/wiki/CPU_cache#Multi-level_caches" title="CPU cache">in cascaded levels</a>; modern high-end <a href="https://en.wikipedia.org/wiki/Embedded_computing" class="mw-redirect" title="Embedded computing">embedded</a>, <a href="https://en.wikipedia.org/wiki/Desktop_computer" title="Desktop computer">desktop</a> and server <a href="https://en.wikipedia.org/wiki/Microprocessor" title="Microprocessor">microprocessors</a> may have as many as six types of cache (between levels and functions).<sup id="cite_ref-7" class="reference"><a href="#cite_note-7"><span class="cite-bracket">&#91;</span>7<span class="cite-bracket">&#93;</span></a></sup> Some examples of caches with a specific function are the <a href="https://en.wikipedia.org/wiki/D-cache" class="mw-redirect" title="D-cache">D-cache</a>, <a href="https://en.wikipedia.org/wiki/I-cache" class="mw-redirect" title="I-cache">I-cache</a> and the <a href="https://en.wikipedia.org/wiki/Translation_lookaside_buffer" title="Translation lookaside buffer">translation lookaside buffer</a> for the <a href="https://en.wikipedia.org/wiki/Memory_management_unit" title="Memory management unit">memory management unit</a> (MMU).
</p>
<div class="mw-heading mw-heading3"><h3 id="GPU_cache"><span class="anchor" id="GPU"></span>GPU cache</h3></span></div>
<p>Earlier <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit" title="Graphics processing unit">graphics processing units</a> (GPUs) often had limited read-only <a href="https://en.wikipedia.org/wiki/Texture_cache" class="mw-redirect" title="Texture cache">texture caches</a> and used <a href="https://en.wikipedia.org/wiki/Swizzling_(computer_graphics)" title="Swizzling (computer graphics)">swizzling</a> to improve 2D <a href="https://en.wikipedia.org/wiki/Locality_of_reference" title="Locality of reference">locality of reference</a>. <a href="https://en.wikipedia.org/wiki/Cache_miss" class="mw-redirect" title="Cache miss">Cache misses</a> would drastically affect performance, e.g. if <a href="https://en.wikipedia.org/wiki/Mipmapping" class="mw-redirect" title="Mipmapping">mipmapping</a> was not used. Caching was important to leverage 32-bit (and wider) transfers for texture data that was often as little as 4 bits per pixel.
</p><p>As GPUs advanced, supporting <a href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units" title="General-purpose computing on graphics processing units">general-purpose computing on graphics processing units</a> and <a href="https://en.wikipedia.org/wiki/Compute_kernel" title="Compute kernel">compute kernels</a>, they have developed progressively larger and increasingly general caches, including <a href="https://en.wikipedia.org/wiki/Instruction_cache" class="mw-redirect" title="Instruction cache">instruction caches</a> for <a href="https://en.wikipedia.org/wiki/Shader" title="Shader">shaders</a>, exhibiting functionality commonly found in CPU caches. These caches have grown to handle <a href="https://en.wikipedia.org/wiki/Synchronization_primitive" class="mw-redirect" title="Synchronization primitive">synchronization primitives</a> between threads and <a href="https://en.wikipedia.org/wiki/Atomic_operation" class="mw-redirect" title="Atomic operation">atomic operations</a>, and interface with a CPU-style MMU.
</p>
<div class="mw-heading mw-heading3"><h3 id="DSPs">DSPs</h3></span></div>
<p><a href="https://en.wikipedia.org/wiki/Digital_signal_processor" title="Digital signal processor">Digital signal processors</a> have similarly generalized over the years. Earlier designs used <a href="https://en.wikipedia.org/wiki/Scratchpad_memory" title="Scratchpad memory">scratchpad memory</a> fed by <a href="https://en.wikipedia.org/wiki/Direct_memory_access" title="Direct memory access">direct memory access</a>, but modern DSPs such as <a href="https://en.wikipedia.org/wiki/Qualcomm_Hexagon" title="Qualcomm Hexagon">Qualcomm Hexagon</a> often include a very similar set of caches to a CPU (e.g. <a href="https://en.wikipedia.org/wiki/Modified_Harvard_architecture" title="Modified Harvard architecture">Modified Harvard architecture</a> with shared L2, split L1 I-cache and D-cache).<sup id="cite_ref-8" class="reference"><a href="#cite_note-8"><span class="cite-bracket">&#91;</span>8<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Translation_lookaside_buffer">Translation lookaside buffer</h3></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Translation_lookaside_buffer" title="Translation lookaside buffer">Translation lookaside buffer</a></div>
<p>A memory management unit (MMU) that fetches page table entries from main memory has a specialized cache, used for recording the results of <a href="https://en.wikipedia.org/wiki/Virtual_address" class="mw-redirect" title="Virtual address">virtual address</a> to <a href="https://en.wikipedia.org/wiki/Physical_address" title="Physical address">physical address</a> translations. This specialized cache is called a translation lookaside buffer (TLB).<sup id="cite_ref-9" class="reference"><a href="#cite_note-9"><span class="cite-bracket">&#91;</span>9<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="In-network_cache">In-network cache</h2></span></div>
<div class="mw-heading mw-heading3"><h3 id="Information-centric_networking">Information-centric networking</h3></span></div>
<p><a href="https://en.wikipedia.org/wiki/Information-centric_networking" title="Information-centric networking">Information-centric networking</a> (ICN) is an approach to evolve the <a href="https://en.wikipedia.org/wiki/Internet" title="Internet">Internet</a> infrastructure away from a host-centric paradigm, based on perpetual connectivity and the <a href="https://en.wikipedia.org/wiki/End-to-end_principle" title="End-to-end principle">end-to-end principle</a>, to a network architecture in which the focal point is identified information. Due to the inherent caching capability of the nodes in an ICN, it can be viewed as a loosely connected network of caches, which has unique requirements for caching policies. However, ubiquitous content caching introduces the challenge to content protection against unauthorized access, which requires extra care and solutions.<sup id="cite_ref-10" class="reference"><a href="#cite_note-10"><span class="cite-bracket">&#91;</span>10<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Unlike proxy servers, in ICN the cache is a network-level solution. Therefore, it has rapidly changing cache states and higher request arrival rates; moreover, smaller cache sizes impose different requirements on the content eviction policies. In particular, eviction policies for ICN should be fast and lightweight. Various cache replication and eviction schemes for different ICN architectures and applications have been proposed.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (August 2024)">citation needed</span></a></i>&#93;</sup>
</p>
<div class="mw-heading mw-heading4"><h4 id="Policies">Policies</h4></span></div>
<div class="mw-heading mw-heading5"><h5 id="Time_aware_least_recently_used_(TLRU)"><span id="Time_aware_least_recently_used_.28TLRU.29"></span>Time aware least recently used (TLRU)</h5></span></div>
<p>The Time aware Least Recently Used (TLRU)<sup id="cite_ref-11" class="reference"><a href="#cite_note-11"><span class="cite-bracket">&#91;</span>11<span class="cite-bracket">&#93;</span></a></sup> is a variant of LRU designed for the situation where the stored contents in cache have a valid life time. The algorithm is suitable in network cache applications, such as ICN, <a href="https://en.wikipedia.org/wiki/Content_delivery_network" title="Content delivery network">content delivery networks</a> (CDNs) and distributed networks in general. TLRU introduces a new term: TTU (Time to Use). TTU is a time stamp of a content/page which stipulates the usability time for the content based on the locality of the content and the content publisher announcement. Owing to this locality based time stamp, TTU provides more control to the local administrator to regulate in network storage.
</p><p>In the TLRU algorithm, when a piece of content arrives, a cache node calculates the local TTU value based on the TTU value assigned by the content publisher. The local TTU value is calculated by using a locally defined function. Once the local TTU value is calculated the replacement of content is performed on a subset of the total content stored in cache node. The TLRU ensures that less popular and small life content should be replaced with the incoming content.
</p>
<div class="mw-heading mw-heading5"><h5 id="Least_frequent_recently_used_(LFRU)"><span id="Least_frequent_recently_used_.28LFRU.29"></span>Least frequent recently used (LFRU)</h5></span></div>
<p>The Least Frequent Recently Used (LFRU)<sup id="cite_ref-12" class="reference"><a href="#cite_note-12"><span class="cite-bracket">&#91;</span>12<span class="cite-bracket">&#93;</span></a></sup> cache replacement scheme combines the benefits of LFU and LRU schemes. LFRU is suitable for 'in network' cache applications, such as ICN, CDNs and distributed networks in general. In LFRU, the cache is divided into two partitions called privileged and unprivileged partitions. The privileged partition can be defined as a protected partition. If content is highly popular, it is pushed into the privileged partition. Replacement of the privileged partition is done as follows: LFRU evicts content from the unprivileged partition, pushes content from privileged partition to unprivileged partition, and finally inserts new content into the privileged partition. In the above procedure the LRU is used for the privileged partition and an approximated LFU (ALFU) scheme is used for the unprivileged partition, hence the abbreviation LFRU. The basic idea is to filter out the locally popular contents with ALFU scheme and push the popular contents to one of the privileged partition.
</p>
<div class="mw-heading mw-heading4"><h4 id="Weather_forecast">Weather forecast</h4></span></div>
<p>In 2011, the use of smartphones with weather forecasting options was overly taxing <a href="https://en.wikipedia.org/wiki/AccuWeather" title="AccuWeather">AccuWeather</a> servers; two requests within the same park would generate separate requests. An optimization by edge-servers to truncate the GPS coordinates to fewer decimal places meant that the cached results from the earlier query would be used. The number of to-the-server lookups per day dropped by half.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13"><span class="cite-bracket">&#91;</span>13<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="Software_caches">Software caches</h2></span></div>
<div class="mw-heading mw-heading3"><h3 id="Disk_cache">Disk cache</h3></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Page_cache" title="Page cache">Page cache</a></div>
<p>While CPU caches are generally managed entirely by hardware, a variety of software manages other caches. The <a href="https://en.wikipedia.org/wiki/Page_cache" title="Page cache">page cache</a> in main memory, which is an example of disk cache, is managed by the operating system <a href="https://en.wikipedia.org/wiki/Kernel_(operating_system)" title="Kernel (operating system)">kernel</a>.
</p><p>While the <a href="https://en.wikipedia.org/wiki/Disk_buffer" title="Disk buffer">disk buffer</a>, which is an integrated part of the hard disk drive or solid state drive, is sometimes misleadingly referred to as "disk cache", its main functions are write sequencing and read prefetching. Repeated cache hits are relatively rare, due to the small size of the buffer in comparison to the drive's capacity. However, high-end <a href="https://en.wikipedia.org/wiki/Disk_controller" title="Disk controller">disk controllers</a> often have their own on-board cache of the hard disk drive's data blocks.
</p><p>Finally, a fast local hard disk drive can also cache information held on even slower data storage devices, such as remote servers (web cache) or local <a href="https://en.wikipedia.org/wiki/Tape_drive" title="Tape drive">tape drives</a> or <a href="https://en.wikipedia.org/wiki/Optical_jukebox" title="Optical jukebox">optical jukeboxes</a>; such a scheme is the main concept of <a href="https://en.wikipedia.org/wiki/Hierarchical_storage_management" title="Hierarchical storage management">hierarchical storage management</a>. Also, fast flash-based solid-state drives (SSDs) can be used as caches for slower rotational-media hard disk drives, working together as <a href="https://en.wikipedia.org/wiki/Hybrid_drive" title="Hybrid drive">hybrid drives</a> or <a href="https://en.wikipedia.org/wiki/Solid-state_hybrid_drive" class="mw-redirect" title="Solid-state hybrid drive">solid-state hybrid drives</a> (SSHDs).
</p>
<div class="mw-heading mw-heading3"><h3 id="Web_cache">Web cache</h3></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Web_cache" title="Web cache">Web cache</a></div>
<p>Web browsers and <a href="https://en.wikipedia.org/wiki/Proxy_server" title="Proxy server">web proxy servers</a> employ web caches to store previous responses from web servers, such as <a href="https://en.wikipedia.org/wiki/Web_page" title="Web page">web pages</a> and <a href="https://en.wikipedia.org/wiki/Image_file_format" title="Image file format">images</a>. Web caches reduce the amount of information that needs to be transmitted across the network, as information previously stored in the cache can often be re-used. This reduces bandwidth and processing requirements of the web server, and helps to improve <a href="https://en.wikipedia.org/wiki/Responsiveness" title="Responsiveness">responsiveness</a> for users of the web.<sup id="cite_ref-14" class="reference"><a href="#cite_note-14"><span class="cite-bracket">&#91;</span>14<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Web browsers employ a built-in web cache, but some <a href="https://en.wikipedia.org/wiki/Internet_service_provider" title="Internet service provider">Internet service providers</a> (ISPs) or organizations also use a caching proxy server, which is a web cache that is shared among all users of that network.
</p><p>Another form of cache is <a href="https://en.wikipedia.org/wiki/P2P_caching" title="P2P caching">P2P caching</a>, where the files most sought for by <a href="https://en.wikipedia.org/wiki/Peer-to-peer" title="Peer-to-peer">peer-to-peer</a> applications are stored in an ISP cache to accelerate P2P transfers. Similarly, decentralised equivalents exist, which allow communities to perform the same task for P2P traffic, for example, Corelli.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15"><span class="cite-bracket">&#91;</span>15<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Memoization">Memoization</h3></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Memoization" title="Memoization">Memoization</a></div>
<p>A cache can store data that is computed on demand rather than retrieved from a backing store. <a href="https://en.wikipedia.org/wiki/Memoization" title="Memoization">Memoization</a> is an <a href="https://en.wikipedia.org/wiki/Program_optimization" title="Program optimization">optimization</a> technique that stores the results of resource-consuming <a href="https://en.wikipedia.org/wiki/Function_call" class="mw-redirect" title="Function call">function calls</a> within a lookup table, allowing subsequent calls to reuse the stored results and avoid repeated computation. It is related to the <a href="https://en.wikipedia.org/wiki/Dynamic_programming" title="Dynamic programming">dynamic programming</a> algorithm design methodology, which can also be thought of as a means of caching.
</p>
<div class="mw-heading mw-heading3"><h3 id="Content_delivery_network">Content delivery network</h3></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Content_delivery_network" title="Content delivery network">Content delivery network</a></div>
<p>A content delivery network (CDN) is a network of distributed servers that deliver pages and other Web content to a user, based on the geographic locations of the user, the origin of the web page and the content delivery server.
</p><p>CDNs began in the late 1990s as a way to speed up the delivery of static content, such as HTML pages, images and videos. By replicating content on multiple servers around the world and delivering it to users based on their location, CDNs can significantly improve the speed and availability of a website or application. When a user requests a piece of content, the CDN will check to see if it has a copy of the content in its cache. If it does, the CDN will deliver the content to the user from the cache.<sup id="cite_ref-:0_16-0" class="reference"><a href="#cite_note-:0-16"><span class="cite-bracket">&#91;</span>16<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Cloud_storage_gateway">Cloud storage gateway</h3></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/Cloud_storage_gateway" title="Cloud storage gateway">Cloud storage gateway</a></div>
<p>A cloud storage gateway, also known as an edge filer, is a <a href="https://en.wikipedia.org/wiki/Hybrid_cloud_storage" title="Hybrid cloud storage">hybrid cloud storage</a> device that connects a local network to one or more <a href="https://en.wikipedia.org/wiki/Cloud_storage_service" class="mw-redirect" title="Cloud storage service">cloud storage services</a>, typically <a href="https://en.wikipedia.org/wiki/Object_storage" title="Object storage">object storage</a> services such as <a href="https://en.wikipedia.org/wiki/Amazon_S3" title="Amazon S3">Amazon S3</a>. It provides a cache for frequently accessed data, providing high speed local access to frequently accessed data in the cloud storage service. Cloud storage gateways also provide additional benefits such as accessing cloud object storage through traditional file serving protocols as well as continued access to cached data during connectivity outages.<sup id="cite_ref-searchstorage1_17-0" class="reference"><a href="#cite_note-searchstorage1-17"><span class="cite-bracket">&#91;</span>17<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Other_caches">Other caches</h3></span></div>
<p>The BIND <a href="https://en.wikipedia.org/wiki/Domain_Name_System" title="Domain Name System">DNS</a> daemon caches a mapping of domain names to <a href="https://en.wikipedia.org/wiki/IP_address" title="IP address">IP addresses</a>, as does a resolver library.
</p><p>Write-through operation is common when operating over unreliable networks (like an Ethernet LAN), because of the enormous complexity of the coherency protocol required between multiple write-back caches when communication is unreliable. For instance, web page caches and <a href="https://en.wikipedia.org/wiki/Client-side" class="mw-redirect" title="Client-side">client-side</a> <a href="https://en.wikipedia.org/wiki/Network_File_System" title="Network File System">network file system</a> caches (like those in <a href="https://en.wikipedia.org/wiki/Network_File_System_(protocol)" class="mw-redirect" title="Network File System (protocol)">NFS</a> or <a href="https://en.wikipedia.org/wiki/Server_Message_Block" title="Server Message Block">SMB</a>) are typically read-only or write-through specifically to keep the network protocol simple and reliable.
</p><p><a href="https://en.wikipedia.org/wiki/Web_search_engine" class="mw-redirect" title="Web search engine">Search engines</a> also frequently make web pages they have indexed available from their cache. For example, <a href="https://en.wikipedia.org/wiki/Google" title="Google">Google</a> provides a "Cached" link next to each search result. This can prove useful when web pages from a web server are temporarily or permanently inaccessible.
</p><p><a href="https://en.wikipedia.org/wiki/Database_caching" title="Database caching">Database caching</a> can substantially improve the throughput of <a href="https://en.wikipedia.org/wiki/Database" title="Database">database</a> applications, for example in the processing of <a href="https://en.wikipedia.org/wiki/Database_index" title="Database index">indexes</a>, <a href="https://en.wikipedia.org/wiki/Data_dictionary" title="Data dictionary">data dictionaries</a>, and frequently used subsets of data.
</p><p>A <a href="https://en.wikipedia.org/wiki/Distributed_cache" title="Distributed cache">distributed cache</a><sup id="cite_ref-18" class="reference"><a href="#cite_note-18"><span class="cite-bracket">&#91;</span>18<span class="cite-bracket">&#93;</span></a></sup> uses networked hosts to provide scalability, reliability and performance to the application.<sup id="cite_ref-19" class="reference"><a href="#cite_note-19"><span class="cite-bracket">&#91;</span>19<span class="cite-bracket">&#93;</span></a></sup> The hosts can be co-located or spread over different geographical regions.
</p>
<div class="mw-heading mw-heading2"><h2 id="Buffer_vs._cache"><span class="anchor" id="The_difference_between_buffer_and_cache"></span>Buffer vs. cache</h2></span></div>
<style data-mw-deduplicate="TemplateStyles:r1236091366">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}@media print{body.ns-0 .mw-parser-output .ambox{display:none!important}}</style><table class="box-More_citations_needed_section plainlinks metadata ambox ambox-content ambox-Refimprove" role="presentation"><tbody><tr><td class="mbox-image"><div class="mbox-image-div"><span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Question_book-new.svg" class="mw-file-description"><img alt="" src="https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/50px-Question_book-new.svg.png" decoding="async" width="50" height="39" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/75px-Question_book-new.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/9/99/Question_book-new.svg/100px-Question_book-new.svg.png 2x" data-file-width="512" data-file-height="399" /></a></span></div></td><td class="mbox-text"><div class="mbox-text-span">This section <b>needs additional citations for <a href="https://en.wikipedia.org/wiki/Wikipedia:Verifiability" title="Wikipedia:Verifiability">verification</a></b>.<span class="hide-when-compact"> Please help <a href="https://en.wikipedia.org/wiki/Special:EditPage/Cache_(computing)" title="Special:EditPage/Cache (computing)">improve this article</a> by <a href="https://en.wikipedia.org/wiki/Help:Referencing_for_beginners" title="Help:Referencing for beginners">adding citations to reliable sources</a>&#32;in this section. Unsourced material may be challenged and removed.</span>  <span class="date-container"><i>(<span class="date">June 2021</span>)</i></span><span class="hide-when-compact"><i> (<small><a href="https://en.wikipedia.org/wiki/Help:Maintenance_template_removal" title="Help:Maintenance template removal">Learn how and when to remove this message</a></small>)</i></span></div></td></tr></tbody></table>
<p>The semantics of a "buffer" and a "cache" are not totally different; even so, there are fundamental differences in intent between the process of caching and the process of buffering.
</p><p>Fundamentally, caching realizes a performance increase for transfers of data that is being repeatedly transferred. While a caching system may realize a performance increase upon the initial (typically write) transfer of a data item, this performance increase is due to buffering occurring within the caching system.
</p><p>With read caches, a data item must have been fetched from its residing location at least once in order for subsequent reads of the data item to realize a performance increase by virtue of being able to be fetched from the cache's (faster) intermediate storage rather than the data's residing location. With write caches, a performance increase of writing a data item may be realized upon the first write of the data item by virtue of the data item immediately being stored in the cache's intermediate storage, deferring the transfer of the data item to its residing storage at a later stage or else occurring as a background process. Contrary to strict buffering, a caching process must adhere to a (potentially distributed) cache coherency protocol in order to maintain consistency between the cache's intermediate storage and the location where the data resides. Buffering, on the other hand,
</p>
<ul><li>reduces the number of transfers for otherwise novel data amongst communicating processes, which amortizes overhead involved for several small transfers over fewer, larger transfers,</li>
<li>provides an intermediary for communicating processes which are incapable of direct transfers amongst each other, or</li>
<li>ensures a minimum data size or representation required by at least one of the communicating processes involved in a transfer.</li></ul>
<p>With typical caching implementations, a data item that is read or written for the first time is effectively being buffered; and in the case of a write, mostly realizing a performance increase for the application from where the write originated. Additionally, the portion of a caching protocol where individual writes are deferred to a batch of writes is a form of buffering. The portion of a caching protocol where individual reads are deferred to a batch of reads is also a form of buffering, although this form may negatively impact the performance of at least the initial reads (even though it may positively impact the performance of the sum of the individual reads). In practice, caching almost always involves some form of buffering, while strict buffering does not involve caching.
</p><p>A buffer is a temporary memory location that is traditionally used because CPU <a href="https://en.wikipedia.org/wiki/Instruction_(computing)" class="mw-redirect" title="Instruction (computing)">instructions</a> cannot directly address data stored in peripheral devices. Thus, addressable memory is used as an intermediate stage. Additionally, such a buffer may be feasible when a large block of data is assembled or disassembled (as required by a storage device), or when data may be delivered in a different order than that in which it is produced. Also, a whole buffer of data is usually transferred sequentially (for example to hard disk), so buffering itself sometimes increases transfer performance or reduces the variation or jitter of the transfer's latency as opposed to caching where the intent is to reduce the latency. These benefits are present even if the buffered data are written to the buffer once and read from the buffer once.
</p><p>A cache also increases transfer performance. A part of the increase similarly comes from the possibility that multiple small transfers will combine into one large block. But the main performance-gain occurs because there is a good chance that the same data will be read from cache multiple times, or that written data will soon be read. A cache's sole purpose is to reduce accesses to the underlying slower storage. Cache is also usually an <a href="https://en.wikipedia.org/wiki/Abstraction_layer" title="Abstraction layer">abstraction layer</a> that is designed to be invisible from the perspective of neighboring layers.
</p>
<div class="mw-heading mw-heading2"><h2 id="See_also">See also</h2></span></div>
<style data-mw-deduplicate="TemplateStyles:r1184024115">.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}</style><div class="div-col" style="column-width: 25em;">
<ul><li><a href="https://en.wikipedia.org/wiki/Cache_coloring" title="Cache coloring">Cache coloring</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cache_hierarchy" title="Cache hierarchy">Cache hierarchy</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cache-oblivious_algorithm" title="Cache-oblivious algorithm">Cache-oblivious algorithm</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cache_stampede" title="Cache stampede">Cache stampede</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cache_language_model" title="Cache language model">Cache language model</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cache_manifest_in_HTML5" title="Cache manifest in HTML5">Cache manifest in HTML5</a></li>
<li><a href="https://en.wikipedia.org/wiki/Dirty_bit" title="Dirty bit">Dirty bit</a></li>
<li><a href="https://en.wikipedia.org/wiki/Five-minute_rule" title="Five-minute rule">Five-minute rule</a></li>
<li><a href="https://en.wikipedia.org/wiki/Materialized_view" title="Materialized view">Materialized view</a></li>
<li><a href="https://en.wikipedia.org/wiki/Memory_hierarchy" title="Memory hierarchy">Memory hierarchy</a></li>
<li><a href="https://en.wikipedia.org/wiki/Pipeline_burst_cache" title="Pipeline burst cache">Pipeline burst cache</a></li>
<li><a href="https://en.wikipedia.org/wiki/Temporary_file" title="Temporary file">Temporary file</a></li></ul>
</div>
<div class="mw-heading mw-heading2"><h2 id="References">References</h2></span></div>
<style data-mw-deduplicate="TemplateStyles:r1239543626">.mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><div class="reflist">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">
<style data-mw-deduplicate="TemplateStyles:r1238218222">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url("https://upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url("https://upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url("https://upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("https://upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}</style><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20120818122040/http://oxforddictionaries.com/definition/english/cache">"Cache"</a>. <i>Oxford Dictionaries</i>. Archived from <a rel="nofollow" class="external text" href="http://www.oxforddictionaries.com/definition/english/cache">the original</a> on 18 August 2012<span class="reference-accessdate">. Retrieved <span class="nowrap">2 August</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Oxford+Dictionaries&amp;rft.atitle=Cache&amp;rft_id=http%3A%2F%2Fwww.oxforddictionaries.com%2Fdefinition%2Fenglish%2Fcache&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFZhongZhengLiuWang2020" class="citation journal cs1">Zhong, Liang; Zheng, Xueqian; Liu, Yong; Wang, Mengting; Cao, Yang (February 2020). <a rel="nofollow" class="external text" href="https://dx.doi.org/10.23919/jcc.2020.02.018">"Cache hit ratio maximization in device-to-device communications overlaying cellular networks"</a>. <i>China Communications</i>. <b>17</b> (2): 232–238. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.23919%2Fjcc.2020.02.018">10.23919/jcc.2020.02.018</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://search.worldcat.org/issn/1673-5447">1673-5447</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:212649328">212649328</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=China+Communications&amp;rft.atitle=Cache+hit+ratio+maximization+in+device-to-device+communications+overlaying+cellular+networks&amp;rft.volume=17&amp;rft.issue=2&amp;rft.pages=232-238&amp;rft.date=2020-02&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A212649328%23id-name%3DS2CID&amp;rft.issn=1673-5447&amp;rft_id=info%3Adoi%2F10.23919%2Fjcc.2020.02.018&amp;rft.aulast=Zhong&amp;rft.aufirst=Liang&amp;rft.au=Zheng%2C+Xueqian&amp;rft.au=Liu%2C+Yong&amp;rft.au=Wang%2C+Mengting&amp;rft.au=Cao%2C+Yang&amp;rft_id=http%3A%2F%2Fdx.doi.org%2F10.23919%2Fjcc.2020.02.018&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBottomley2004" class="citation web cs1">Bottomley, James (1 January 2004). <a rel="nofollow" class="external text" href="https://www.linuxjournal.com/article/7105">"Understanding Caching"</a>. <i>Linux Journal</i><span class="reference-accessdate">. Retrieved <span class="nowrap">1 October</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Linux+Journal&amp;rft.atitle=Understanding+Caching&amp;rft.date=2004-01-01&amp;rft.aulast=Bottomley&amp;rft.aufirst=James&amp;rft_id=https%3A%2F%2Fwww.linuxjournal.com%2Farticle%2F7105&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-HennessyPatterson2011-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-HennessyPatterson2011_4-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFHennessyPatterson2011" class="citation book cs1">Hennessy, John L.; Patterson, David A. (2011). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=v3-1hVwHnHwC&amp;pg=SL2-PA12"><i>Computer Architecture: A Quantitative Approach</i></a>. Elsevier. p.&#160;B–12. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-12-383872-8" title="Special:BookSources/978-0-12-383872-8"><bdi>978-0-12-383872-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computer+Architecture%3A+A+Quantitative+Approach&amp;rft.pages=B-12&amp;rft.pub=Elsevier&amp;rft.date=2011&amp;rft.isbn=978-0-12-383872-8&amp;rft.aulast=Hennessy&amp;rft.aufirst=John+L.&amp;rft.au=Patterson%2C+David+A.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3Dv3-1hVwHnHwC%26pg%3DSL2-PA12&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFPattersonHennessy1990" class="citation book cs1">Patterson, David A.; Hennessy, John L. (1990). <i>Computer Architecture A Quantitative Approach</i>. Morgan Kaufmann Publishers. p.&#160;413. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/1-55860-069-8" title="Special:BookSources/1-55860-069-8"><bdi>1-55860-069-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computer+Architecture+A+Quantitative+Approach&amp;rft.pages=413&amp;rft.pub=Morgan+Kaufmann+Publishers&amp;rft.date=1990&amp;rft.isbn=1-55860-069-8&amp;rft.aulast=Patterson&amp;rft.aufirst=David+A.&amp;rft.au=Hennessy%2C+John+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSuZeng2021" class="citation journal cs1">Su, Chao; Zeng, Qingkai (10 June 2021). Nicopolitidis, Petros (ed.). <a rel="nofollow" class="external text" href="https://doi.org/10.1155%2F2021%2F5559552">"Survey of CPU Cache-Based Side-Channel Attacks: Systematic Analysis, Security Models, and Countermeasures"</a>. <i>Security and Communication Networks</i>. <b>2021</b>: 1–15. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1155%2F2021%2F5559552">10.1155/2021/5559552</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://search.worldcat.org/issn/1939-0122">1939-0122</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Security+and+Communication+Networks&amp;rft.atitle=Survey+of+CPU+Cache-Based+Side-Channel+Attacks%3A+Systematic+Analysis%2C+Security+Models%2C+and+Countermeasures&amp;rft.volume=2021&amp;rft.pages=1-15&amp;rft.date=2021-06-10&amp;rft_id=info%3Adoi%2F10.1155%2F2021%2F5559552&amp;rft.issn=1939-0122&amp;rft.aulast=Su&amp;rft.aufirst=Chao&amp;rft.au=Zeng%2C+Qingkai&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1155%252F2021%252F5559552&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://wccftech.com/intel-broadwell-core-i7-5775c-128mb-l4-cache-and-skylake-core-i7-6700k-flagship-processors-available-retail/">"Intel Broadwell Core i7 5775C '128MB L4 Cache' Gaming Behemoth and Skylake Core i7 6700K Flagship Processors Finally Available In Retail"</a>. 25 September 2015.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Intel+Broadwell+Core+i7+5775C+%27128MB+L4+Cache%27+Gaming+Behemoth+and+Skylake+Core+i7+6700K+Flagship+Processors+Finally+Available+In+Retail&amp;rft.date=2015-09-25&amp;rft_id=https%3A%2F%2Fwccftech.com%2Fintel-broadwell-core-i7-5775c-128mb-l4-cache-and-skylake-core-i7-6700k-flagship-processors-available-retail%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span> Mentions L4 cache. Combined with separate I-Cache and TLB, this brings the total 'number of caches (levels+functions) to 6.</span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://developer.qualcomm.com/software/hexagon-dsp-sdk/dsp-processor">"qualcom Hexagon DSP SDK overview"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=qualcom+Hexagon+DSP+SDK+overview&amp;rft_id=https%3A%2F%2Fdeveloper.qualcomm.com%2Fsoftware%2Fhexagon-dsp-sdk%2Fdsp-processor&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFFrank_Uyeda2009" class="citation web cs1">Frank Uyeda (2009). <a rel="nofollow" class="external text" href="http://cseweb.ucsd.edu/classes/su09/cse120/lectures/Lecture7.pdf">"Lecture 7: Memory Management"</a> <span class="cs1-format">(PDF)</span>. <i>CSE 120: Principles of Operating Systems</i>. UC San Diego<span class="reference-accessdate">. Retrieved <span class="nowrap">4 December</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=CSE+120%3A+Principles+of+Operating+Systems&amp;rft.atitle=Lecture+7%3A+Memory+Management&amp;rft.date=2009&amp;rft.au=Frank+Uyeda&amp;rft_id=http%3A%2F%2Fcseweb.ucsd.edu%2Fclasses%2Fsu09%2Fcse120%2Flectures%2FLecture7.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBilal,_Muhammad2019" class="citation journal cs1">Bilal, Muhammad; et&#160;al. (2019). "Secure Distribution of Protected Content in Information-Centric Networking". <i>IEEE Systems Journal</i>. <b>14</b> (2): 1–12. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1907.11717">1907.11717</a></span>. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2020ISysJ..14.1921B">2020ISysJ..14.1921B</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FJSYST.2019.2931813">10.1109/JSYST.2019.2931813</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:198967720">198967720</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Systems+Journal&amp;rft.atitle=Secure+Distribution+of+Protected+Content+in+Information-Centric+Networking&amp;rft.volume=14&amp;rft.issue=2&amp;rft.pages=1-12&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1907.11717&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A198967720%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FJSYST.2019.2931813&amp;rft_id=info%3Abibcode%2F2020ISysJ..14.1921B&amp;rft.au=Bilal%2C+Muhammad&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBilalKang2014" class="citation conference cs1">Bilal, Muhammad; Kang, Shin-Gak (2014). <i>Time Aware Least Recent Used (TLRU) cache management policy in ICN</i>. 16th International Conference on Advanced Communication Technology. pp.&#160;528–532. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1801.00390">1801.00390</a></span>. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2018arXiv180100390B">2018arXiv180100390B</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FICACT.2014.6779016">10.1109/ICACT.2014.6779016</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-89-968650-3-2" title="Special:BookSources/978-89-968650-3-2"><bdi>978-89-968650-3-2</bdi></a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:830503">830503</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Time+Aware+Least+Recent+Used+%28TLRU%29+cache+management+policy+in+ICN&amp;rft.pages=528-532&amp;rft.date=2014&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A830503%23id-name%3DS2CID&amp;rft_id=info%3Abibcode%2F2018arXiv180100390B&amp;rft_id=info%3Aarxiv%2F1801.00390&amp;rft_id=info%3Adoi%2F10.1109%2FICACT.2014.6779016&amp;rft.isbn=978-89-968650-3-2&amp;rft.aulast=Bilal&amp;rft.aufirst=Muhammad&amp;rft.au=Kang%2C+Shin-Gak&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBilal,_Muhammad2017" class="citation journal cs1">Bilal, Muhammad; et&#160;al. (2017). "A Cache Management Scheme for Efficient Content Eviction and Replication in Cache Networks". <i>IEEE Access</i>. <b>5</b>: 1692–1701. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1702.04078">1702.04078</a></span>. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2017arXiv170204078B">2017arXiv170204078B</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FACCESS.2017.2669344">10.1109/ACCESS.2017.2669344</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:14517299">14517299</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Access&amp;rft.atitle=A+Cache+Management+Scheme+for+Efficient+Content+Eviction+and+Replication+in+Cache+Networks&amp;rft.volume=5&amp;rft.pages=1692-1701&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1702.04078&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A14517299%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FACCESS.2017.2669344&amp;rft_id=info%3Abibcode%2F2017arXiv170204078B&amp;rft.au=Bilal%2C+Muhammad&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFMurphy2011" class="citation magazine cs1">Murphy, Chris (30 May 2011). "5 Lines Of Code In The Cloud". <i><a href="https://en.wikipedia.org/wiki/InformationWeek" title="InformationWeek">InformationWeek</a></i>. p.&#160;28. <q>300 million to 500 million fewer requests a day handled by AccuWeather servers</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=InformationWeek&amp;rft.atitle=5+Lines+Of+Code+In+The+Cloud&amp;rft.pages=28&amp;rft.date=2011-05-30&amp;rft.aulast=Murphy&amp;rft.aufirst=Chris&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFMultiple_(wiki)" class="citation web cs1">Multiple (wiki). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20191212152625/http://www.docforge.com/wiki/Web_application/Caching">"Web application caching"</a>. <i>Docforge</i>. Archived from <a rel="nofollow" class="external text" href="http://docforge.com/wiki/Web_application/Caching">the original</a> on 12 December 2019<span class="reference-accessdate">. Retrieved <span class="nowrap">24 July</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Docforge&amp;rft.atitle=Web+application+caching&amp;rft.au=Multiple+%28wiki%29&amp;rft_id=http%3A%2F%2Fdocforge.com%2Fwiki%2FWeb_application%2FCaching&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFTysonMautheKauneMu" class="citation conference cs1">Tyson, Gareth; Mauthe, Andreas; Kaune, Sebastian; Mu, Mu; Plagemann, Thomas. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20150618193018/http://comp.eprints.lancs.ac.uk/2044/1/MMCN09.pdf"><i>Corelli: A Dynamic Replication Service for Supporting Latency-Dependent Content in Community Networks</i></a> <span class="cs1-format">(PDF)</span>. MMCN'09. Archived from <a rel="nofollow" class="external text" href="http://comp.eprints.lancs.ac.uk/2044/1/MMCN09.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 18 June 2015.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Corelli%3A+A+Dynamic+Replication+Service+for+Supporting+Latency-Dependent+Content+in+Community+Networks&amp;rft.aulast=Tyson&amp;rft.aufirst=Gareth&amp;rft.au=Mauthe%2C+Andreas&amp;rft.au=Kaune%2C+Sebastian&amp;rft.au=Mu%2C+Mu&amp;rft.au=Plagemann%2C+Thomas&amp;rft_id=http%3A%2F%2Fcomp.eprints.lancs.ac.uk%2F2044%2F1%2FMMCN09.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-:0-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-:0_16-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://people.cs.umass.edu/~ramesh/Site/PUBLICATIONS_files/DMPPSW02.pdf">"Globally Distributed Content Delivery, by J. Dilley, B. Maggs, J. Parikh, H. Prokop, R. Sitaraman and B. Weihl, IEEE Internet Computing, Volume 6, Issue 5, November 2002"</a> <span class="cs1-format">(PDF)</span>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20170809231307/http://people.cs.umass.edu/~ramesh/Site/PUBLICATIONS_files/DMPPSW02.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 9 August 2017<span class="reference-accessdate">. Retrieved <span class="nowrap">25 October</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Globally+Distributed+Content+Delivery%2C+by+J.+Dilley%2C+B.+Maggs%2C+J.+Parikh%2C+H.+Prokop%2C+R.+Sitaraman+and+B.+Weihl%2C+IEEE+Internet+Computing%2C+Volume+6%2C+Issue+5%2C+November+2002.&amp;rft_id=https%3A%2F%2Fpeople.cs.umass.edu%2F~ramesh%2FSite%2FPUBLICATIONS_files%2FDMPPSW02.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-searchstorage1-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-searchstorage1_17-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.techtarget.com/searchstorage/definition/cloud-storage-gateway">"Definition: cloud storage gateway"</a>. <i>SearchStorage</i>. July 2014.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=SearchStorage&amp;rft.atitle=Definition%3A+cloud+storage+gateway&amp;rft.date=2014-07&amp;rft_id=https%3A%2F%2Fwww.techtarget.com%2Fsearchstorage%2Fdefinition%2Fcloud-storage-gateway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFPaulFei2001" class="citation journal cs1">Paul, S.; Fei, Z. (1 February 2001). "Distributed caching with centralized control". <i>Computer Communications</i>. <b>24</b> (2): 256–268. <a href="https://en.wikipedia.org/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.38.1094">10.1.1.38.1094</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2FS0140-3664%2800%2900322-4">10.1016/S0140-3664(00)00322-4</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer+Communications&amp;rft.atitle=Distributed+caching+with+centralized+control&amp;rft.volume=24&amp;rft.issue=2&amp;rft.pages=256-268&amp;rft.date=2001-02-01&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.38.1094%23id-name%3DCiteSeerX&amp;rft_id=info%3Adoi%2F10.1016%2FS0140-3664%2800%2900322-4&amp;rft.aulast=Paul&amp;rft.aufirst=S.&amp;rft.au=Fei%2C+Z.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKhan2009" class="citation journal cs1">Khan, Iqbal (July 2009). <a rel="nofollow" class="external text" href="https://msdn.microsoft.com/magazine/dd942840.aspx">"Distributed Caching on the Path To Scalability"</a>. <i>MSDN</i>. <b>24</b> (7).</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=MSDN&amp;rft.atitle=Distributed+Caching+on+the+Path+To+Scalability&amp;rft.volume=24&amp;rft.issue=7&amp;rft.date=2009-07&amp;rft.aulast=Khan&amp;rft.aufirst=Iqbal&amp;rft_id=https%3A%2F%2Fmsdn.microsoft.com%2Fmagazine%2Fdd942840.aspx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ACache+%28computing%29" class="Z3988"></span></span>
</li>
</ol></div></div>
<div class="mw-heading mw-heading2"><h2 id="Further_reading">Further reading</h2></span></div>
<ul><li><a rel="nofollow" class="external text" href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf">"What Every Programmer Should Know About Memory"</a></li>
<li><a rel="nofollow" class="external text" href="http://msdn.microsoft.com/en-us/library/dd129907.aspx">"Caching in the Distributed Environment"</a></li></ul>
<div class="navbox-styles"><style data-mw-deduplicate="TemplateStyles:r1129693374">.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:": "}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:" · ";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:" (";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:")";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:" "counter(listitem)"\a0 "}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:" ("counter(listitem)"\a0 "}</style><style data-mw-deduplicate="TemplateStyles:r1236075235">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}</style><style data-mw-deduplicate="TemplateStyles:r1038841319">.mw-parser-output .tooltip-dotted{border-bottom:1px dotted;cursor:help}</style></div><div role="navigation" class="navbox authority-control" aria-label="Navbox" style="padding:3px"><table class="nowraplinks hlist navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Help:Authority_control" title="Help:Authority control">Authority control databases</a>: National <span class="mw-valign-text-top noprint" typeof="mw:File/Frameless"><a href="https://www.wikidata.org/wiki/Q165596#identifiers" title="Edit this at Wikidata"><img alt="Edit this at Wikidata" src="https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png" decoding="async" width="10" height="10" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/15px-OOjs_UI_icon_edit-ltr-progressive.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/20px-OOjs_UI_icon_edit-ltr-progressive.svg.png 2x" data-file-width="20" data-file-height="20" /></a></span></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em"><ul><li><span class="uid"><a rel="nofollow" class="external text" href="https://d-nb.info/gnd/4362843-6">Germany</a></span></li><li><span class="uid"><span class="rt-commentedText tooltip tooltip-dotted" title="Cache memory"><a rel="nofollow" class="external text" href="https://id.loc.gov/authorities/sh88007957">United States</a></span></span></li><li><span class="uid"><a rel="nofollow" class="external text" href="http://olduli.nli.org.il/F/?func=find-b&amp;local_base=NLX10&amp;find_code=UID&amp;request=987007541784405171">Israel</a></span></li></ul></div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw‐web.codfw.main‐7746b7987c‐h7hfm
Cached time: 20240916202841
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.505 seconds
Real time usage: 0.782 seconds
Preprocessor visited node count: 2182/1000000
Post‐expand include size: 55984/2097152 bytes
Template argument size: 2293/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 17/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 81469/5000000 bytes
Lua time usage: 0.332/10.000 seconds
Lua memory usage: 6771511/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  650.777      1 -total
 31.84%  207.209      1 Template:Reflist
 18.60%  121.045      8 Template:Cite_web
 16.27%  105.873      1 Template:Authority_control
 16.14%  105.012      1 Template:IPAc-en
 11.57%   75.270      1 Template:Audio
  9.71%   63.195      1 Template:Short_description
  6.27%   40.798      2 Template:Pagetype
  5.85%   38.057      1 Template:Redirect
  5.70%   37.105      1 Template:More_citations_needed_section
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:6829-0!canonical and timestamp 20240916202841 and revision id 1246086343. Rendering was triggered because: page-view
 -->
</div>