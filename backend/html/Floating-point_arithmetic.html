<div class="mw-content-ltr mw-parser-output" lang="en" dir="ltr"><style data-mw-deduplicate="TemplateStyles:r1236090951">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}@media print{body.ns-0 .mw-parser-output .hatnote{display:none!important}}</style><div role="note" class="hatnote navigation-not-searchable">"Floating point" redirects here. For other uses, see <a href="https://en.wikipedia.org/wiki/Floating_point_(disambiguation)" class="mw-disambig" title="Floating point (disambiguation)">Floating point (disambiguation)</a>.</div>
<div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Computer approximation for real numbers</div>
<p class="mw-empty-elt">
</p>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Z3_Deutsches_Museum.JPG" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Z3_Deutsches_Museum.JPG/200px-Z3_Deutsches_Museum.JPG" decoding="async" width="200" height="150" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Z3_Deutsches_Museum.JPG/300px-Z3_Deutsches_Museum.JPG 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Z3_Deutsches_Museum.JPG/400px-Z3_Deutsches_Museum.JPG 2x" data-file-width="1600" data-file-height="1200" /></a><figcaption>An early electromechanical programmable computer, the <a href="https://en.wikipedia.org/wiki/Z3_(computer)" title="Z3 (computer)">Z3</a>, included floating-point arithmetic (replica on display at <a href="https://en.wikipedia.org/wiki/Deutsches_Museum" title="Deutsches Museum">Deutsches Museum</a> in <a href="https://en.wikipedia.org/wiki/Munich" title="Munich">Munich</a>).</figcaption></figure>
<p>In <a href="https://en.wikipedia.org/wiki/Computing" title="Computing">computing</a>, <b>floating-point arithmetic</b> (<b>FP</b>) is <a href="https://en.wikipedia.org/wiki/Arithmetic" title="Arithmetic">arithmetic</a> that represents subsets of <a href="https://en.wikipedia.org/wiki/Real_number" title="Real number">real numbers</a> using an <a href="https://en.wikipedia.org/wiki/Integer_(computer_science)" title="Integer (computer science)">integer</a> with a fixed precision, called the <a href="https://en.wikipedia.org/wiki/Significand" title="Significand">significand</a>, scaled by an integer <a href="https://en.wikipedia.org/wiki/Exponent" class="mw-redirect" title="Exponent">exponent</a> of a fixed base.
Numbers of this form are called <b>floating-point numbers</b>.<sup id="cite_ref-Muller_2010_1-0" class="reference"><a href="#cite_note-Muller_2010-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup><sup class="reference nowrap"><span title="Page / location: 3">&#58;&#8202;3&#8202;</span></sup><sup id="cite_ref-sterbenz1974fpcomp_2-0" class="reference"><a href="#cite_note-sterbenz1974fpcomp-2"><span class="cite-bracket">&#91;</span>2<span class="cite-bracket">&#93;</span></a></sup><sup class="reference nowrap"><span title="Page / location: 10">&#58;&#8202;10&#8202;</span></sup>
For example, 12.345 is a floating-point number in base ten with five digits of precision:
</p><p><span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 12.345=\!\underbrace {12345} _{\text{significand}}\!\times \!\underbrace {10} _{\text{base}}\!\!\!\!\!\!\!\overbrace {{}^{-3}} ^{\text{exponent}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>12.345</mn>
        <mo>=</mo>
        <mspace width="negativethinmathspace" />
        <munder>
          <mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
            <munder>
              <mn>12345</mn>
              <mo>&#x23DF;<!-- ⏟ --></mo>
            </munder>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>significand</mtext>
          </mrow>
        </munder>
        <mspace width="negativethinmathspace" />
        <mo>&#x00D7;<!-- × --></mo>
        <mspace width="negativethinmathspace" />
        <munder>
          <mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
            <munder>
              <mn>10</mn>
              <mo>&#x23DF;<!-- ⏟ --></mo>
            </munder>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>base</mtext>
          </mrow>
        </munder>
        <mspace width="negativethinmathspace" />
        <mspace width="negativethinmathspace" />
        <mspace width="negativethinmathspace" />
        <mspace width="negativethinmathspace" />
        <mspace width="negativethinmathspace" />
        <mspace width="negativethinmathspace" />
        <mspace width="negativethinmathspace" />
        <mover>
          <mrow class="MJX-TeXAtom-OP MJX-fixedlimits">
            <mover>
              <msup>
                <mrow class="MJX-TeXAtom-ORD">

                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mn>3</mn>
                </mrow>
              </msup>
              <mo>&#x23DE;<!-- ⏞ --></mo>
            </mover>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>exponent</mtext>
          </mrow>
        </mover>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 12.345=\!\underbrace {12345} _{\text{significand}}\!\times \!\underbrace {10} _{\text{base}}\!\!\!\!\!\!\!\overbrace {{}^{-3}} ^{\text{exponent}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b6afee7f27ca53770592d822fe8e09f9c62a3015" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -4.171ex; width:26.549ex; height:9.843ex;" alt="{\displaystyle 12.345=\!\underbrace {12345} _{\text{significand}}\!\times \!\underbrace {10} _{\text{base}}\!\!\!\!\!\!\!\overbrace {{}^{-3}} ^{\text{exponent}}}"></span>
</p><p>However, unlike 12.345, 12.3456 is not a floating-point number in base ten with five digits of precision&#8212;it needs six digits of precision; the nearest floating-point number with only five digits is 12.346.
In practice, most floating-point systems use <a href="https://en.wikipedia.org/wiki/Binary_number" title="Binary number">base two</a>, though base ten (<a href="https://en.wikipedia.org/wiki/Decimal_floating_point" title="Decimal floating point">decimal floating point</a>) is also common.
</p><p>Floating-point arithmetic operations, such as addition and division, approximate the corresponding real number arithmetic operations by rounding any result that is not a floating-point number itself to a nearby floating-point number.<sup id="cite_ref-Muller_2010_1-1" class="reference"><a href="#cite_note-Muller_2010-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup><sup class="reference nowrap"><span title="Page / location: 22">&#58;&#8202;22&#8202;</span></sup><sup id="cite_ref-sterbenz1974fpcomp_2-1" class="reference"><a href="#cite_note-sterbenz1974fpcomp-2"><span class="cite-bracket">&#91;</span>2<span class="cite-bracket">&#93;</span></a></sup><sup class="reference nowrap"><span title="Page / location: 10">&#58;&#8202;10&#8202;</span></sup>
For example, in a floating-point arithmetic with five base-ten digits of precision, the sum 12.345 + 1.0001 = 13.3451 might be rounded to 13.345.
</p><p>The term <i>floating point</i> refers to the fact that the number's <a href="https://en.wikipedia.org/wiki/Radix_point" class="mw-redirect" title="Radix point">radix point</a> can "float" anywhere to the left, right, or between the significant digits of the number. This position is indicated by the exponent, so floating point can be considered a form of <a href="https://en.wikipedia.org/wiki/Scientific_notation" title="Scientific notation">scientific notation</a>.
</p><p>A floating-point system can be used to represent, with a fixed number of digits, numbers of very different <a href="https://en.wikipedia.org/wiki/Orders_of_magnitude_(numbers)" title="Orders of magnitude (numbers)">orders of magnitude</a> — such as the number of meters <a href="https://en.wikipedia.org/wiki/Orders_of_magnitude_(length)#100_zettametres" title="Orders of magnitude (length)">between galaxies</a> or <a href="https://en.wikipedia.org/wiki/Orders_of_magnitude_(length)#10_femtometres" title="Orders of magnitude (length)">between protons in an atom</a>.  For this reason, floating-point arithmetic is often used to allow very small and very large real numbers that require fast processing times.  The result of this <a href="https://en.wikipedia.org/wiki/Dynamic_range" title="Dynamic range">dynamic range</a> is that the numbers that can be represented are not uniformly spaced; the difference between two consecutive representable numbers varies with their exponent.<sup id="cite_ref-Smith_1997_3-0" class="reference"><a href="#cite_note-Smith_1997-3"><span class="cite-bracket">&#91;</span>3<span class="cite-bracket">&#93;</span></a></sup>
</p>
<figure class="mw-halign-right" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:A_number_line_representing_single-precision_floating_point%27s_numbers_and_numbers_that_it_cannot_display.png" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/A_number_line_representing_single-precision_floating_point%27s_numbers_and_numbers_that_it_cannot_display.png/500px-A_number_line_representing_single-precision_floating_point%27s_numbers_and_numbers_that_it_cannot_display.png" decoding="async" width="500" height="93" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/A_number_line_representing_single-precision_floating_point%27s_numbers_and_numbers_that_it_cannot_display.png/750px-A_number_line_representing_single-precision_floating_point%27s_numbers_and_numbers_that_it_cannot_display.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/9/98/A_number_line_representing_single-precision_floating_point%27s_numbers_and_numbers_that_it_cannot_display.png/1000px-A_number_line_representing_single-precision_floating_point%27s_numbers_and_numbers_that_it_cannot_display.png 2x" data-file-width="1814" data-file-height="337" /></a><figcaption>Single-precision floating-point numbers on a <a href="https://en.wikipedia.org/wiki/Number_line" title="Number line">number line</a>: the green lines mark representable values.</figcaption></figure>
<figure class="mw-halign-right" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:FloatingPointPrecisionAugmented.png" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/FloatingPointPrecisionAugmented.png/500px-FloatingPointPrecisionAugmented.png" decoding="async" width="500" height="18" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/FloatingPointPrecisionAugmented.png/750px-FloatingPointPrecisionAugmented.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/FloatingPointPrecisionAugmented.png/1000px-FloatingPointPrecisionAugmented.png 2x" data-file-width="2116" data-file-height="78" /></a><figcaption>Augmented version above showing both <a href="https://en.wikipedia.org/wiki/Signed_number_representations" title="Signed number representations">signs</a> of representable values</figcaption></figure>
<p>Over the years, a variety of floating-point representations have been used in computers.  In 1985, the <a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a> Standard for Floating-Point Arithmetic was established, and since the 1990s, the most commonly encountered representations are those defined by the IEEE.
</p><p>The speed of floating-point operations, commonly measured in terms of <a href="https://en.wikipedia.org/wiki/FLOPS" title="FLOPS">FLOPS</a>, is an important characteristic of a <a href="https://en.wikipedia.org/wiki/Computer_system" class="mw-redirect" title="Computer system">computer system</a>, especially for applications that involve intensive mathematical calculations.
</p><p>A <a href="https://en.wikipedia.org/wiki/Floating-point_unit" title="Floating-point unit">floating-point unit</a> (FPU, colloquially a math <a href="https://en.wikipedia.org/wiki/Coprocessor" title="Coprocessor">coprocessor</a>) is a part of a computer system specially designed to carry out operations on floating-point numbers.
</p>
<meta property="mw:PageProp/toc" />
<div class="mw-heading mw-heading2"><h2 id="Overview">Overview</h2></span></div>
<div class="mw-heading mw-heading3"><h3 id="Floating-point_numbers">Floating-point numbers</h3></span></div>
<p>A <a href="https://en.wikipedia.org/wiki/Number_representation" class="mw-redirect" title="Number representation">number representation</a> specifies some way of encoding a number, usually as a string of digits.
</p><p>There are several mechanisms by which strings of digits can represent numbers. In standard mathematical notation, the digit string can be of any length, and the location of the <a href="https://en.wikipedia.org/wiki/Radix_point" class="mw-redirect" title="Radix point">radix point</a> is indicated by placing an explicit <a href="https://en.wikipedia.org/wiki/Decimal_separator" title="Decimal separator">"point" character</a> (dot or comma) there. If the radix point is not specified, then the string implicitly represents an <a href="https://en.wikipedia.org/wiki/Integer" title="Integer">integer</a> and the unstated radix point would be off the right-hand end of the string, next to the least significant digit. In <a href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic" title="Fixed-point arithmetic">fixed-point</a> systems, a position in the string is specified for the radix point. So a fixed-point scheme might use a string of 8 decimal digits with the decimal point in the middle, whereby "00012345" would represent 0001.2345.
</p><p>In <a href="https://en.wikipedia.org/wiki/Scientific_notation" title="Scientific notation">scientific notation</a>, the given number is scaled by a <a href="https://en.wikipedia.org/wiki/Exponentiation" title="Exponentiation">power of 10</a>, so that it lies within a specific range—typically between 1 and 10, with the radix point appearing immediately after the first digit.  As a power of ten, the scaling factor is then indicated separately at the end of the number.  For example, the orbital period of <a href="https://en.wikipedia.org/wiki/Jupiter" title="Jupiter">Jupiter</a>'s moon <a href="https://en.wikipedia.org/wiki/Io_(moon)" title="Io (moon)">Io</a> is <span class="nowrap"><span data-sort-value="7005152853504700000♠"></span>152,853.5047</span> seconds, a value that would be represented in standard-form scientific notation as <span class="nowrap"><span data-sort-value="7005152853504700000♠"></span>1.528535047<span style="margin-left:0.25em;margin-right:0.15em;">×</span>10<sup>5</sup></span> seconds.
</p><p>Floating-point representation is similar in concept to scientific notation. Logically, a floating-point number consists of:
</p>
<ul><li>A signed (meaning positive or negative) digit string of a given length in a given <a href="https://en.wikipedia.org/wiki/Base_(exponentiation)" title="Base (exponentiation)">base</a> (or <a href="https://en.wikipedia.org/wiki/Radix" title="Radix">radix</a>). This digit string is referred to as the <i><a href="https://en.wikipedia.org/wiki/Significand" title="Significand">significand</a></i>, <i>mantissa</i>, or <i>coefficient</i>.<sup id="cite_ref-NB_Significand_4-0" class="reference"><a href="#cite_note-NB_Significand-4"><span class="cite-bracket">&#91;</span>nb 1<span class="cite-bracket">&#93;</span></a></sup> The length of the significand determines the <i>precision</i> to which numbers can be represented.  The radix point position is assumed always to be somewhere within the significand—often just after or just before the most significant digit, or to the right of the rightmost (least significant) digit.  This article generally follows the convention that the radix point is set just after the most significant (leftmost) digit.</li>
<li>A signed integer <a href="https://en.wikipedia.org/wiki/Exponent" class="mw-redirect" title="Exponent">exponent</a> (also referred to as the <i>characteristic</i>, or <i>scale</i>),<sup id="cite_ref-NB_Exponent_5-0" class="reference"><a href="#cite_note-NB_Exponent-5"><span class="cite-bracket">&#91;</span>nb 2<span class="cite-bracket">&#93;</span></a></sup> which modifies the magnitude of the number.</li></ul>
<p>To derive the value of the floating-point number, the <i>significand</i> is multiplied by the <i>base</i> raised to the power of the <i>exponent</i>, equivalent to shifting the radix point from its implied position by a number of places equal to the value of the exponent—to the right if the exponent is positive or to the left if the exponent is negative.
</p><p>Using base-10 (the familiar <a href="https://en.wikipedia.org/wiki/Decimal_representation" title="Decimal representation">decimal</a> notation) as an example, the number <span class="nowrap"><span data-sort-value="7005152853504700000♠"></span>152,853.5047</span>, which has ten decimal digits of precision, is represented as the significand <span class="nowrap"><span data-sort-value="7009152853504700000♠"></span>1,528,535,047</span> together with 5 as the exponent.  To determine the actual value, a decimal point is placed after the first digit of the significand and the result is multiplied by 10<sup><span class="nowrap"><span data-sort-value="7000500000000000000♠"></span>5</span></sup> to give <span class="nowrap"><span data-sort-value="7005152853504700000♠"></span>1.528535047<span style="margin-left:0.25em;margin-right:0.15em;">×</span>10<sup>5</sup></span>, or <span class="nowrap"><span data-sort-value="7005152853504700000♠"></span>152,853.5047</span>. In storing such a number, the base (10) need not be stored, since it will be the same for the entire range of supported numbers, and can thus be inferred.
</p><p>Symbolically, this final value is:
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\frac {s}{b^{\,p-1}}}\times b^{e},}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mi>s</mi>
            <msup>
              <mi>b</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mspace width="thinmathspace" />
                <mi>p</mi>
                <mo>&#x2212;<!-- − --></mo>
                <mn>1</mn>
              </mrow>
            </msup>
          </mfrac>
        </mrow>
        <mo>&#x00D7;<!-- × --></mo>
        <msup>
          <mi>b</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>e</mi>
          </mrow>
        </msup>
        <mo>,</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\frac {s}{b^{\,p-1}}}\times b^{e},}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86a81cce555673e1074b92fb4867de5dc050d9e6" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.171ex; width:10.864ex; height:5.009ex;" alt="{\displaystyle {\frac {s}{b^{\,p-1}}}\times b^{e},}"></span>
</p><p>where <span class="texhtml mvar" style="font-style:italic;">s</span> is the significand (ignoring any implied decimal point), <span class="texhtml mvar" style="font-style:italic;">p</span> is the precision (the number of digits in the significand), <span class="texhtml mvar" style="font-style:italic;">b</span> is the base (in our example, this is the number <i>ten</i>), and <span class="texhtml mvar" style="font-style:italic;">e</span> is the exponent.
</p><p><span class="anchor" id="Base-4"></span><span class="anchor" id="Base-8"></span><span class="anchor" id="Base-256"></span><span class="anchor" id="Base-65536"></span>Historically, several number bases have been used for representing floating-point numbers, with base two (<a href="https://en.wikipedia.org/wiki/Binary_numeral_system" class="mw-redirect" title="Binary numeral system">binary</a>) being the most common, followed by base ten (<a href="https://en.wikipedia.org/wiki/Decimal_floating_point" title="Decimal floating point">decimal floating point</a>), and other less common varieties, such as base sixteen (<a href="https://en.wikipedia.org/wiki/Hexadecimal_floating_point" title="Hexadecimal floating point">hexadecimal floating point</a><sup id="cite_ref-Zehendner_2008_6-0" class="reference"><a href="#cite_note-Zehendner_2008-6"><span class="cite-bracket">&#91;</span>4<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Beebe_2017_7-0" class="reference"><a href="#cite_note-Beebe_2017-7"><span class="cite-bracket">&#91;</span>5<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-NB_9_8-0" class="reference"><a href="#cite_note-NB_9-8"><span class="cite-bracket">&#91;</span>nb 3<span class="cite-bracket">&#93;</span></a></sup>), base eight (octal floating point<sup id="cite_ref-Muller_2010_1-2" class="reference"><a href="#cite_note-Muller_2010-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Beebe_2017_7-1" class="reference"><a href="#cite_note-Beebe_2017-7"><span class="cite-bracket">&#91;</span>5<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Savard_2018_9-0" class="reference"><a href="#cite_note-Savard_2018-9"><span class="cite-bracket">&#91;</span>6<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Zehendner_2008_6-1" class="reference"><a href="#cite_note-Zehendner_2008-6"><span class="cite-bracket">&#91;</span>4<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-NB_8_10-0" class="reference"><a href="#cite_note-NB_8-10"><span class="cite-bracket">&#91;</span>nb 4<span class="cite-bracket">&#93;</span></a></sup>), base four (quaternary floating point<sup id="cite_ref-Parkinson_2000_11-0" class="reference"><a href="#cite_note-Parkinson_2000-11"><span class="cite-bracket">&#91;</span>7<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Beebe_2017_7-2" class="reference"><a href="#cite_note-Beebe_2017-7"><span class="cite-bracket">&#91;</span>5<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-NB_11_12-0" class="reference"><a href="#cite_note-NB_11-12"><span class="cite-bracket">&#91;</span>nb 5<span class="cite-bracket">&#93;</span></a></sup>), base three (<a href="https://en.wikipedia.org/wiki/Balanced_ternary_floating_point" class="mw-redirect" title="Balanced ternary floating point">balanced ternary floating point</a><sup id="cite_ref-Muller_2010_1-3" class="reference"><a href="#cite_note-Muller_2010-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup>) and even base 256<sup id="cite_ref-Beebe_2017_7-3" class="reference"><a href="#cite_note-Beebe_2017-7"><span class="cite-bracket">&#91;</span>5<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-NB_12_13-0" class="reference"><a href="#cite_note-NB_12-13"><span class="cite-bracket">&#91;</span>nb 6<span class="cite-bracket">&#93;</span></a></sup> and base <span class="nowrap"><span data-sort-value="7004655360000000000♠"></span>65,536</span>.<sup id="cite_ref-Lazarus_1956_14-0" class="reference"><a href="#cite_note-Lazarus_1956-14"><span class="cite-bracket">&#91;</span>8<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-NB_10_15-0" class="reference"><a href="#cite_note-NB_10-15"><span class="cite-bracket">&#91;</span>nb 7<span class="cite-bracket">&#93;</span></a></sup>
</p><p>A floating-point number is a <a href="https://en.wikipedia.org/wiki/Rational_number" title="Rational number">rational number</a>, because it can be represented as one integer divided by another; for example <span class="nowrap"><span data-sort-value="7003145000000000000♠"></span>1.45<span style="margin-left:0.25em;margin-right:0.15em;">×</span>10<sup>3</sup></span> is (145/100)×1000 or <span class="nowrap"><span data-sort-value="7005145000000000000♠"></span>145,000</span>/100. The base determines the fractions that can be represented; for instance, 1/5 cannot be represented exactly as a floating-point number using a binary base, but 1/5 can be represented exactly using a decimal base (<span class="nowrap"><span data-sort-value="6999200000000000000♠"></span>0.2</span>, or <span class="nowrap"><span data-sort-value="6999200000000000000♠"></span>2<span style="margin-left:0.25em;margin-right:0.15em;">×</span>10<sup>−1</sup></span>). However, 1/3 cannot be represented exactly by either binary (0.010101...) or decimal (0.333...), but in <a href="https://en.wikipedia.org/wiki/Ternary_numeral_system" title="Ternary numeral system">base 3</a>, it is trivial (0.1 or 1×3<sup>−1</sup>) . The occasions on which infinite expansions occur <a href="https://en.wikipedia.org/wiki/Positional_notation#Infinite_representations" title="Positional notation">depend on the base and its prime factors</a>.
</p><p>The way in which the significand (including its sign) and exponent are stored in a computer is implementation-dependent. The common IEEE formats are described in detail later and elsewhere, but as an example, in the binary single-precision (32-bit) floating-point representation, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p=24}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
        <mo>=</mo>
        <mn>24</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p=24}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e7a1f78962b615188b35552e3a5c12c49edd7192" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:6.682ex; height:2.509ex;" alt="{\displaystyle p=24}"></span>, and so the significand is a string of 24 <a href="https://en.wikipedia.org/wiki/Bit" title="Bit">bits</a>.  For instance, the number <a href="https://en.wikipedia.org/wiki/Pi" title="Pi">π</a>'s first 33 bits are:
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 11001001\ 00001111\ 1101101{\underline {0}}\ 10100010\ 0.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>11001001</mn>
        <mtext>&#xA0;</mtext>
        <mn>00001111</mn>
        <mtext>&#xA0;</mtext>
        <mn>1101101</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <munder>
            <mn>0</mn>
            <mo>&#x005F;<!-- _ --></mo>
          </munder>
        </mrow>
        <mtext>&#xA0;</mtext>
        <mn>10100010</mn>
        <mtext>&#xA0;</mtext>
        <mn>0.</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 11001001\ 00001111\ 1101101{\underline {0}}\ 10100010\ 0.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/303a069975e556333e66839b929b63c1c618ac84" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.562ex; margin-bottom: -0.776ex; width:41.33ex; height:3.176ex;" alt="{\displaystyle 11001001\ 00001111\ 1101101{\underline {0}}\ 10100010\ 0.}"></span>
</p><p>In this binary expansion, let us denote the positions from 0 (leftmost bit, or most significant bit) to 32 (rightmost bit). The 24-bit significand will stop at position&#160;23, shown as the underlined bit <span class="nowrap"><span data-sort-value="5000000000000000000♠"></span>0</span> above. The next bit, at position&#160;24, is called the <i>round bit</i> or <i>rounding bit</i>. It is used to round the 33-bit approximation to the nearest 24-bit number (there are <a href="https://en.wikipedia.org/wiki/Rounding#Tie-breaking" title="Rounding">specific rules for halfway values</a>, which is not the case here). This bit, which is <span class="nowrap"><span data-sort-value="7000100000000000000♠"></span>1</span> in this example, is added to the integer formed by the leftmost 24 bits, yielding:
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 11001001\ 00001111\ 1101101{\underline {1}}.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>11001001</mn>
        <mtext>&#xA0;</mtext>
        <mn>00001111</mn>
        <mtext>&#xA0;</mtext>
        <mn>1101101</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <munder>
            <mn>1</mn>
            <mo>&#x005F;<!-- _ --></mo>
          </munder>
        </mrow>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 11001001\ 00001111\ 1101101{\underline {1}}.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2a95f70a59ffb71883524e67a8084da07a1ffa3e" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.511ex; margin-bottom: -0.827ex; width:29.707ex; height:3.176ex;" alt="{\displaystyle 11001001\ 00001111\ 1101101{\underline {1}}.}"></span>
</p><p>When this is stored in memory using the IEEE 754 encoding, this becomes the <a href="https://en.wikipedia.org/wiki/Significand" title="Significand">significand</a> <span class="texhtml mvar" style="font-style:italic;">s</span>. The significand is assumed to have a binary point to the right of the leftmost bit. So, the binary representation of π is calculated from left-to-right as follows:
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}&amp;\left(\sum _{n=0}^{p-1}{\text{bit}}_{n}\times 2^{-n}\right)\times 2^{e}\\={}&amp;\left(1\times 2^{-0}+1\times 2^{-1}+0\times 2^{-2}+0\times 2^{-3}+1\times 2^{-4}+\cdots +1\times 2^{-23}\right)\times 2^{1}\\\approx {}&amp;1.5707964\times 2\\\approx {}&amp;3.1415928\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd />
              <mtd>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <munderover>
                      <mo>&#x2211;<!-- ∑ --></mo>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>n</mi>
                        <mo>=</mo>
                        <mn>0</mn>
                      </mrow>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>p</mi>
                        <mo>&#x2212;<!-- − --></mo>
                        <mn>1</mn>
                      </mrow>
                    </munderover>
                    <msub>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mtext>bit</mtext>
                      </mrow>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>n</mi>
                      </mrow>
                    </msub>
                    <mo>&#x00D7;<!-- × --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mo>&#x2212;<!-- − --></mo>
                        <mi>n</mi>
                      </mrow>
                    </msup>
                  </mrow>
                  <mo>)</mo>
                </mrow>
                <mo>&#x00D7;<!-- × --></mo>
                <msup>
                  <mn>2</mn>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>e</mi>
                  </mrow>
                </msup>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mo>=</mo>
                <mrow class="MJX-TeXAtom-ORD">

                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mn>1</mn>
                    <mo>&#x00D7;<!-- × --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mo>&#x2212;<!-- − --></mo>
                        <mn>0</mn>
                      </mrow>
                    </msup>
                    <mo>+</mo>
                    <mn>1</mn>
                    <mo>&#x00D7;<!-- × --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mo>&#x2212;<!-- − --></mo>
                        <mn>1</mn>
                      </mrow>
                    </msup>
                    <mo>+</mo>
                    <mn>0</mn>
                    <mo>&#x00D7;<!-- × --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mo>&#x2212;<!-- − --></mo>
                        <mn>2</mn>
                      </mrow>
                    </msup>
                    <mo>+</mo>
                    <mn>0</mn>
                    <mo>&#x00D7;<!-- × --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mo>&#x2212;<!-- − --></mo>
                        <mn>3</mn>
                      </mrow>
                    </msup>
                    <mo>+</mo>
                    <mn>1</mn>
                    <mo>&#x00D7;<!-- × --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mo>&#x2212;<!-- − --></mo>
                        <mn>4</mn>
                      </mrow>
                    </msup>
                    <mo>+</mo>
                    <mo>&#x22EF;<!-- ⋯ --></mo>
                    <mo>+</mo>
                    <mn>1</mn>
                    <mo>&#x00D7;<!-- × --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mo>&#x2212;<!-- − --></mo>
                        <mn>23</mn>
                      </mrow>
                    </msup>
                  </mrow>
                  <mo>)</mo>
                </mrow>
                <mo>&#x00D7;<!-- × --></mo>
                <msup>
                  <mn>2</mn>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msup>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mo>&#x2248;<!-- ≈ --></mo>
                <mrow class="MJX-TeXAtom-ORD">

                </mrow>
              </mtd>
              <mtd>
                <mn>1.5707964</mn>
                <mo>&#x00D7;<!-- × --></mo>
                <mn>2</mn>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mo>&#x2248;<!-- ≈ --></mo>
                <mrow class="MJX-TeXAtom-ORD">

                </mrow>
              </mtd>
              <mtd>
                <mn>3.1415928</mn>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}&amp;\left(\sum _{n=0}^{p-1}{\text{bit}}_{n}\times 2^{-n}\right)\times 2^{e}\\={}&amp;\left(1\times 2^{-0}+1\times 2^{-1}+0\times 2^{-2}+0\times 2^{-3}+1\times 2^{-4}+\cdots +1\times 2^{-23}\right)\times 2^{1}\\\approx {}&amp;1.5707964\times 2\\\approx {}&amp;3.1415928\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/eb32f6fa82313115847df1312662ec490dbf31f6" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -8.005ex; width:75.968ex; height:17.176ex;" alt="{\displaystyle {\begin{aligned}&amp;\left(\sum _{n=0}^{p-1}{\text{bit}}_{n}\times 2^{-n}\right)\times 2^{e}\\={}&amp;\left(1\times 2^{-0}+1\times 2^{-1}+0\times 2^{-2}+0\times 2^{-3}+1\times 2^{-4}+\cdots +1\times 2^{-23}\right)\times 2^{1}\\\approx {}&amp;1.5707964\times 2\\\approx {}&amp;3.1415928\end{aligned}}}"></span>
</p><p>where <span class="texhtml mvar" style="font-style:italic;">p</span> is the precision (<span class="nowrap"><span data-sort-value="7001240000000000000♠"></span>24</span> in this example), <span class="texhtml mvar" style="font-style:italic;">n</span> is the position of the bit of the significand from the left (starting at <span class="nowrap"><span data-sort-value="5000000000000000000♠"></span>0</span> and finishing at <span class="nowrap"><span data-sort-value="7001230000000000000♠"></span>23</span> here) and <span class="texhtml mvar" style="font-style:italic;">e</span> is the exponent (<span class="nowrap"><span data-sort-value="7000100000000000000♠"></span>1</span> in this example).
</p><p><span class="anchor" id="Hidden_bit"></span>It can be required that the most significant digit of the significand of a non-zero number be non-zero (except when the corresponding exponent would be smaller than the minimum one). This process is called <i>normalization</i>. For binary formats (which uses only the digits <span class="nowrap"><span data-sort-value="5000000000000000000♠"></span>0</span> and <span class="nowrap"><span data-sort-value="7000100000000000000♠"></span>1</span>), this non-zero digit is necessarily <span class="nowrap"><span data-sort-value="7000100000000000000♠"></span>1</span>. Therefore, it does not need to be represented in memory, allowing the format to have one more bit of precision. This rule is variously called the <i>leading bit convention</i>, the <i>implicit bit convention</i>, the <i>hidden bit convention</i>,<sup id="cite_ref-Muller_2010_1-4" class="reference"><a href="#cite_note-Muller_2010-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup> or the <i>assumed bit convention</i>.
</p>
<div class="mw-heading mw-heading3"><h3 id="Alternatives_to_floating-point_numbers">Alternatives to floating-point numbers</h3></span></div>
<p>The floating-point representation is by far the most common way of representing in computers an approximation to real numbers. However, there are alternatives:
</p>
<ul><li><a href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic" title="Fixed-point arithmetic">Fixed-point</a> representation uses integer hardware operations controlled by a software implementation of a specific convention about the location of the binary or decimal point, for example, 6 bits or digits from the right. The hardware to manipulate these representations is less costly than floating point, and it can be used to perform normal integer operations, too. Binary fixed point is usually used in special-purpose applications on embedded processors that can only do integer arithmetic, but decimal fixed point is common in commercial applications.</li>
<li><a href="https://en.wikipedia.org/wiki/Logarithmic_number_system" title="Logarithmic number system">Logarithmic number systems</a> (LNSs) represent a real number by the logarithm of its absolute value and a sign bit. The value distribution is similar to floating point, but the value-to-representation curve (<i>i.e.</i>, the graph of the logarithm function) is smooth (except at 0). Conversely to floating-point arithmetic, in a logarithmic number system multiplication, division and exponentiation are simple to implement, but addition and subtraction are complex. The (<a href="https://en.wikipedia.org/wiki/Symmetric_level-index_arithmetic" title="Symmetric level-index arithmetic">symmetric</a>) <a href="https://en.wikipedia.org/wiki/Level-index_arithmetic" class="mw-redirect" title="Level-index arithmetic">level-index arithmetic</a> (LI and SLI) of Charles Clenshaw, <a href="https://en.wikipedia.org/wiki/Frank_William_John_Olver" class="mw-redirect" title="Frank William John Olver">Frank Olver</a> and Peter Turner is a scheme based on a <a href="https://en.wikipedia.org/wiki/Generalized_logarithm" class="mw-redirect" title="Generalized logarithm">generalized logarithm</a> representation.</li>
<li><a href="https://en.wikipedia.org/wiki/Tapered_floating-point_representation" class="mw-redirect" title="Tapered floating-point representation">Tapered floating-point representation</a>, which does not appear to be used in practice.</li>
<li>Some simple rational numbers (<i>e.g.</i>, 1/3 and 1/10) cannot be represented exactly in binary floating point, no matter what the precision is. Using a different radix allows one to represent some of them (<i>e.g.</i>, 1/10 in decimal floating point), but the possibilities remain limited. Software packages that perform <a href="https://en.wikipedia.org/wiki/Fraction" title="Fraction">rational arithmetic</a> represent numbers as fractions with integral numerator and denominator, and can therefore represent any rational number exactly.  Such packages generally need to use "<a href="https://en.wikipedia.org/wiki/Bignum" class="mw-redirect" title="Bignum">bignum</a>" arithmetic for the individual integers.</li>
<li><a href="https://en.wikipedia.org/wiki/Interval_arithmetic" title="Interval arithmetic">Interval arithmetic</a> allows one to represent numbers as intervals and obtain guaranteed bounds on results. It is generally based on other arithmetics, in particular floating point.</li>
<li><a href="https://en.wikipedia.org/wiki/Computer_algebra_system" title="Computer algebra system">Computer algebra systems</a> such as <a href="https://en.wikipedia.org/wiki/Mathematica" class="mw-redirect" title="Mathematica">Mathematica</a>, <a href="https://en.wikipedia.org/wiki/Maxima_(software)" title="Maxima (software)">Maxima</a>, and <a href="https://en.wikipedia.org/wiki/Maple_(software)" title="Maple (software)">Maple</a> can often handle irrational numbers like <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \pi }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03C0;<!-- π --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \pi }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9be4ba0bb8df3af72e90a0535fabcc17431e540a" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.332ex; height:1.676ex;" alt="{\displaystyle \pi }"></span> or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\sqrt {3}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <msqrt>
            <mn>3</mn>
          </msqrt>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\sqrt {3}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3b19c09494138b5082459afac7f9a8d99c546fcd" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:3.098ex; height:2.843ex;" alt="{\displaystyle {\sqrt {3}}}"></span> in a completely "formal" way (<a href="https://en.wikipedia.org/wiki/Symbolic_computation" class="mw-redirect" title="Symbolic computation">symbolic computation</a>), without dealing with a specific encoding of the significand.  Such a program can evaluate expressions like "<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sin(3\pi )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>sin</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>3</mn>
        <mi>&#x03C0;<!-- π --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sin(3\pi )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7d239f0e06c5d96ed18c3add618e47f27b3534b3" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:7.159ex; height:2.843ex;" alt="{\displaystyle \sin(3\pi )}"></span>" exactly, because it is programmed to process the underlying mathematics directly, instead of using approximate values for each intermediate calculation.</li></ul>
<div class="mw-heading mw-heading2"><h2 id="History">History</h2></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="https://en.wikipedia.org/wiki/IEEE_754#History" title="IEEE 754">IEEE 754 §&#160;History</a></div>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Quevedo_1917.jpg" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Quevedo_1917.jpg/150px-Quevedo_1917.jpg" decoding="async" width="150" height="157" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Quevedo_1917.jpg/225px-Quevedo_1917.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/c/c0/Quevedo_1917.jpg/300px-Quevedo_1917.jpg 2x" data-file-width="831" data-file-height="872" /></a><figcaption><a href="https://en.wikipedia.org/wiki/Leonardo_Torres_Quevedo" title="Leonardo Torres Quevedo">Leonardo Torres Quevedo</a>, in 1914, published an analysis of floating point based on the <a href="https://en.wikipedia.org/wiki/Analytical_engine" title="Analytical engine">analytical engine</a>.</figcaption></figure>
<p>In 1914, the Spanish engineer <a href="https://en.wikipedia.org/wiki/Leonardo_Torres_Quevedo" title="Leonardo Torres Quevedo">Leonardo Torres Quevedo</a> published <i>Essays on Automatics</i>,<sup id="cite_ref-16" class="reference"><a href="#cite_note-16"><span class="cite-bracket">&#91;</span>9<span class="cite-bracket">&#93;</span></a></sup> where he designed a special-purpose electromechanical calculator based on <a href="https://en.wikipedia.org/wiki/Charles_Babbage" title="Charles Babbage">Charles Babbage</a>'s <a href="https://en.wikipedia.org/wiki/Analytical_engine" title="Analytical engine">analytical engine</a> and described a way to store floating-point numbers in a consistent manner. He stated that numbers will be stored in exponential format as <i>n</i> x 10<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle ^{m}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>m</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle ^{m}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a8c4d272ab903e44501a5ac0aff0c8f2b0fcf611" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.171ex; width:1.675ex; height:2.176ex;" alt="{\displaystyle ^{m}}"></span>, and offered three rules by which consistent manipulation of floating-point numbers by machines could be implemented. For Torres, "<i>n</i> will always be the same number of <a href="https://en.wikipedia.org/wiki/Numerical_digit" title="Numerical digit">digits</a> (e.g. six), the first digit of <i>n</i> will be of order of tenths, the second of hundredths, etc, and one will write each quantity in the form: <i>n</i>; <i>m</i>." The format he proposed shows the need for a fixed-sized significand as is presently used for floating-point data, fixing the location of the decimal point in the significand so that each representation was unique, and how to format such numbers by specifying a syntax to be used that could be entered through a <a href="https://en.wikipedia.org/wiki/Typewriter" title="Typewriter">typewriter</a>, as was the case of his <a href="https://en.wikipedia.org/wiki/Leonardo_Torres_y_Quevedo#Analytical_machines" class="mw-redirect" title="Leonardo Torres y Quevedo"> Electromechanical Arithmometer</a> in 1920.<sup id="cite_ref-17" class="reference"><a href="#cite_note-17"><span class="cite-bracket">&#91;</span>10<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-FOOTNOTERandell19826,_11–13_18-0" class="reference"><a href="#cite_note-FOOTNOTERandell19826,_11–13-18"><span class="cite-bracket">&#91;</span>11<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-19" class="reference"><a href="#cite_note-19"><span class="cite-bracket">&#91;</span>12<span class="cite-bracket">&#93;</span></a></sup> 
</p>
<figure class="mw-default-size mw-halign-right" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Konrad_Zuse_(1992).jpg" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Konrad_Zuse_%281992%29.jpg/150px-Konrad_Zuse_%281992%29.jpg" decoding="async" width="150" height="200" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Konrad_Zuse_%281992%29.jpg/225px-Konrad_Zuse_%281992%29.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Konrad_Zuse_%281992%29.jpg/300px-Konrad_Zuse_%281992%29.jpg 2x" data-file-width="354" data-file-height="472" /></a><figcaption><a href="https://en.wikipedia.org/wiki/Konrad_Zuse" title="Konrad Zuse">Konrad Zuse</a>, architect of the <a href="https://en.wikipedia.org/wiki/Z3_(computer)" title="Z3 (computer)">Z3</a> computer, which uses a 22-bit binary floating-point representation</figcaption></figure>
<p>In 1938, <a href="https://en.wikipedia.org/wiki/Konrad_Zuse" title="Konrad Zuse">Konrad Zuse</a> of Berlin completed the <a href="https://en.wikipedia.org/wiki/Z1_(computer)" title="Z1 (computer)">Z1</a>, the first binary, programmable <a href="https://en.wikipedia.org/wiki/Mechanical_computer" title="Mechanical computer">mechanical computer</a>;<sup id="cite_ref-Rojas_1997_20-0" class="reference"><a href="#cite_note-Rojas_1997-20"><span class="cite-bracket">&#91;</span>13<span class="cite-bracket">&#93;</span></a></sup> it uses a 24-bit binary floating-point number representation with a 7-bit signed exponent, a 17-bit significand (including one implicit bit), and a sign bit.<sup id="cite_ref-Rojas_2014_21-0" class="reference"><a href="#cite_note-Rojas_2014-21"><span class="cite-bracket">&#91;</span>14<span class="cite-bracket">&#93;</span></a></sup> The more reliable <a href="https://en.wikipedia.org/wiki/Relay" title="Relay">relay</a>-based <a href="https://en.wikipedia.org/wiki/Z3_(computer)" title="Z3 (computer)">Z3</a>, completed in 1941, has representations for both positive and negative infinities; in particular, it implements defined operations with infinity, such as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle ^{1}/_{\infty }=0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msup>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>/</mo>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle ^{1}/_{\infty }=0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/23ef4d558c2fedd08aaaa744e83c7d36dd85cce6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:8.353ex; height:3.343ex;" alt="{\displaystyle ^{1}/_{\infty }=0}"></span>, and it stops on undefined operations, such as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 0\times \infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>0</mn>
        <mo>&#x00D7;<!-- × --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 0\times \infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6c2c67d872e7859a5b51d652639651d1e1384df0" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:6.327ex; height:2.176ex;" alt="{\displaystyle 0\times \infty }"></span>.
</p><p>Zuse also proposed, but did not complete, carefully rounded floating-point arithmetic that includes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \pm \infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>&#x00B1;<!-- ± --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \pm \infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c586ae37f8efec026b8a4ea3f6a5253576c2c4e6" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:4.132ex; height:2.176ex;" alt="{\displaystyle \pm \infty }"></span> and NaN representations, anticipating features of the IEEE Standard by four decades.<sup id="cite_ref-Kahan_1997_JVNL_22-0" class="reference"><a href="#cite_note-Kahan_1997_JVNL-22"><span class="cite-bracket">&#91;</span>15<span class="cite-bracket">&#93;</span></a></sup> In contrast, <a href="https://en.wikipedia.org/wiki/John_von_Neumann" title="John von Neumann">von Neumann</a> recommended against floating-point numbers for the 1951 <a href="https://en.wikipedia.org/wiki/IAS_machine" title="IAS machine">IAS machine</a>, arguing that fixed-point arithmetic is preferable.<sup id="cite_ref-Kahan_1997_JVNL_22-1" class="reference"><a href="#cite_note-Kahan_1997_JVNL-22"><span class="cite-bracket">&#91;</span>15<span class="cite-bracket">&#93;</span></a></sup>
</p><p>The first <i>commercial</i> computer with floating-point hardware was Zuse's <a href="https://en.wikipedia.org/wiki/Z4_(computer)" title="Z4 (computer)">Z4</a> computer, designed in 1942–1945. In 1946, Bell Laboratories introduced the <a href="https://en.wikipedia.org/wiki/Model_V" title="Model V">Model&#160;V</a>, which implemented <a href="https://en.wikipedia.org/wiki/Decimal_floating_point" title="Decimal floating point">decimal floating-point numbers</a>.<sup id="cite_ref-Randell_1982_2_23-0" class="reference"><a href="#cite_note-Randell_1982_2-23"><span class="cite-bracket">&#91;</span>16<span class="cite-bracket">&#93;</span></a></sup>
</p><p>The <a href="https://en.wikipedia.org/wiki/Pilot_ACE" title="Pilot ACE">Pilot ACE</a> has binary floating-point arithmetic, and it became operational in 1950 at <a href="https://en.wikipedia.org/wiki/National_Physical_Laboratory,_UK" class="mw-redirect" title="National Physical Laboratory, UK">National Physical Laboratory, UK</a>. Thirty-three were later sold commercially as the <a href="https://en.wikipedia.org/wiki/English_Electric_DEUCE" title="English Electric DEUCE">English Electric DEUCE</a>. The arithmetic is actually implemented in software, but with a one megahertz clock rate, the speed of floating-point and fixed-point operations in this machine were initially faster than those of many competing computers.
</p><p>The mass-produced <a href="https://en.wikipedia.org/wiki/IBM_704" title="IBM 704">IBM 704</a> followed in 1954; it introduced the use of a <a href="https://en.wikipedia.org/wiki/Exponent_bias" title="Exponent bias">biased exponent</a>. For many decades after that, floating-point hardware was typically an optional feature, and computers that had it were said to be "scientific computers", or to have "<a href="https://en.wikipedia.org/wiki/Scientific_computation" class="mw-redirect" title="Scientific computation">scientific computation</a>" (SC) capability (see also <a href="https://en.wikipedia.org/wiki/Extensions_for_Scientific_Computation" class="mw-redirect" title="Extensions for Scientific Computation">Extensions for Scientific Computation</a> (XSC)). It was not until the launch of the Intel i486 in 1989 that <i>general-purpose</i> personal computers had floating-point capability in hardware as a standard feature.
</p><p>The <a href="https://en.wikipedia.org/wiki/UNIVAC_1100/2200_series" title="UNIVAC 1100/2200 series">UNIVAC 1100/2200 series</a>, introduced in 1962, supported two floating-point representations:
</p>
<ul><li><i>Single precision</i>: 36 bits, organized as a 1-bit sign, an 8-bit exponent, and a 27-bit significand.</li>
<li><i>Double precision</i>: 72 bits, organized as a 1-bit sign, an 11-bit exponent, and a 60-bit significand.</li></ul>
<p>The <a href="https://en.wikipedia.org/wiki/IBM_7094" class="mw-redirect" title="IBM 7094">IBM 7094</a>, also introduced in 1962, supported single-precision and double-precision representations, but with no relation to the UNIVAC's representations. Indeed, in 1964, IBM introduced <a href="https://en.wikipedia.org/wiki/IBM_hexadecimal_floating-point" title="IBM hexadecimal floating-point">hexadecimal floating-point representations</a> in its <a href="https://en.wikipedia.org/wiki/System/360" class="mw-redirect" title="System/360">System/360</a> mainframes; these same representations are still available for use in modern <a href="https://en.wikipedia.org/wiki/Z/Architecture" title="Z/Architecture">z/Architecture</a> systems.  In 1998, IBM implemented IEEE-compatible binary floating-point arithmetic in its mainframes; in 2005, IBM also added IEEE-compatible decimal floating-point arithmetic.
</p><p>Initially, computers used many different representations for floating-point numbers. The lack of standardization at the mainframe level was an ongoing problem by the early 1970s for those writing and maintaining higher-level source code; these manufacturer floating-point standards differed in the word sizes, the representations, and the rounding behavior and general accuracy of operations. Floating-point compatibility across multiple computing systems was in desperate need of standardization by the early 1980s, leading to the creation of the <a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a> standard once the 32-bit (or 64-bit) <a href="https://en.wikipedia.org/wiki/Word_(computer_architecture)" title="Word (computer architecture)">word</a> had become commonplace. This standard was significantly based on a proposal from Intel, which was designing the <a href="https://en.wikipedia.org/wiki/Intel_8087" title="Intel 8087">i8087</a> numerical coprocessor; Motorola, which was designing the <a href="https://en.wikipedia.org/wiki/68000" class="mw-redirect" title="68000">68000</a> around the same time, gave significant input as well.
</p>
<figure class="mw-default-size mw-halign-right" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:William_Kahan_2008.jpg" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/William_Kahan_2008.jpg/150px-William_Kahan_2008.jpg" decoding="async" width="150" height="106" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/William_Kahan_2008.jpg/225px-William_Kahan_2008.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/William_Kahan_2008.jpg/300px-William_Kahan_2008.jpg 2x" data-file-width="3225" data-file-height="2287" /></a><figcaption><a href="https://en.wikipedia.org/wiki/William_Kahan" title="William Kahan">William Kahan</a>, principal architect of the <a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a> floating-point standard</figcaption></figure>
<p>In 1989, mathematician and computer scientist <a href="https://en.wikipedia.org/wiki/William_Kahan" title="William Kahan">William Kahan</a> was honored with the <a href="https://en.wikipedia.org/wiki/Turing_Award" title="Turing Award">Turing Award</a> for being the primary architect behind this proposal; he was aided by his student Jerome Coonen and a visiting professor, <a href="https://en.wikipedia.org/wiki/Harold_S._Stone" title="Harold S. Stone">Harold Stone</a>.<sup id="cite_ref-Severance_1998_24-0" class="reference"><a href="#cite_note-Severance_1998-24"><span class="cite-bracket">&#91;</span>17<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Among the x86 innovations are these:
</p>
<ul><li>A precisely specified floating-point representation at the bit-string level, so that all compliant computers interpret bit patterns the same way. This makes it possible to accurately and efficiently transfer floating-point numbers from one computer to another (after accounting for <a href="https://en.wikipedia.org/wiki/Endianness" title="Endianness">endianness</a>).</li>
<li>A precisely specified behavior for the arithmetic operations: A result is required to be produced as if infinitely precise arithmetic were used to yield a value that is then rounded according to specific rules. This means that a compliant computer program would always produce the same result when given a particular input, thus mitigating the almost mystical reputation that floating-point computation had developed for its hitherto seemingly non-deterministic behavior.</li>
<li>The ability of <a href="https://en.wikipedia.org/wiki/IEEE_754#Exception_handling" title="IEEE 754">exceptional conditions</a> (overflow, <a href="https://en.wikipedia.org/wiki/Division_by_zero" title="Division by zero">divide by zero</a>, etc.) to propagate through a computation in a benign manner and then be handled by the software in a controlled fashion.</li></ul>
<div class="mw-heading mw-heading2"><h2 id="Range_of_floating-point_numbers">Range of floating-point numbers</h2></span></div>
<p>A floating-point number consists of two <a href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic" title="Fixed-point arithmetic">fixed-point</a> components, whose range depends exclusively on the number of bits or digits in their representation. Whereas components linearly depend on their range, the floating-point range linearly depends on the significand range and exponentially on the range of exponent component, which attaches outstandingly wider range to the number.
</p><p>On a typical computer system, a <i><a href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format" title="Double-precision floating-point format">double-precision</a></i> (64-bit) binary floating-point number has a coefficient of 53 bits (including 1 implied bit), an exponent of 11 bits, and 1 sign bit. Since 2<sup>10</sup> = 1024, the complete range of the positive normal floating-point numbers in this format is from 2<sup>−1022</sup>&#160;≈&#160;2&#160;×&#160;10<sup>−308</sup> to approximately 2<sup>1024</sup>&#160;≈&#160;2&#160;×&#160;10<sup>308</sup>.
</p><p>The number of normal floating-point numbers in a system (<i>B</i>, <i>P</i>, <i>L</i>, <i>U</i>) where
</p>
<ul><li><i>B</i> is the base of the system,</li>
<li><i>P</i> is the precision of the significand (in base <i>B</i>),</li>
<li><i>L</i> is the smallest exponent of the system,</li>
<li><i>U</i> is the largest exponent of the system,</li></ul>
<p>is <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 2\left(B-1\right)\left(B^{P-1}\right)\left(U-L+1\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>2</mn>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mi>B</mi>
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mrow>
          <mo>(</mo>
          <msup>
            <mi>B</mi>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>P</mi>
              <mo>&#x2212;<!-- − --></mo>
              <mn>1</mn>
            </mrow>
          </msup>
          <mo>)</mo>
        </mrow>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mi>U</mi>
            <mo>&#x2212;<!-- − --></mo>
            <mi>L</mi>
            <mo>+</mo>
            <mn>1</mn>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 2\left(B-1\right)\left(B^{P-1}\right)\left(U-L+1\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/50a5e9a91a7338cf13ed00dfe9042b7aa0d8a79b" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:29.379ex; height:3.343ex;" alt="{\displaystyle 2\left(B-1\right)\left(B^{P-1}\right)\left(U-L+1\right)}"></span>.
</p><p>There is a smallest positive normal floating-point number,
</p>
<dl><dd>Underflow level = UFL = <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle B^{L}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>B</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>L</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle B^{L}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/03c80b97f6b23ac47189791d0c01da71ab982531" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:3.116ex; height:2.676ex;" alt="{\displaystyle B^{L}}"></span>,</dd></dl>
<p>which has a 1 as the leading digit and 0 for the remaining digits of the significand, and the smallest possible value for the exponent.
</p><p>There is a largest floating-point number,
</p>
<dl><dd>Overflow level = OFL = <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \left(1-B^{-P}\right)\left(B^{U+1}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow>
          <mo>(</mo>
          <mrow>
            <mn>1</mn>
            <mo>&#x2212;<!-- − --></mo>
            <msup>
              <mi>B</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mo>&#x2212;<!-- − --></mo>
                <mi>P</mi>
              </mrow>
            </msup>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mrow>
          <mo>(</mo>
          <msup>
            <mi>B</mi>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>U</mi>
              <mo>+</mo>
              <mn>1</mn>
            </mrow>
          </msup>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \left(1-B^{-P}\right)\left(B^{U+1}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/89ef88d856c29d99a33aa71976c5827a32abf281" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.005ex; width:18.516ex; height:3.343ex;" alt="{\displaystyle \left(1-B^{-P}\right)\left(B^{U+1}\right)}"></span>,</dd></dl>
<p>which has <i>B</i> − 1 as the value for each digit of the significand and the largest possible value for the exponent.
</p><p>In addition, there are representable values strictly between −UFL and UFL. Namely, <a href="https://en.wikipedia.org/wiki/Signed_zero" title="Signed zero">positive and negative zeros</a>, as well as <a href="https://en.wikipedia.org/wiki/Subnormal_number" title="Subnormal number">subnormal numbers</a>.
</p>
<div class="mw-heading mw-heading2"><h2 id="IEEE_754:_floating_point_in_modern_computers">IEEE 754: floating point in modern computers <span class="anchor" id="IEEE_754"></span></h2></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a></div>
<style data-mw-deduplicate="TemplateStyles:r1129693374">.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:": "}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:" · ";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:" (";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:")";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:" "counter(listitem)"\a0 "}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:" ("counter(listitem)"\a0 "}</style><style data-mw-deduplicate="TemplateStyles:r1126788409">.mw-parser-output .plainlist ol,.mw-parser-output .plainlist ul{line-height:inherit;list-style:none;margin:0;padding:0}.mw-parser-output .plainlist ol li,.mw-parser-output .plainlist ul li{margin-bottom:0}</style><style data-mw-deduplicate="TemplateStyles:r1246091330">.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:var(--background-color-neutral-subtle,#f8f9fa);border:1px solid var(--border-color-base,#a2a9b1);padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:640px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}body.skin--responsive .mw-parser-output .sidebar a>img{max-width:none!important}@media screen{html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-night .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-list-title,html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle{background:transparent!important}html.skin-theme-clientpref-os .mw-parser-output .sidebar:not(.notheme) .sidebar-title-with-pretitle a{color:var(--color-progressive)!important}}@media print{body.ns-0 .mw-parser-output .sidebar{display:none!important}}</style><table class="sidebar nomobile nowraplinks plainlist"><tbody><tr><th class="sidebar-title"><a class="mw-selflink selflink">Floating-point</a> <a href="https://en.wikipedia.org/wiki/Computer_number_format" title="Computer number format">formats</a></th></tr><tr><th class="sidebar-heading">
<a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a></th></tr><tr><td class="sidebar-content">
<ul><li>16-bit: <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format" title="Half-precision floating-point format">Half</a> (binary16)</li>
<li>32-bit: <a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" title="Single-precision floating-point format">Single</a> (binary32), <a href="https://en.wikipedia.org/wiki/Decimal32_floating-point_format" title="Decimal32 floating-point format">decimal32</a></li>
<li>64-bit: <a href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format" title="Double-precision floating-point format">Double</a> (binary64), <a href="https://en.wikipedia.org/wiki/Decimal64_floating-point_format" title="Decimal64 floating-point format">decimal64</a></li>
<li>128-bit: <a href="https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format" title="Quadruple-precision floating-point format">Quadruple</a> (binary128), <a href="https://en.wikipedia.org/wiki/Decimal128_floating-point_format" title="Decimal128 floating-point format">decimal128</a></li>
<li>256-bit: <a href="https://en.wikipedia.org/wiki/Octuple-precision_floating-point_format" title="Octuple-precision floating-point format">Octuple</a> (binary256)</li>
<li><a href="https://en.wikipedia.org/wiki/Extended_precision" title="Extended precision">Extended precision</a></li></ul></td>
</tr><tr><th class="sidebar-heading">
Other</th></tr><tr><td class="sidebar-content">
<ul><li><a href="https://en.wikipedia.org/wiki/Minifloat" title="Minifloat">Minifloat</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bfloat16_floating-point_format" title="Bfloat16 floating-point format">bfloat16</a></li>
<li><a href="https://en.wikipedia.org/wiki/TensorFloat-32" title="TensorFloat-32">TensorFloat-32</a></li>
<li><a href="https://en.wikipedia.org/wiki/Microsoft_Binary_Format" title="Microsoft Binary Format">Microsoft Binary Format</a></li>
<li><a href="https://en.wikipedia.org/wiki/IBM_hexadecimal_floating-point" title="IBM hexadecimal floating-point">IBM floating-point architecture</a></li>
<li><a href="https://en.wikipedia.org/wiki/Power_Management_Bus#Linear11_Floating_Point_Format" title="Power Management Bus">PMBus Linear-11</a></li>
<li><a href="https://en.wikipedia.org/wiki/G.711" title="G.711">G.711 8-bit floats</a></li></ul></td>
</tr><tr><th class="sidebar-heading">
Alternatives</th></tr><tr><td class="sidebar-content">
<ul><li><a href="https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic" title="Arbitrary-precision arithmetic">Arbitrary precision</a></li></ul></td>
</tr><tr><td class="sidebar-navbar"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><style data-mw-deduplicate="TemplateStyles:r1239400231">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}</style><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="https://en.wikipedia.org/wiki/Template:Floating-point" title="Template:Floating-point"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="https://en.wikipedia.org/wiki/Template_talk:Floating-point" title="Template talk:Floating-point"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a href="https://en.wikipedia.org/wiki/Special:EditPage/Template:Floating-point" title="Special:EditPage/Template:Floating-point"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p>The <a href="https://en.wikipedia.org/wiki/Institute_of_Electrical_and_Electronics_Engineers" title="Institute of Electrical and Electronics Engineers">IEEE</a> standardized the computer representation for binary floating-point numbers in <a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a> (a.k.a. IEC 60559) in 1985. This first standard is followed by almost all modern machines. It was <a href="https://en.wikipedia.org/wiki/IEEE_754-2008_revision" title="IEEE 754-2008 revision">revised in 2008</a>. IBM mainframes support <a href="https://en.wikipedia.org/wiki/IBM_hexadecimal_floating_point" class="mw-redirect" title="IBM hexadecimal floating point">IBM's own hexadecimal floating point format</a> and IEEE 754-2008 <a href="https://en.wikipedia.org/wiki/Decimal_floating_point" title="Decimal floating point">decimal floating point</a> in addition to the IEEE 754 binary format. The <a href="https://en.wikipedia.org/wiki/Cray_T90" title="Cray T90">Cray T90</a> series had an IEEE version, but the <a href="https://en.wikipedia.org/wiki/Cray_SV1" title="Cray SV1">SV1</a> still uses Cray floating-point format.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (July 2020)">citation needed</span></a></i>&#93;</sup>
</p><p>The standard provides for many closely related formats, differing in only a few details. Five of these formats are called <i>basic formats</i>, and others are termed <i>extended precision formats</i> and <i>extendable precision format</i>. Three formats are especially widely used in computer hardware and languages:<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="Possibly wrong for double extended: OK for hardware, but for languages? Note that in C, long double may not correspond to double extended (see 32-bit ARM and PowerPC). (July 2020)">citation needed</span></a></i>&#93;</sup>
</p>
<ul><li><a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" title="Single-precision floating-point format">Single precision</a> (binary32), usually used to represent the "float" <a href="https://en.wikipedia.org/wiki/C_data_types#Basic_types" title="C data types">type in the C language</a> family. This is a binary format that occupies 32 bits (4 bytes) and its significand has a precision of 24 bits (about 7 decimal digits).</li>
<li><a href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format" title="Double-precision floating-point format">Double precision</a> (binary64), usually used to represent the "double" <a href="https://en.wikipedia.org/wiki/C_data_types#Basic_types" title="C data types">type in the C language</a> family. This is a binary format that occupies 64 bits (8 bytes) and its significand has a precision of 53 bits (about 16 decimal digits).</li>
<li><a href="https://en.wikipedia.org/wiki/Extended_precision" title="Extended precision">Double extended</a>, also ambiguously called "extended precision" format. This is a binary format that occupies at least 79 bits (80 if the hidden/implicit bit rule is not used) and its significand has a precision of at least 64 bits (about 19 decimal digits). The <a href="https://en.wikipedia.org/wiki/C99" title="C99">C99</a> and <a href="https://en.wikipedia.org/wiki/C11_(C_standard_revision)" title="C11 (C standard revision)">C11</a> standards of the C language family, in their annex F ("IEC 60559 floating-point arithmetic"), recommend such an extended format to be provided as "<a href="https://en.wikipedia.org/wiki/Long_double" title="Long double">long double</a>".<sup id="cite_ref-C99_25-0" class="reference"><a href="#cite_note-C99-25"><span class="cite-bracket">&#91;</span>18<span class="cite-bracket">&#93;</span></a></sup> A format satisfying the minimal requirements (64-bit significand precision, 15-bit exponent, thus fitting on 80 bits) is provided by the <a href="https://en.wikipedia.org/wiki/X86" title="X86">x86</a> architecture. Often on such processors, this format can be used with "long double", though extended precision is not available with MSVC.<sup id="cite_ref-MSVC_26-0" class="reference"><a href="#cite_note-MSVC-26"><span class="cite-bracket">&#91;</span>19<span class="cite-bracket">&#93;</span></a></sup> For <a href="https://en.wikipedia.org/wiki/Data_structure_alignment" title="Data structure alignment">alignment</a> purposes, many tools store this 80-bit value in a 96-bit or 128-bit space.<sup id="cite_ref-GCC_27-0" class="reference"><a href="#cite_note-GCC-27"><span class="cite-bracket">&#91;</span>20<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-float_128_28-0" class="reference"><a href="#cite_note-float_128-28"><span class="cite-bracket">&#91;</span>21<span class="cite-bracket">&#93;</span></a></sup> On other processors, "long double" may stand for a larger format, such as quadruple precision,<sup id="cite_ref-ARM_2013_AArch64_29-0" class="reference"><a href="#cite_note-ARM_2013_AArch64-29"><span class="cite-bracket">&#91;</span>22<span class="cite-bracket">&#93;</span></a></sup> or just double precision, if any form of extended precision is not available.<sup id="cite_ref-ARM_2013_Compiler_30-0" class="reference"><a href="#cite_note-ARM_2013_Compiler-30"><span class="cite-bracket">&#91;</span>23<span class="cite-bracket">&#93;</span></a></sup></li></ul>
<p>Increasing the precision of the floating-point representation generally reduces the amount of accumulated <a href="https://en.wikipedia.org/wiki/Round-off_error" title="Round-off error">round-off error</a> caused by intermediate calculations.<sup id="cite_ref-Kahan_2004_31-0" class="reference"><a href="#cite_note-Kahan_2004-31"><span class="cite-bracket">&#91;</span>24<span class="cite-bracket">&#93;</span></a></sup>
Other IEEE formats include:
</p>
<ul><li><a href="https://en.wikipedia.org/wiki/Decimal64_floating-point_format" title="Decimal64 floating-point format">Decimal64</a> and <a href="https://en.wikipedia.org/wiki/Decimal128_floating-point_format" title="Decimal128 floating-point format">decimal128</a> floating-point formats. These formats (especially decimal128) are pervasive in financial transactions because, along with the <a href="https://en.wikipedia.org/wiki/Decimal32_floating-point_format" title="Decimal32 floating-point format">decimal32</a> format, they allow correct decimal rounding.</li>
<li><a href="https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format#IEEE_754_quadruple-precision_binary_floating-point_format:_binary128" title="Quadruple-precision floating-point format">Quadruple precision</a> (binary128). This is a binary format that occupies 128 bits (16 bytes) and its significand has a precision of 113 bits (about 34 decimal digits).</li>
<li><a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format" title="Half-precision floating-point format">Half precision</a>, also called binary16, a 16-bit floating-point value. It is being used in the NVIDIA <a href="https://en.wikipedia.org/wiki/Cg_(programming_language)" title="Cg (programming language)">Cg</a> graphics language, and in the openEXR standard (where it actually predates the introduction in the IEEE 754 standard).<sup id="cite_ref-OpenEXR_32-0" class="reference"><a href="#cite_note-OpenEXR-32"><span class="cite-bracket">&#91;</span>25<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-OpenEXR-half_33-0" class="reference"><a href="#cite_note-OpenEXR-half-33"><span class="cite-bracket">&#91;</span>26<span class="cite-bracket">&#93;</span></a></sup></li></ul>
<p>Any integer with absolute value less than 2<sup>24</sup> can be exactly represented in the single-precision format, and any integer with absolute value less than 2<sup>53</sup> can be exactly represented in the double-precision format. Furthermore, a wide range of powers of 2 times such a number can be represented. These properties are sometimes used for purely integer data, to get 53-bit integers on platforms that have double-precision floats but only 32-bit integers.
</p><p>The standard specifies some special values, and their representation: positive <a href="https://en.wikipedia.org/wiki/Infinity" title="Infinity">infinity</a> (<span class="texhtml">+∞</span>), negative infinity (<span class="texhtml">−∞</span>), a <a href="https://en.wikipedia.org/wiki/Negative_zero" class="mw-redirect" title="Negative zero">negative zero</a> (−0) distinct from ordinary ("positive") zero, and "not a number" values (<a href="https://en.wikipedia.org/wiki/NaN" title="NaN">NaNs</a>).
</p><p>Comparison of floating-point numbers, as defined by the IEEE standard, is a bit different from usual integer comparison. Negative and positive zero compare equal, and every NaN compares unequal to every value, including itself. All finite floating-point numbers are strictly smaller than <span class="texhtml">+∞</span> and strictly greater than <span class="texhtml">−∞</span>, and they are ordered in the same way as their values (in the set of real numbers).
</p>
<div class="mw-heading mw-heading3"><h3 id="Internal_representation">Internal representation</h3></span></div>
<p>Floating-point numbers are typically packed into a computer datum as the sign bit, the exponent field, and the significand or mantissa, from left to right.  For the IEEE 754 binary formats (basic and extended) which have extant hardware implementations, they are apportioned as follows:
</p>
<table class="wikitable" style="text-align:right; border:0">

<tbody><tr>
<th rowspan="2">Type
</th>
<th colspan="4">Bits
</th>
<td rowspan="7" style="background:white; border:0">
</td>
<th rowspan="2">Exponent<br />bias
</th>
<th rowspan="2">Bits<br />precision
</th>
<th rowspan="2">Number of<br />decimal digits
</th></tr>
<tr>
<th>Sign
</th>
<th>Exponent
</th>
<th>Significand
</th>
<th>Total
</th></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Half_precision" class="mw-redirect" title="Half precision">Half</a> (<a href="https://en.wikipedia.org/wiki/IEEE_floating_point" class="mw-redirect" title="IEEE floating point">IEEE 754-2008</a>)
</td>
<td>1
</td>
<td>5
</td>
<td>10
</td>
<td>16
</td>
<td>15
</td>
<td>11
</td>
<td>~3.3
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Single_precision" class="mw-redirect" title="Single precision">Single</a>
</td>
<td>1
</td>
<td>8
</td>
<td>23
</td>
<td>32
</td>
<td>127
</td>
<td>24
</td>
<td>~7.2
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Double_precision" class="mw-redirect" title="Double precision">Double</a>
</td>
<td>1
</td>
<td>11
</td>
<td>52
</td>
<td>64
</td>
<td>1023
</td>
<td>53
</td>
<td>~15.9
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Extended_precision#x86_extended_precision_format" title="Extended precision">x86 extended precision</a>
</td>
<td>1
</td>
<td>15
</td>
<td>64
</td>
<td>80
</td>
<td>16383
</td>
<td>64
</td>
<td>~19.2
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Quad_precision" class="mw-redirect" title="Quad precision">Quad</a>
</td>
<td>1
</td>
<td>15
</td>
<td>112
</td>
<td>128
</td>
<td>16383
</td>
<td>113
</td>
<td>~34.0
</td></tr></tbody></table>
<p>While the exponent can be positive or negative, in binary formats it is stored as an unsigned number that has a fixed "bias" added to it. Values of all 0s in this field are reserved for the zeros and <a href="https://en.wikipedia.org/wiki/Subnormal_numbers" class="mw-redirect" title="Subnormal numbers">subnormal numbers</a>; values of all 1s are reserved for the infinities and NaNs. The exponent range for normal numbers is [−126, 127] for single precision, [−1022, 1023] for double, or [−16382, 16383] for quad. Normal numbers exclude subnormal values, zeros, infinities, and NaNs.
</p><p>In the IEEE binary interchange formats the leading 1 bit of a normalized significand is not actually stored in the computer datum. It is called the "hidden" or "implicit" bit. Because of this, the single-precision format actually has a significand with 24 bits of precision, the double-precision format has 53, and quad has 113.
</p><p>For example, it was shown above that π, rounded to 24 bits of precision, has:
</p>
<ul><li>sign = 0&#160;; <i>e</i> = 1&#160;; <i>s</i> = 110010010000111111011011 (including the hidden bit)</li></ul>
<p>The sum of the exponent bias (127) and the exponent (1) is 128, so this is represented in the single-precision format as
</p>
<ul><li>0 10000000 10010010000111111011011 (excluding the hidden bit) = 40490FDB<sup id="cite_ref-IEEE-754_Analysis_34-0" class="reference"><a href="#cite_note-IEEE-754_Analysis-34"><span class="cite-bracket">&#91;</span>27<span class="cite-bracket">&#93;</span></a></sup> as a <a href="https://en.wikipedia.org/wiki/Hexadecimal" title="Hexadecimal">hexadecimal</a> number.</li></ul>
<p>An example of a layout for <a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" title="Single-precision floating-point format">32-bit floating point</a> is
</p>
<figure class="mw-default-size mw-halign-none" typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Float_example.svg" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Float_example.svg/590px-Float_example.svg.png" decoding="async" width="590" height="75" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Float_example.svg/885px-Float_example.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Float_example.svg/1180px-Float_example.svg.png 2x" data-file-width="590" data-file-height="75" /></a><figcaption></figcaption></figure>
<p>and the <a href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format" title="Double-precision floating-point format">64-bit ("double")</a> layout is similar.
</p>
<div class="mw-heading mw-heading2"><h2 id="Other_notable_floating-point_formats">Other notable floating-point formats</h2></span></div>
<p>In addition to the widely used <a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a> standard formats, other floating-point formats are used, or have been used, in certain domain-specific areas.
</p>
<ul><li>The <a href="https://en.wikipedia.org/wiki/Microsoft_Binary_Format" title="Microsoft Binary Format">Microsoft Binary Format (MBF)</a> was developed for the Microsoft BASIC language products, including Microsoft's first ever product the <a href="https://en.wikipedia.org/wiki/Altair_BASIC" title="Altair BASIC">Altair BASIC</a> (1975), <a href="https://en.wikipedia.org/wiki/TRS-80" title="TRS-80">TRS-80 LEVEL II</a>, <a href="https://en.wikipedia.org/wiki/CP/M" title="CP/M">CP/M</a>'s <a href="https://en.wikipedia.org/wiki/MBASIC" title="MBASIC">MBASIC</a>, <a href="https://en.wikipedia.org/wiki/IBM_PC_5150" class="mw-redirect" title="IBM PC 5150">IBM PC 5150</a>'s <a href="https://en.wikipedia.org/wiki/BASICA" class="mw-redirect" title="BASICA">BASICA</a>, <a href="https://en.wikipedia.org/wiki/MS-DOS" title="MS-DOS">MS-DOS</a>'s <a href="https://en.wikipedia.org/wiki/GW-BASIC" title="GW-BASIC">GW-BASIC</a> and <a href="https://en.wikipedia.org/wiki/QuickBASIC" title="QuickBASIC">QuickBASIC</a> prior to version 4.00.  QuickBASIC version 4.00 and 4.50 switched to the IEEE 754-1985 format but can revert to the MBF format using the /MBF command option.  MBF was designed and developed on a simulated <a href="https://en.wikipedia.org/wiki/Intel_8080" title="Intel 8080">Intel 8080</a> by <a href="https://en.wikipedia.org/wiki/Monte_Davidoff" title="Monte Davidoff">Monte Davidoff</a>, a dormmate of <a href="https://en.wikipedia.org/wiki/Bill_Gates" title="Bill Gates">Bill Gates</a>, during spring of 1975 for the <a href="https://en.wikipedia.org/wiki/MITS_Altair_8800" class="mw-redirect" title="MITS Altair 8800">MITS Altair 8800</a>.  The initial release of July 1975 supported a single-precision (32 bits) format due to cost of the <a href="https://en.wikipedia.org/wiki/MITS_Altair_8800" class="mw-redirect" title="MITS Altair 8800">MITS Altair 8800</a> 4-kilobytes memory.  In December 1975, the 8-kilobytes version added a double-precision (64 bits) format.  A single-precision (40 bits) variant format was adopted for other CPU's, notably the <a href="https://en.wikipedia.org/wiki/MOS_6502" class="mw-redirect" title="MOS 6502">MOS 6502</a> (<a href="https://en.wikipedia.org/wiki/Apple_//" class="mw-redirect" title="Apple //">Apple //</a>, <a href="https://en.wikipedia.org/wiki/Commodore_PET" title="Commodore PET">Commodore PET</a>, <a href="https://en.wikipedia.org/wiki/Atari" title="Atari">Atari</a>), <a href="https://en.wikipedia.org/wiki/Motorola_6800" title="Motorola 6800">Motorola 6800</a> (MITS Altair 680) and <a href="https://en.wikipedia.org/wiki/Motorola_6809" title="Motorola 6809">Motorola 6809</a> (<a href="https://en.wikipedia.org/wiki/TRS-80_Color_Computer" title="TRS-80 Color Computer">TRS-80 Color Computer</a>).  All Microsoft language products from 1975 through 1987 used the <a href="https://en.wikipedia.org/wiki/Microsoft_Binary_Format" title="Microsoft Binary Format">Microsoft Binary Format</a> until Microsoft adopted the IEEE-754 standard format in all its products starting in 1988 to their current releases. MBF consists of the MBF single-precision format (32 bits, "6-digit BASIC"),<sup id="cite_ref-Borland_1994_MBF_35-0" class="reference"><a href="#cite_note-Borland_1994_MBF-35"><span class="cite-bracket">&#91;</span>28<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Steil_2008_6502_36-0" class="reference"><a href="#cite_note-Steil_2008_6502-36"><span class="cite-bracket">&#91;</span>29<span class="cite-bracket">&#93;</span></a></sup> the MBF extended-precision format (40 bits, "9-digit BASIC"),<sup id="cite_ref-Steil_2008_6502_36-1" class="reference"><a href="#cite_note-Steil_2008_6502-36"><span class="cite-bracket">&#91;</span>29<span class="cite-bracket">&#93;</span></a></sup> and the MBF double-precision format (64 bits);<sup id="cite_ref-Borland_1994_MBF_35-1" class="reference"><a href="#cite_note-Borland_1994_MBF-35"><span class="cite-bracket">&#91;</span>28<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Microsoft_2006_KB35826_37-0" class="reference"><a href="#cite_note-Microsoft_2006_KB35826-37"><span class="cite-bracket">&#91;</span>30<span class="cite-bracket">&#93;</span></a></sup> each of them is represented with an 8-bit exponent, followed by a sign bit, followed by a significand of respectively 23, 31, and 55 bits.</li>
<li>The <a href="https://en.wikipedia.org/wiki/Bfloat16_floating-point_format" title="Bfloat16 floating-point format">Bfloat16 format</a> requires the same amount of memory (16 bits) as the <a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format" title="Half-precision floating-point format">IEEE 754 half-precision format</a>, but allocates 8 bits to the exponent instead of 5, thus providing the same range as a <a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" title="Single-precision floating-point format">IEEE 754 single-precision</a> number. The tradeoff is a reduced precision, as the trailing significand field is reduced from 10 to 7 bits. This format is mainly used in the training of <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine learning">machine learning</a> models, where range is more valuable than precision. Many machine learning accelerators provide hardware support for this format.</li>
<li>The TensorFloat-32<sup id="cite_ref-Kharya_2020_38-0" class="reference"><a href="#cite_note-Kharya_2020-38"><span class="cite-bracket">&#91;</span>31<span class="cite-bracket">&#93;</span></a></sup> format combines the 8 bits of exponent of the Bfloat16 with the 10 bits of trailing significand field of half-precision formats, resulting in a size of 19 bits. This format was introduced by <a href="https://en.wikipedia.org/wiki/Nvidia" title="Nvidia">Nvidia</a>, which provides hardware support for it in the Tensor Cores of its <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit" title="Graphics processing unit">GPUs</a> based on the Nvidia Ampere architecture. The drawback of this format is its size, which is not a power of 2. However, according to Nvidia, this format should only be used internally by hardware to speed up computations, while inputs and outputs should be stored in the 32-bit single-precision IEEE 754 format.<sup id="cite_ref-Kharya_2020_38-1" class="reference"><a href="#cite_note-Kharya_2020-38"><span class="cite-bracket">&#91;</span>31<span class="cite-bracket">&#93;</span></a></sup></li>
<li>The <a href="https://en.wikipedia.org/wiki/Hopper_(microarchitecture)" title="Hopper (microarchitecture)">Hopper</a> architecture GPUs provide two FP8 formats: one with the same numerical range as half-precision (E5M2) and one with higher precision, but less range (E4M3).<sup id="cite_ref-NVIDIA_Hopper_39-0" class="reference"><a href="#cite_note-NVIDIA_Hopper-39"><span class="cite-bracket">&#91;</span>32<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Micikevicius_2022_40-0" class="reference"><a href="#cite_note-Micikevicius_2022-40"><span class="cite-bracket">&#91;</span>33<span class="cite-bracket">&#93;</span></a></sup></li></ul>
<table class="wikitable">
<caption>Bfloat16, TensorFloat-32, and the two FP8 formats, compared with IEEE&#160;754 half-precision and single-precision formats
</caption>
<tbody><tr>
<th>Type
</th>
<th>Sign
</th>
<th>Exponent
</th>
<th>Trailing significand field
</th>
<th>Total bits
</th></tr>
<tr>
<td>FP8 (E4M3)
</td>
<td>1
</td>
<td>4
</td>
<td>3
</td>
<td>8
</td></tr>
<tr>
<td>FP8 (E5M2)
</td>
<td>1
</td>
<td>5
</td>
<td>2
</td>
<td>8
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format" title="Half-precision floating-point format">Half-precision</a>
</td>
<td>1
</td>
<td>5
</td>
<td>10
</td>
<td>16
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Bfloat16_floating-point_format" title="Bfloat16 floating-point format">Bfloat16</a>
</td>
<td>1
</td>
<td>8
</td>
<td>7
</td>
<td>16
</td></tr>
<tr>
<td>TensorFloat-32
</td>
<td>1
</td>
<td>8
</td>
<td>10
</td>
<td>19
</td></tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" title="Single-precision floating-point format">Single-precision</a>
</td>
<td>1
</td>
<td>8
</td>
<td>23
</td>
<td>32
</td></tr></tbody></table>
<div class="mw-heading mw-heading2"><h2 id="Representable_numbers,_conversion_and_rounding"><span id="Representable_numbers.2C_conversion_and_rounding"></span>Representable numbers, conversion and rounding <span class="anchor" id="Representable_numbers"></span></h2></span></div>
<p>By their nature, all numbers expressed in floating-point format are <a href="https://en.wikipedia.org/wiki/Rational_number" title="Rational number">rational numbers</a> with a terminating expansion in the relevant base (for example, a terminating decimal expansion in base-10, or a terminating binary expansion in base-2). Irrational numbers, such as <a href="https://en.wikipedia.org/wiki/Pi" title="Pi">π</a> or √2, or non-terminating rational numbers, must be approximated. The number of digits (or bits) of precision also limits the set of rational numbers that can be represented exactly. For example, the decimal number 123456789 cannot be exactly represented if only eight decimal digits of precision are available (it would be rounded to one of the two straddling representable values, 12345678&#160;×&#160;10<sup>1</sup> or 12345679&#160;×&#160;10<sup>1</sup>), the same applies to <a href="https://en.wikipedia.org/wiki/Repeating_decimal" title="Repeating decimal">non-terminating digits</a> (.<span style="text-decoration:overline;">5</span> to be rounded to either .55555555 or .55555556).
</p><p>When a number is represented in some format (such as a character string) which is not a native floating-point representation supported in a computer implementation, then it will require a conversion before it can be used in that implementation. If the number can be represented exactly in the floating-point format then the conversion is exact. If there is not an exact representation then the conversion requires a choice of which floating-point number to use to represent the original value. The representation chosen will have a different value from the original, and the value thus adjusted is called the <i>rounded value</i>.
</p><p>Whether or not a rational number has a terminating expansion depends on the base. For example, in base-10 the number 1/2 has a terminating expansion (0.5) while the number 1/3 does not (0.333...). In base-2 only rationals with denominators that are powers of 2 (such as 1/2 or 3/16) are terminating. Any rational with a denominator that has a prime factor other than 2 will have an infinite binary expansion. This means that numbers that appear to be short and exact when written in decimal format may need to be approximated when converted to binary floating-point. For example, the decimal number 0.1 is not representable in binary floating-point of any finite precision;  the exact binary representation would have a "1100" sequence continuing endlessly:
</p>
<dl><dd><i>e</i> = −4; <i>s</i> = 1100110011001100110011001100110011...,</dd></dl>
<p>where, as previously, <i>s</i> is the significand and <i>e</i> is the exponent.
</p><p>When rounded to 24 bits this becomes
</p>
<dl><dd><i>e</i> = −4; <i>s</i> = 110011001100110011001101,</dd></dl>
<p>which is actually 0.100000001490116119384765625 in decimal.
</p><p>As a further example, the real number <a href="https://en.wikipedia.org/wiki/Pi" title="Pi">π</a>, represented in binary as an infinite sequence of bits is
</p>
<dl><dd>11.0010010000111111011010101000100010000101101000110000100011010011...</dd></dl>
<p>but is
</p>
<dl><dd>11.0010010000111111011011</dd></dl>
<p>when approximated by <a href="https://en.wikipedia.org/wiki/Rounding" title="Rounding">rounding</a> to a precision of 24 bits.
</p><p>In binary single-precision floating-point, this is represented as <i>s</i>&#160;=&#160;1.10010010000111111011011 with <i>e</i>&#160;=&#160;1.
This has a decimal value of
</p>
<dl><dd><b>3.141592</b>7410125732421875,</dd></dl>
<p>whereas a more accurate approximation of the true value of π is
</p>
<dl><dd><b>3.14159265358979323846264338327950</b>...</dd></dl>
<p>The result of rounding differs from the true value by about 0.03 parts per million, and matches the decimal representation of π in the first 7 digits. The difference is the <a href="https://en.wikipedia.org/wiki/Discretization_error" title="Discretization error">discretization error</a> and is limited by the <a href="https://en.wikipedia.org/wiki/Machine_epsilon" title="Machine epsilon">machine epsilon</a>.
</p><p>The arithmetical difference between two consecutive representable floating-point numbers which have the same exponent is called a <a href="https://en.wikipedia.org/wiki/Unit_in_the_last_place" title="Unit in the last place">unit in the last place</a> (ULP). For example, if there is no representable number lying between the representable numbers 1.45a70c22<sub>hex</sub> and 1.45a70c24<sub>hex</sub>, the ULP is 2×16<sup>−8</sup>, or 2<sup>−31</sup>. For numbers with a base-2 exponent part of 0, i.e. numbers with an absolute value higher than or equal to 1 but lower than 2, an ULP is exactly 2<sup>−23</sup> or about 10<sup>−7</sup> in single precision, and exactly 2<sup>−53</sup> or about 10<sup>−16</sup> in double precision. The mandated behavior of IEEE-compliant hardware is that the result be within one-half of a ULP.
</p>
<div class="mw-heading mw-heading3"><h3 id="Rounding_modes">Rounding modes</h3></span></div>
<p>Rounding is used when the exact result of a floating-point operation (or a conversion to floating-point format) would need more digits than there are digits in the significand. IEEE 754 requires <i>correct rounding</i>: that is, the rounded result is as if infinitely precise arithmetic was used to compute the value and then rounded (although in implementation only three extra bits are needed to ensure this). There are several different <a href="https://en.wikipedia.org/wiki/Rounding" title="Rounding">rounding</a> schemes (or <i>rounding modes</i>). Historically, <a href="https://en.wikipedia.org/wiki/Truncation" title="Truncation">truncation</a> was the typical approach. Since the introduction of IEEE 754, the default method (<i><a href="https://en.wikipedia.org/wiki/Rounding" title="Rounding">round to nearest, ties to even</a></i>, sometimes called Banker's Rounding) is more commonly used. This method rounds the ideal (infinitely precise) result of an arithmetic operation to the nearest representable value, and gives that representation as the result.<sup id="cite_ref-NB_1_41-0" class="reference"><a href="#cite_note-NB_1-41"><span class="cite-bracket">&#91;</span>nb 8<span class="cite-bracket">&#93;</span></a></sup> In the case of a tie, the value that would make the significand end in an even digit is chosen. The IEEE 754 standard requires the same rounding to be applied to all fundamental algebraic operations, including square root and conversions, when there is a numeric (non-NaN) result. It means that the results of IEEE 754 operations are completely determined in all bits of the result, except for the representation of NaNs. ("Library" functions such as cosine and log are not mandated.)
</p><p>Alternative rounding options are also available. IEEE 754 specifies the following rounding modes:
</p>
<ul><li>round to nearest, where ties round to the nearest even digit in the required position (the default and by far the most common mode)</li>
<li>round to nearest, where ties round away from zero (optional for binary floating-point and commonly used in decimal)</li>
<li>round up (toward +∞; negative results thus round toward zero)</li>
<li>round down (toward −∞; negative results thus round away from zero)</li>
<li>round toward zero (truncation; it is similar to the common behavior of float-to-integer conversions, which convert −3.9 to −3 and 3.9 to 3)</li></ul>
<p>Alternative modes are useful when the amount of error being introduced must be bounded. Applications that require a bounded error are multi-precision floating-point, and <a href="https://en.wikipedia.org/wiki/Interval_arithmetic" title="Interval arithmetic">interval arithmetic</a>.
The alternative rounding modes are also useful in diagnosing numerical instability: if the results of a subroutine vary substantially between rounding to + and − infinity then it is likely numerically unstable and affected by round-off error.<sup id="cite_ref-Kahan_2006_Mindless_42-0" class="reference"><a href="#cite_note-Kahan_2006_Mindless-42"><span class="cite-bracket">&#91;</span>34<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Binary-to-decimal_conversion_with_minimal_number_of_digits">Binary-to-decimal conversion with minimal number of digits</h3></span></div>
<p>Converting a double-precision binary floating-point number to a decimal string is a common operation, but an algorithm producing results that are both accurate and minimal did not appear in print until 1990, with Steele and White's Dragon4. Some of the improvements since then include:
</p>
<ul><li>David M. Gay's <i>dtoa.c</i>, a practical open-source implementation of many ideas in Dragon4.<sup id="cite_ref-Gay_1990_43-0" class="reference"><a href="#cite_note-Gay_1990-43"><span class="cite-bracket">&#91;</span>35<span class="cite-bracket">&#93;</span></a></sup></li>
<li>Grisu3, with a 4&#215; speedup as it removes the use of <a href="https://en.wikipedia.org/wiki/Bignum" class="mw-redirect" title="Bignum">bignums</a>. Must be used with a fallback, as it fails for ~0.5% of cases.<sup id="cite_ref-Loitsch_2010_44-0" class="reference"><a href="#cite_note-Loitsch_2010-44"><span class="cite-bracket">&#91;</span>36<span class="cite-bracket">&#93;</span></a></sup></li>
<li>Errol3, an always-succeeding algorithm similar to, but slower than, Grisu3. Apparently not as good as an early-terminating Grisu with fallback.<sup id="cite_ref-mazong_45-0" class="reference"><a href="#cite_note-mazong-45"><span class="cite-bracket">&#91;</span>37<span class="cite-bracket">&#93;</span></a></sup></li>
<li>Ryū, an always-succeeding algorithm that is faster and simpler than Grisu3.<sup id="cite_ref-Adams_2018_46-0" class="reference"><a href="#cite_note-Adams_2018-46"><span class="cite-bracket">&#91;</span>38<span class="cite-bracket">&#93;</span></a></sup></li>
<li>Schubfach, an always-succeeding algorithm that is based on a similar idea to Ryū, developed almost simultaneously and independently.<sup id="cite_ref-Giulietti_47-0" class="reference"><a href="#cite_note-Giulietti-47"><span class="cite-bracket">&#91;</span>39<span class="cite-bracket">&#93;</span></a></sup> Performs better than Ryū and Grisu3 in certain benchmarks.<sup id="cite_ref-abolz_48-0" class="reference"><a href="#cite_note-abolz-48"><span class="cite-bracket">&#91;</span>40<span class="cite-bracket">&#93;</span></a></sup></li></ul>
<p>Many modern language runtimes use Grisu3 with a Dragon4 fallback.<sup id="cite_ref-double_conversion_2020_49-0" class="reference"><a href="#cite_note-double_conversion_2020-49"><span class="cite-bracket">&#91;</span>41<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading3"><h3 id="Decimal-to-binary_conversion">Decimal-to-binary conversion</h3></span></div>
<p>The problem of parsing a decimal string into a binary FP representation is complex, with an accurate parser not appearing until Clinger's 1990 work (implemented in dtoa.c).<sup id="cite_ref-Gay_1990_43-1" class="reference"><a href="#cite_note-Gay_1990-43"><span class="cite-bracket">&#91;</span>35<span class="cite-bracket">&#93;</span></a></sup> Further work has likewise progressed in the direction of faster parsing.<sup id="cite_ref-Lemire_2021_50-0" class="reference"><a href="#cite_note-Lemire_2021-50"><span class="cite-bracket">&#91;</span>42<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="Floating-point_operations">Floating-point operations</h2></span></div>
<p>For ease of presentation and understanding, decimal <a href="https://en.wikipedia.org/wiki/Radix" title="Radix">radix</a> with 7 digit precision will be used in the examples, as in the IEEE 754 <i>decimal32</i> format. The fundamental principles are the same in any <a href="https://en.wikipedia.org/wiki/Radix" title="Radix">radix</a> or precision, except that normalization is optional (it does not affect the numerical value of the result). Here, <i>s</i> denotes the significand and <i>e</i> denotes the exponent.
</p>
<div class="mw-heading mw-heading3"><h3 id="Addition_and_subtraction">Addition and subtraction</h3></span></div>
<p>A simple method to add floating-point numbers is to first represent them with the same exponent. In the example below, the second number is shifted right by three digits, and one then proceeds with the usual addition method:
</p>
<pre>  123456.7 = 1.234567 × 10^5
  101.7654 = 1.017654 × 10^2 = 0.001017654 × 10^5
</pre>
<pre>  Hence:
  123456.7 + 101.7654 = (1.234567 × 10^5) + (1.017654 × 10^2)
                      = (1.234567 × 10^5) + (0.001017654 × 10^5)
                      = (1.234567 + 0.001017654) × 10^5
                      =  1.235584654 × 10^5
</pre>
<p>In detail:
</p>
<pre>  e=5;  s=1.234567     (123456.7)
+ e=2;  s=1.017654     (101.7654)
</pre>
<pre>  e=5;  s=1.234567
+ e=5;  s=0.001017654  (after shifting)
--------------------
  e=5;  s=1.235584654  (true sum: 123558.4654)
</pre>
<p>This is the true result, the exact sum of the operands. It will be rounded to seven digits and then normalized if necessary. The final result is
</p>
<pre>  e=5;  s=1.235585    (final sum: 123558.5)
</pre>
<p>The lowest three digits of the second operand (654) are essentially lost. This is <a href="https://en.wikipedia.org/wiki/Round-off_error" title="Round-off error">round-off error</a>. In extreme cases, the sum of two non-zero numbers may be equal to one of them:
</p>
<pre>  e=5;  s=1.234567
+ e=−3; s=9.876543
</pre>
<pre>  e=5;  s=1.234567
+ e=5;  s=0.00000009876543 (after shifting)
----------------------
  e=5;  s=1.23456709876543 (true sum)
  e=5;  s=1.234567         (after rounding and normalization)
</pre>
<p>In the above conceptual examples it would appear that a large number of extra digits would need to be provided by the adder to ensure correct rounding; however, for binary addition or subtraction using careful implementation techniques only a <i>guard</i> bit, a <i>rounding</i> bit and one extra <i>sticky</i> bit need to be carried beyond the precision of the operands.<sup id="cite_ref-Goldberg_1991_51-0" class="reference"><a href="#cite_note-Goldberg_1991-51"><span class="cite-bracket">&#91;</span>43<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Patterson-Hennessy_2014_52-0" class="reference"><a href="#cite_note-Patterson-Hennessy_2014-52"><span class="cite-bracket">&#91;</span>44<span class="cite-bracket">&#93;</span></a></sup><sup class="reference nowrap"><span title="Page / location: 218–220">&#58;&#8202;218–220&#8202;</span></sup>
</p><p>Another problem of loss of significance occurs when <i>approximations</i> to two nearly equal numbers are subtracted. In the following example <i>e</i>&#160;=&#160;5; <i>s</i>&#160;=&#160;1.234571 and <i>e</i>&#160;=&#160;5; <i>s</i>&#160;=&#160;1.234567 are approximations to the rationals 123457.1467 and 123456.659.
</p>
<pre>  e=5;  s=1.234571
− e=5;  s=1.234567
----------------
  e=5;  s=0.000004
  e=−1; s=4.000000 (after rounding and normalization)
</pre>
<p>The floating-point difference is computed exactly because the numbers are close—the <a href="https://en.wikipedia.org/wiki/Sterbenz_lemma" title="Sterbenz lemma">Sterbenz lemma</a> guarantees this, even in case of underflow when <a href="https://en.wikipedia.org/wiki/Gradual_underflow" class="mw-redirect" title="Gradual underflow">gradual underflow</a> is supported. Despite this, the difference of the original numbers is <i>e</i>&#160;=&#160;−1; <i>s</i>&#160;=&#160;4.877000, which differs more than 20% from the difference <i>e</i>&#160;=&#160;−1; <i>s</i>&#160;=&#160;4.000000 of the approximations. In extreme cases, all significant digits of precision can be lost.<sup id="cite_ref-Goldberg_1991_51-1" class="reference"><a href="#cite_note-Goldberg_1991-51"><span class="cite-bracket">&#91;</span>43<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Sierra_1962_53-0" class="reference"><a href="#cite_note-Sierra_1962-53"><span class="cite-bracket">&#91;</span>45<span class="cite-bracket">&#93;</span></a></sup> This <i><a href="https://en.wikipedia.org/wiki/Catastrophic_cancellation" title="Catastrophic cancellation">cancellation</a></i> illustrates the danger in assuming that all of the digits of a computed result are meaningful. Dealing with the consequences of these errors is a topic in <a href="https://en.wikipedia.org/wiki/Numerical_analysis" title="Numerical analysis">numerical analysis</a>; see also <a href="#Accuracy_problems">Accuracy problems</a>.
</p>
<div class="mw-heading mw-heading3"><h3 id="Multiplication_and_division">Multiplication and division</h3></span></div>
<p>To multiply, the significands are multiplied while the exponents are added, and the result is rounded and normalized.
</p>
<pre>  e=3;  s=4.734612
× e=5;  s=5.417242
-----------------------
  e=8;  s=25.648538980104 (true product)
  e=8;  s=25.64854        (after rounding)
  e=9;  s=2.564854        (after normalization)
</pre>
<p>Similarly, division is accomplished by subtracting the divisor's exponent from the dividend's exponent, and dividing the dividend's significand by the divisor's significand.
</p><p>There are no cancellation or absorption problems with multiplication or division, though small errors may accumulate as operations are performed in succession.<sup id="cite_ref-Goldberg_1991_51-2" class="reference"><a href="#cite_note-Goldberg_1991-51"><span class="cite-bracket">&#91;</span>43<span class="cite-bracket">&#93;</span></a></sup> In practice, the way these operations are carried out in digital logic can be quite complex (see <a href="https://en.wikipedia.org/wiki/Booth%27s_multiplication_algorithm" title="Booth&#39;s multiplication algorithm">Booth's multiplication algorithm</a> and <a href="https://en.wikipedia.org/wiki/Division_algorithm" title="Division algorithm">Division algorithm</a>).<sup id="cite_ref-NB_2_54-0" class="reference"><a href="#cite_note-NB_2-54"><span class="cite-bracket">&#91;</span>nb 9<span class="cite-bracket">&#93;</span></a></sup>
For a fast, simple method, see the <a href="https://en.wikipedia.org/wiki/Horner_scheme#Floating_point_multiplication_and_division" class="mw-redirect" title="Horner scheme">Horner method</a>.
</p>
<div class="mw-heading mw-heading3"><h3 id="Literal_syntax">Literal syntax</h3></span></div>
<p>Literals for floating-point numbers depend on languages. They typically use <code>e</code> or <code>E</code> to denote <a href="https://en.wikipedia.org/wiki/Scientific_notation" title="Scientific notation">scientific notation</a>. The <a href="https://en.wikipedia.org/wiki/C_(programming_language)" title="C (programming language)">C programming language</a> and the <a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a> standard also define a <a href="https://en.wikipedia.org/wiki/IEEE_754#Hexadecimal_literals" title="IEEE 754">hexadecimal literal syntax</a> with a base-2 exponent instead of 10. In languages like <a href="https://en.wikipedia.org/wiki/C_(programming_language)" title="C (programming language)">C</a>, when the decimal exponent is omitted, a decimal point is needed to differentiate them from integers. Other languages do not have an integer type (such as <a href="https://en.wikipedia.org/wiki/JavaScript" title="JavaScript">JavaScript</a>), or allow overloading of numeric types (such as <a href="https://en.wikipedia.org/wiki/Haskell_(programming_language)" class="mw-redirect" title="Haskell (programming language)">Haskell</a>). In these cases, digit strings such as <code>123</code> may also be floating-point literals.
</p><p>Examples of floating-point literals are:
</p>
<ul><li><code>99.9</code></li>
<li><code>-5000.12</code></li>
<li><code>6.02e23</code></li>
<li><code>-3e-45</code></li>
<li><code>0x1.fffffep+127</code> in C and IEEE 754</li></ul>
<div class="mw-heading mw-heading2"><h2 id="Dealing_with_exceptional_cases">Dealing with exceptional cases <span class="anchor" id="Floating_point_exception"></span><span class="anchor" id="Exception_handling"></span></h2></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1236090951"><div role="note" class="hatnote navigation-not-searchable">Further information: <a href="https://en.wikipedia.org/wiki/IEEE_754#Exception_handling" title="IEEE 754">IEEE 754 §&#160;Exception handling</a></div>
<p>Floating-point computation in a computer can run into three kinds of problems:
</p>
<ul><li>An operation can be mathematically undefined, such as ∞/∞, or <a href="https://en.wikipedia.org/wiki/Division_by_zero" title="Division by zero">division by zero</a>.</li>
<li>An operation can be legal in principle, but not supported by the specific format, for example, calculating the <a href="https://en.wikipedia.org/wiki/Square_root" title="Square root">square root</a> of −1 or the inverse sine of 2 (both of which result in <a href="https://en.wikipedia.org/wiki/Complex_number" title="Complex number">complex numbers</a>).</li>
<li>An operation can be legal in principle, but the result can be impossible to represent in the specified format, because the exponent is too large or too small to encode in the exponent field. Such an event is called an overflow (exponent too large), <a href="https://en.wikipedia.org/wiki/Arithmetic_underflow" title="Arithmetic underflow">underflow</a> (exponent too small) or <a href="https://en.wikipedia.org/wiki/Subnormal_number" title="Subnormal number">denormalization</a> (precision loss).</li></ul>
<p>Prior to the IEEE standard, such conditions usually caused the program to terminate, or triggered some kind of <a href="https://en.wikipedia.org/wiki/Trap_(computing)" class="mw-redirect" title="Trap (computing)">trap</a> that the programmer might be able to catch. How this worked was system-dependent, meaning that floating-point programs were not <a href="https://en.wikipedia.org/wiki/Porting" title="Porting">portable</a>. (The term "exception" as used in IEEE 754 is a general term meaning an exceptional condition, which is not necessarily an error, and is a different usage to that typically defined in programming languages such as a C++ or Java, in which an "<a href="https://en.wikipedia.org/wiki/Exception_handling" title="Exception handling">exception</a>" is an alternative flow of control, closer to what is termed a "trap" in IEEE 754 terminology.)
</p><p>Here, the required default method of handling exceptions according to IEEE 754 is discussed (the IEEE 754 optional trapping and other "alternate exception handling" modes are not discussed). Arithmetic exceptions are (by default) required to be recorded in "sticky" status flag bits. That they are "sticky" means that they are not reset by the next (arithmetic) operation, but stay set until explicitly reset. The use of "sticky" flags thus allows for testing of exceptional conditions to be delayed until after a full floating-point expression or subroutine: without them exceptional conditions that could not be otherwise ignored would require explicit testing immediately after every floating-point operation. By default, an operation always returns a result according to specification without interrupting computation. For instance, 1/0 returns +∞, while also setting the divide-by-zero flag bit (this default of ∞ is designed to often return a finite result when used in subsequent operations and so be safely ignored).
</p><p>The original IEEE 754 standard, however, failed to recommend operations to handle such sets of arithmetic exception flag bits. So while these were implemented in hardware, initially programming language implementations typically did not provide a means to access them (apart from assembler). Over time some programming language standards (e.g., <a href="https://en.wikipedia.org/wiki/C99" title="C99">C99</a>/C11 and Fortran) have been updated to specify methods to access and change status flag bits. The 2008 version of the IEEE 754 standard now specifies a few operations for accessing and handling the arithmetic flag bits. The programming model is based on a single thread of execution and use of them by multiple threads has to be handled by a <a href="https://en.wikipedia.org/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">means</a> outside of the standard (e.g. <a href="https://en.wikipedia.org/wiki/C11_(C_standard_revision)" title="C11 (C standard revision)">C11</a> specifies that the flags have <a href="https://en.wikipedia.org/wiki/Thread-local_storage" title="Thread-local storage">thread-local storage</a>).
</p><p>IEEE 754 specifies five arithmetic exceptions that are to be recorded in the status flags ("sticky bits"):
</p>
<ul><li><b>inexact</b>, set if the rounded (and returned) value is different from the mathematically exact result of the operation.</li>
<li><b>underflow</b>, set if the rounded value is tiny (as specified in IEEE 754) <i>and</i> inexact (or maybe limited to if it has denormalization loss, as per the 1985 version of IEEE 754), returning a subnormal value including the zeros.</li>
<li><b>overflow</b>, set if the absolute value of the rounded value is too large to be represented. An infinity or maximal finite value is returned, depending on which rounding is used.</li>
<li><b>divide-by-zero</b>, set if the result is infinite given finite operands, returning an infinity, either +∞ or −∞.</li>
<li><b>invalid</b>, set if a real-valued result cannot be returned e.g. sqrt(−1) or 0/0, returning a quiet NaN.</li></ul>
<figure class="mw-halign-left" typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Resistors_in_Parallel.svg" class="mw-file-description"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Resistors_in_Parallel.svg/200px-Resistors_in_Parallel.svg.png" decoding="async" width="200" height="80" class="mw-file-element" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Resistors_in_Parallel.svg/300px-Resistors_in_Parallel.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Resistors_in_Parallel.svg/400px-Resistors_in_Parallel.svg.png 2x" data-file-width="300" data-file-height="120" /></a><figcaption>Fig. 1: resistances in parallel, with total resistance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle R_{tot}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>R</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mi>o</mi>
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle R_{tot}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db9ad2846f85f109dcfaaa60106f69304ff2377" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:3.981ex; height:2.509ex;" alt="{\displaystyle R_{tot}}"></span></figcaption></figure><p>The default return value for each of the exceptions is designed to give the correct result in the majority of cases such that the exceptions can be ignored in the majority of codes. <i>inexact</i> returns a correctly rounded result, and <i>underflow</i> returns a value less than or equal to the smallest positive normal number in magnitude and can almost always be ignored.<sup id="cite_ref-Kahan_1997_Status_55-0" class="reference"><a href="#cite_note-Kahan_1997_Status-55"><span class="cite-bracket">&#91;</span>46<span class="cite-bracket">&#93;</span></a></sup> <i>divide-by-zero</i> returns infinity exactly, which will typically then divide a finite number and so give zero, or else will give an <i>invalid</i> exception subsequently if not, and so can also typically be ignored. For example, the effective resistance of n resistors in parallel (see fig. 1) is given by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle R_{\text{tot}}=1/(1/R_{1}+1/R_{2}+\cdots +1/R_{n})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>R</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>tot</mtext>
          </mrow>
        </msub>
        <mo>=</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <msub>
          <mi>R</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>+</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <msub>
          <mi>R</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msub>
        <mo>+</mo>
        <mo>&#x22EF;<!-- ⋯ --></mo>
        <mo>+</mo>
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <msub>
          <mi>R</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle R_{\text{tot}}=1/(1/R_{1}+1/R_{2}+\cdots +1/R_{n})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cd57a135e4c4097f3aac012da434c472b1fbe90b" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:38.168ex; height:2.843ex;" alt="{\displaystyle R_{\text{tot}}=1/(1/R_{1}+1/R_{2}+\cdots +1/R_{n})}"></span>. If a short-circuit develops with <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle R_{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>R</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle R_{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c1d63c96f59d98589d923c4f0b04222feaa7283e" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:2.818ex; height:2.509ex;" alt="{\displaystyle R_{1}}"></span> set to 0, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 1/R_{1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>1</mn>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <msub>
          <mi>R</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 1/R_{1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e6e4aaeaef2ceb43e4b429f07d7bfd798d3db831" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:5.143ex; height:2.843ex;" alt="{\displaystyle 1/R_{1}}"></span> will return +infinity which will give a final <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle R_{tot}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>R</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>t</mi>
            <mi>o</mi>
            <mi>t</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle R_{tot}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db9ad2846f85f109dcfaaa60106f69304ff2377" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:3.981ex; height:2.509ex;" alt="{\displaystyle R_{tot}}"></span> of 0, as expected<sup id="cite_ref-Intel_56-0" class="reference"><a href="#cite_note-Intel-56"><span class="cite-bracket">&#91;</span>47<span class="cite-bracket">&#93;</span></a></sup> (see the continued fraction example of <a href="https://en.wikipedia.org/wiki/Floating_point#IEEE_754:_floating_point_in_modern_computers" class="mw-redirect" title="Floating point">IEEE 754 design rationale</a> for another example).
</p><p><i>Overflow</i> and <i>invalid</i> exceptions can typically not be ignored, but do not necessarily represent errors: for example, a <a href="https://en.wikipedia.org/wiki/Zero_of_a_function" title="Zero of a function">root-finding</a> routine, as part of its normal operation, may evaluate a passed-in function at values outside of its domain, returning NaN and an <i>invalid</i> exception flag to be ignored until finding a useful start point.<sup id="cite_ref-Kahan_1997_Status_55-1" class="reference"><a href="#cite_note-Kahan_1997_Status-55"><span class="cite-bracket">&#91;</span>46<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="Accuracy_problems">Accuracy problems</h2></span></div>
<p>The fact that floating-point numbers cannot accurately represent all real numbers, and that floating-point operations cannot accurately represent true arithmetic operations, leads to many surprising situations. This is related to the finite <a href="https://en.wikipedia.org/wiki/Precision_(computer_science)" title="Precision (computer science)">precision</a> with which computers generally represent numbers.
</p><p>For example, the decimal numbers 0.1 and 0.01 cannot be represented exactly as binary floating-point numbers. In the IEEE 754 binary32 format with its 24-bit significand, the result of attempting to square the approximation to 0.1 is neither 0.01 nor the representable number closest to it. The decimal number 0.1 is represented in binary as <span class="texhtml"><var style="padding-right: 1px;">e</var>&#160;=&#160;−4</span>; <span class="texhtml"><var style="padding-right: 1px;">s</var>&#160;=&#160;110011001100110011001101</span>, which is
</p>
<style data-mw-deduplicate="TemplateStyles:r996643573">.mw-parser-output .block-indent{padding-left:3em;padding-right:0;overflow:hidden}</style><div class="block-indent">0.100000001490116119384765625 exactly.</div>
<p>Squaring this number gives
</p>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r996643573"><div class="block-indent">0.010000000298023226097399174250313080847263336181640625 exactly.</div>
<p>Squaring it with rounding to the 24-bit precision gives
</p>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r996643573"><div class="block-indent">0.010000000707805156707763671875 exactly.</div>
<p>But the representable number closest to 0.01 is
</p>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r996643573"><div class="block-indent">0.009999999776482582092285156250 exactly.</div>
<p>Also, the non-representability of π (and π/2) means that an attempted computation of tan(π/2) will not yield a result of infinity, nor will it even overflow in the usual floating-point formats (assuming an accurate implementation of tan). It is simply not possible for standard floating-point hardware to attempt to compute tan(π/2), because π/2 cannot be represented exactly. This computation in C:
</p>
<div class="mw-highlight mw-highlight-lang-c mw-content-ltr" dir="ltr"><pre><span></span><span class="cm">/* Enough digits to be sure we get the correct approximation. */</span>
<span class="kt">double</span><span class="w"> </span><span class="n">pi</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">3.1415926535897932384626433832795</span><span class="p">;</span>
<span class="kt">double</span><span class="w"> </span><span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tan</span><span class="p">(</span><span class="n">pi</span><span class="o">/</span><span class="mf">2.0</span><span class="p">);</span>
</pre></div>
<p>will give a result of 16331239353195370.0. In single precision (using the <code>tanf</code> function), the result will be −22877332.0.
</p><p>By the same token, an attempted computation of sin(π) will not yield zero. The result will be (approximately) 0.1225<span style="margin:0 .15em 0 .25em">×</span>10<sup>−15</sup> in double precision, or −0.8742<span style="margin:0 .15em 0 .25em">×</span>10<sup>−7</sup> in single precision.<sup id="cite_ref-NB_3_57-0" class="reference"><a href="#cite_note-NB_3-57"><span class="cite-bracket">&#91;</span>nb 10<span class="cite-bracket">&#93;</span></a></sup>
</p><p>While floating-point addition and multiplication are both <a href="https://en.wikipedia.org/wiki/Commutative" class="mw-redirect" title="Commutative">commutative</a> (<span class="texhtml"><var style="padding-right: 1px;">a</var> + <var style="padding-right: 1px;">b</var> = <var style="padding-right: 1px;">b</var> + <var style="padding-right: 1px;">a</var></span> and <span class="texhtml"><var style="padding-right: 1px;">a</var> × <var style="padding-right: 1px;">b</var> = <var style="padding-right: 1px;">b</var> × <var style="padding-right: 1px;">a</var></span>), they are not necessarily <a href="https://en.wikipedia.org/wiki/Associative_property" title="Associative property">associative</a>. That is, <span class="texhtml">(<var style="padding-right: 1px;">a</var> + <var style="padding-right: 1px;">b</var>) + <var style="padding-right: 1px;">c</var></span> is not necessarily equal to <span class="texhtml"><var style="padding-right: 1px;">a</var> + (<var style="padding-right: 1px;">b</var> + <var style="padding-right: 1px;">c</var>)</span>. Using 7-digit significand decimal arithmetic:
</p>
<pre> a = 1234.567, b = 45.67834, c = 0.0004
</pre>
<pre> (a + b) + c:
     1234.567   (a)
   +   45.67834 (b)
   ____________
     1280.24534   rounds to   1280.245
</pre>
<pre>    1280.245  (a + b)
   +   0.0004 (c)
   ____________
    1280.2454   rounds to   <b>1280.245</b>  ← (a + b) + c
</pre>
<pre> a + (b + c):
   45.67834 (b)
 +  0.0004  (c)
 ____________
   45.67874
</pre>
<pre>   1234.567   (a)
 +   45.67874   (b + c)
 ____________
   1280.24574   rounds to   <b>1280.246</b> ← a + (b + c)
</pre>
<p>They are also not necessarily <a href="https://en.wikipedia.org/wiki/Distributive_property" title="Distributive property">distributive</a>. That is, <span class="texhtml">(<var style="padding-right: 1px;">a</var> + <var style="padding-right: 1px;">b</var>) × <var style="padding-right: 1px;">c</var></span> may not be the same as <span class="texhtml"><var style="padding-right: 1px;">a</var> × <var style="padding-right: 1px;">c</var> + <var style="padding-right: 1px;">b</var> × <var style="padding-right: 1px;">c</var></span>:
</p>
<pre> 1234.567 × 3.333333 = 4115.223
 1.234567 × 3.333333 = 4.115223
                       4115.223 + 4.115223 = 4119.338
 but
 1234.567 + 1.234567 = 1235.802
                       1235.802 × 3.333333 = 4119.340
</pre>
<p>In addition to loss of significance, inability to represent numbers such as π and 0.1 exactly, and other slight inaccuracies, the following phenomena may occur:
</p>
<div><ul><li><a href="https://en.wikipedia.org/wiki/Catastrophic_cancellation" title="Catastrophic cancellation">Cancellation</a>: subtraction of nearly equal operands may cause extreme loss of accuracy.<sup id="cite_ref-Harris_58-0" class="reference"><a href="#cite_note-Harris-58"><span class="cite-bracket">&#91;</span>48<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Sierra_1962_53-1" class="reference"><a href="#cite_note-Sierra_1962-53"><span class="cite-bracket">&#91;</span>45<span class="cite-bracket">&#93;</span></a></sup> When we subtract two almost equal numbers we set the most significant digits to zero, leaving ourselves with just the insignificant, and most erroneous, digits.<sup id="cite_ref-Muller_2010_1-5" class="reference"><a href="#cite_note-Muller_2010-1"><span class="cite-bracket">&#91;</span>1<span class="cite-bracket">&#93;</span></a></sup><sup class="reference nowrap"><span title="Page / location: 124">&#58;&#8202;124&#8202;</span></sup> For example, when determining a <a href="https://en.wikipedia.org/wiki/Derivative" title="Derivative">derivative</a> of a function the following formula is used:
<p><span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle Q(h)={\frac {f(a+h)-f(a)}{h}}.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Q</mi>
        <mo stretchy="false">(</mo>
        <mi>h</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>f</mi>
              <mo stretchy="false">(</mo>
              <mi>a</mi>
              <mo>+</mo>
              <mi>h</mi>
              <mo stretchy="false">)</mo>
              <mo>&#x2212;<!-- − --></mo>
              <mi>f</mi>
              <mo stretchy="false">(</mo>
              <mi>a</mi>
              <mo stretchy="false">)</mo>
            </mrow>
            <mi>h</mi>
          </mfrac>
        </mrow>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Q(h)={\frac {f(a+h)-f(a)}{h}}.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bb3cb4002e059cfdbf6e76b86efc59519ee208d3" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.005ex; width:25.223ex; height:5.843ex;" alt="{\displaystyle Q(h)={\frac {f(a+h)-f(a)}{h}}.}"></span>
</p>
Intuitively one would want an <span class="texhtml"><var style="padding-right: 1px;">h</var></span> very close to zero; however, when using floating-point operations, the smallest number will not give the best approximation of a derivative. As <span class="texhtml"><var style="padding-right: 1px;">h</var></span> grows smaller, the difference between <span class="texhtml"><var style="padding-right: 1px;">f</var>(<var style="padding-right: 1px;">a</var> + <var style="padding-right: 1px;">h</var>)</span> and <span class="texhtml"><var style="padding-right: 1px;">f</var>(<var style="padding-right: 1px;">a</var>)</span> grows smaller, cancelling out the most significant and least erroneous digits and making the most erroneous digits more important. As a result the smallest number of <span class="texhtml"><var style="padding-right: 1px;">h</var></span> possible will give a more erroneous approximation of a derivative than a somewhat larger number. This is perhaps the most common and serious accuracy problem.</li><li>Conversions to integer are not intuitive: converting (63.0/9.0) to integer yields 7, but converting (0.63/0.09) may yield 6. This is because conversions generally truncate rather than round. <a href="https://en.wikipedia.org/wiki/Floor_and_ceiling_functions" title="Floor and ceiling functions">Floor and ceiling functions</a> may produce answers which are off by one from the intuitively expected value.</li><li>Limited exponent range: results might overflow yielding infinity, or underflow yielding a <a href="https://en.wikipedia.org/wiki/Subnormal_number" title="Subnormal number">subnormal number</a> or zero. In these cases precision will be lost.</li><li>Testing for <a href="https://en.wikipedia.org/wiki/Division_by_zero#Computer_arithmetic" title="Division by zero">safe division</a> is problematic: Checking that the divisor is not zero does not guarantee that a division will not overflow.</li><li>Testing for equality is problematic. Two computational sequences that are mathematically equal may well produce different floating-point values.<sup id="cite_ref-Barker_59-0" class="reference"><a href="#cite_note-Barker-59"><span class="cite-bracket">&#91;</span>49<span class="cite-bracket">&#93;</span></a></sup></li></ul></div>
<div class="mw-heading mw-heading3"><h3 id="Incidents">Incidents</h3></span></div>
<ul><li>On 25 February 1991, a <a href="https://en.wikipedia.org/wiki/Loss_of_significance" class="mw-redirect" title="Loss of significance">loss of significance</a> in a <a href="https://en.wikipedia.org/wiki/MIM-104_Patriot" title="MIM-104 Patriot">MIM-104 Patriot</a> missile battery <a href="https://en.wikipedia.org/wiki/MIM-104_Patriot#Failure_at_Dhahran" title="MIM-104 Patriot">prevented it from intercepting</a> an incoming <a href="https://en.wikipedia.org/wiki/Al_Hussein_(missile)" class="mw-redirect" title="Al Hussein (missile)">Scud</a> missile in <a href="https://en.wikipedia.org/wiki/Dhahran" title="Dhahran">Dhahran</a>, <a href="https://en.wikipedia.org/wiki/Saudi_Arabia" title="Saudi Arabia">Saudi Arabia</a>, contributing to the death of 28 soldiers from the U.S. Army's <a href="https://en.wikipedia.org/wiki/14th_Quartermaster_Detachment" title="14th Quartermaster Detachment">14th Quartermaster Detachment</a>.<sup id="cite_ref-GAO_report_IMTEC_92-26_60-0" class="reference"><a href="#cite_note-GAO_report_IMTEC_92-26-60"><span class="cite-bracket">&#91;</span>50<span class="cite-bracket">&#93;</span></a></sup></li></ul>
<div class="mw-heading mw-heading3"><h3 id="Machine_precision_and_backward_error_analysis">Machine precision and backward error analysis</h3></span></div>
<p><i>Machine precision</i> is a quantity that characterizes the accuracy of a floating-point system, and is used in <a href="https://en.wikipedia.org/wiki/Error_analysis_(mathematics)#Error_analysis_in_numerical_modeling" title="Error analysis (mathematics)">backward error analysis</a> of floating-point algorithms. It is also known as unit roundoff or <i><a href="https://en.wikipedia.org/wiki/Machine_epsilon" title="Machine epsilon">machine epsilon</a></i>. Usually denoted <span class="texhtml"><var style="padding-right: 1px;">Ε</var><sub>mach</sub></span>, its value depends on the particular rounding being used.
</p><p>With rounding to zero,
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathrm {E} _{\text{mach}}=B^{1-P},\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">E</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>mach</mtext>
          </mrow>
        </msub>
        <mo>=</mo>
        <msup>
          <mi>B</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
            <mo>&#x2212;<!-- − --></mo>
            <mi>P</mi>
          </mrow>
        </msup>
        <mo>,</mo>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathrm {E} _{\text{mach}}=B^{1-P},\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/16192cc80058cfea0162debfd31dc11a422b61dd" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:15.113ex; height:3.009ex;" alt="{\displaystyle \mathrm {E} _{\text{mach}}=B^{1-P},\,}"></span>
whereas rounding to nearest,
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathrm {E} _{\text{mach}}={\tfrac {1}{2}}B^{1-P},}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">E</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>mach</mtext>
          </mrow>
        </msub>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mstyle displaystyle="false" scriptlevel="0">
            <mfrac>
              <mn>1</mn>
              <mn>2</mn>
            </mfrac>
          </mstyle>
        </mrow>
        <msup>
          <mi>B</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
            <mo>&#x2212;<!-- − --></mo>
            <mi>P</mi>
          </mrow>
        </msup>
        <mo>,</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathrm {E} _{\text{mach}}={\tfrac {1}{2}}B^{1-P},}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b55346e447384f9497ffbb42d68a91280ec9974" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.171ex; width:16.384ex; height:3.509ex;" alt="{\displaystyle \mathrm {E} _{\text{mach}}={\tfrac {1}{2}}B^{1-P},}"></span>
where <i>B</i> is the base of the system and <i>P</i> is the precision of the significand (in base <i>B</i>).
</p><p>This is important since it bounds the <i><a href="https://en.wikipedia.org/wiki/Relative_error" class="mw-redirect" title="Relative error">relative error</a></i> in representing any non-zero real number <span class="texhtml"><var style="padding-right: 1px;">x</var></span> within the normalized range of a floating-point system:
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \left|{\frac {\operatorname {fl} (x)-x}{x}}\right|\leq \mathrm {E} _{\text{mach}}.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow>
          <mo>|</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mfrac>
              <mrow>
                <mi>fl</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mo stretchy="false">(</mo>
                <mi>x</mi>
                <mo stretchy="false">)</mo>
                <mo>&#x2212;<!-- − --></mo>
                <mi>x</mi>
              </mrow>
              <mi>x</mi>
            </mfrac>
          </mrow>
          <mo>|</mo>
        </mrow>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">E</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>mach</mtext>
          </mrow>
        </msub>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \left|{\frac {\operatorname {fl} (x)-x}{x}}\right|\leq \mathrm {E} _{\text{mach}}.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/853988a2e76c33411e1dbb3579a37fa35acb927c" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.671ex; width:20.193ex; height:6.509ex;" alt="{\displaystyle \left|{\frac {\operatorname {fl} (x)-x}{x}}\right|\leq \mathrm {E} _{\text{mach}}.}"></span>
</p><p>Backward error analysis, the theory of which was developed and popularized by <a href="https://en.wikipedia.org/wiki/James_H._Wilkinson" title="James H. Wilkinson">James H. Wilkinson</a>, can be used to establish that an algorithm implementing a numerical function is numerically stable.<sup id="cite_ref-RalstonReilly2003_61-0" class="reference"><a href="#cite_note-RalstonReilly2003-61"><span class="cite-bracket">&#91;</span>51<span class="cite-bracket">&#93;</span></a></sup> The basic approach is to show that although the calculated result, due to roundoff errors, will not be exactly correct, it is the exact solution to a nearby problem with slightly perturbed input data. If the perturbation required is small, on the order of the uncertainty in the input data, then the results are in some sense as accurate as the data "deserves". The algorithm is then defined as <i><a href="https://en.wikipedia.org/wiki/Numerical_stability#Forward,_backward,_and_mixed_stability" title="Numerical stability">backward stable</a></i>. Stability is a measure of the sensitivity to rounding errors of a given numerical procedure; by contrast, the <a href="https://en.wikipedia.org/wiki/Condition_number" title="Condition number">condition number</a> of a function for a given problem indicates the inherent sensitivity of the function to small perturbations in its input and is independent of the implementation used to solve the problem.<sup id="cite_ref-Einarsson_2005_62-0" class="reference"><a href="#cite_note-Einarsson_2005-62"><span class="cite-bracket">&#91;</span>52<span class="cite-bracket">&#93;</span></a></sup>
</p><p>As a trivial example, consider a simple expression giving the inner product of (length two) vectors <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="{\displaystyle x}"></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="{\displaystyle y}"></span>, then
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}\operatorname {fl} (x\cdot y)&amp;=\operatorname {fl} {\big (}\operatorname {fl} (x_{1}\cdot y_{1})+\operatorname {fl} (x_{2}\cdot y_{2}){\big )},&amp;&amp;{\text{ where }}\operatorname {fl} (){\text{ indicates correctly rounded floating-point arithmetic}}\\&amp;=\operatorname {fl} {\big (}(x_{1}\cdot y_{1})(1+\delta _{1})+(x_{2}\cdot y_{2})(1+\delta _{2}){\big )},&amp;&amp;{\text{ where }}\delta _{n}\leq \mathrm {E} _{\text{mach}},{\text{ from above}}\\&amp;={\big (}(x_{1}\cdot y_{1})(1+\delta _{1})+(x_{2}\cdot y_{2})(1+\delta _{2}){\big )}(1+\delta _{3})\\&amp;=(x_{1}\cdot y_{1})(1+\delta _{1})(1+\delta _{3})+(x_{2}\cdot y_{2})(1+\delta _{2})(1+\delta _{3}),\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <mi>fl</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mo stretchy="false">(</mo>
                <mi>x</mi>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <mi>y</mi>
                <mo stretchy="false">)</mo>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>fl</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo maxsize="1.2em" minsize="1.2em">(</mo>
                  </mrow>
                </mrow>
                <mi>fl</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>+</mo>
                <mi>fl</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo maxsize="1.2em" minsize="1.2em">)</mo>
                  </mrow>
                </mrow>
                <mo>,</mo>
              </mtd>
              <mtd />
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>&#xA0;where&#xA0;</mtext>
                </mrow>
                <mi>fl</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mo stretchy="false">(</mo>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>&#xA0;indicates correctly rounded floating-point arithmetic</mtext>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mi>fl</mi>
                <mo>&#x2061;<!-- ⁡ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo maxsize="1.2em" minsize="1.2em">(</mo>
                  </mrow>
                </mrow>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>+</mo>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo maxsize="1.2em" minsize="1.2em">)</mo>
                  </mrow>
                </mrow>
                <mo>,</mo>
              </mtd>
              <mtd />
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>&#xA0;where&#xA0;</mtext>
                </mrow>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>n</mi>
                  </mrow>
                </msub>
                <mo>&#x2264;<!-- ≤ --></mo>
                <msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="normal">E</mi>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>mach</mtext>
                  </mrow>
                </msub>
                <mo>,</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>&#xA0;from above</mtext>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo maxsize="1.2em" minsize="1.2em">(</mo>
                  </mrow>
                </mrow>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>+</mo>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo maxsize="1.2em" minsize="1.2em">)</mo>
                  </mrow>
                </mrow>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>+</mo>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo>&#x22C5;<!-- ⋅ --></mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>,</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}\operatorname {fl} (x\cdot y)&amp;=\operatorname {fl} {\big (}\operatorname {fl} (x_{1}\cdot y_{1})+\operatorname {fl} (x_{2}\cdot y_{2}){\big )},&amp;&amp;{\text{ where }}\operatorname {fl} (){\text{ indicates correctly rounded floating-point arithmetic}}\\&amp;=\operatorname {fl} {\big (}(x_{1}\cdot y_{1})(1+\delta _{1})+(x_{2}\cdot y_{2})(1+\delta _{2}){\big )},&amp;&amp;{\text{ where }}\delta _{n}\leq \mathrm {E} _{\text{mach}},{\text{ from above}}\\&amp;={\big (}(x_{1}\cdot y_{1})(1+\delta _{1})+(x_{2}\cdot y_{2})(1+\delta _{2}){\big )}(1+\delta _{3})\\&amp;=(x_{1}\cdot y_{1})(1+\delta _{1})(1+\delta _{3})+(x_{2}\cdot y_{2})(1+\delta _{2})(1+\delta _{3}),\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/91cfb9605c32f283534751331630a5a4fd1e0e97" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -6.171ex; width:130.907ex; height:13.509ex;" alt="{\displaystyle {\begin{aligned}\operatorname {fl} (x\cdot y)&amp;=\operatorname {fl} {\big (}\operatorname {fl} (x_{1}\cdot y_{1})+\operatorname {fl} (x_{2}\cdot y_{2}){\big )},&amp;&amp;{\text{ where }}\operatorname {fl} (){\text{ indicates correctly rounded floating-point arithmetic}}\\&amp;=\operatorname {fl} {\big (}(x_{1}\cdot y_{1})(1+\delta _{1})+(x_{2}\cdot y_{2})(1+\delta _{2}){\big )},&amp;&amp;{\text{ where }}\delta _{n}\leq \mathrm {E} _{\text{mach}},{\text{ from above}}\\&amp;={\big (}(x_{1}\cdot y_{1})(1+\delta _{1})+(x_{2}\cdot y_{2})(1+\delta _{2}){\big )}(1+\delta _{3})\\&amp;=(x_{1}\cdot y_{1})(1+\delta _{1})(1+\delta _{3})+(x_{2}\cdot y_{2})(1+\delta _{2})(1+\delta _{3}),\end{aligned}}}"></span>
and so
<span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \operatorname {fl} (x\cdot y)={\hat {x}}\cdot {\hat {y}},}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>fl</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>x</mi>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>&#x22C5;<!-- ⋅ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>y</mi>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>,</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \operatorname {fl} (x\cdot y)={\hat {x}}\cdot {\hat {y}},}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/aaefe06c6b20bb5187afd515c1290cc79d51b170" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:15.389ex; height:2.843ex;" alt="{\displaystyle \operatorname {fl} (x\cdot y)={\hat {x}}\cdot {\hat {y}},}"></span>
</p><p>where
</p><p><span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}{\hat {x}}_{1}&amp;=x_{1}(1+\delta _{1});&amp;{\hat {x}}_{2}&amp;=x_{2}(1+\delta _{2});\\{\hat {y}}_{1}&amp;=y_{1}(1+\delta _{3});&amp;{\hat {y}}_{2}&amp;=y_{2}(1+\delta _{3}),\\\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mrow class="MJX-TeXAtom-ORD">
                      <mover>
                        <mi>x</mi>
                        <mo stretchy="false">&#x005E;<!-- ^ --></mo>
                      </mover>
                    </mrow>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>;</mo>
              </mtd>
              <mtd>
                <msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mrow class="MJX-TeXAtom-ORD">
                      <mover>
                        <mi>x</mi>
                        <mo stretchy="false">&#x005E;<!-- ^ --></mo>
                      </mover>
                    </mrow>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>x</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>;</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mrow class="MJX-TeXAtom-ORD">
                      <mover>
                        <mi>y</mi>
                        <mo stretchy="false">&#x005E;<!-- ^ --></mo>
                      </mover>
                    </mrow>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>1</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>;</mo>
              </mtd>
              <mtd>
                <msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mrow class="MJX-TeXAtom-ORD">
                      <mover>
                        <mi>y</mi>
                        <mo stretchy="false">&#x005E;<!-- ^ --></mo>
                      </mover>
                    </mrow>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
              </mtd>
              <mtd>
                <mi></mi>
                <mo>=</mo>
                <msub>
                  <mi>y</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <mn>1</mn>
                <mo>+</mo>
                <msub>
                  <mi>&#x03B4;<!-- δ --></mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>3</mn>
                  </mrow>
                </msub>
                <mo stretchy="false">)</mo>
                <mo>,</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}{\hat {x}}_{1}&amp;=x_{1}(1+\delta _{1});&amp;{\hat {x}}_{2}&amp;=x_{2}(1+\delta _{2});\\{\hat {y}}_{1}&amp;=y_{1}(1+\delta _{3});&amp;{\hat {y}}_{2}&amp;=y_{2}(1+\delta _{3}),\\\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0974c5b2aec0cd595a21dbd756adc581fe26fe7e" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -2.505ex; width:38.221ex; height:6.176ex;" alt="{\displaystyle {\begin{aligned}{\hat {x}}_{1}&amp;=x_{1}(1+\delta _{1});&amp;{\hat {x}}_{2}&amp;=x_{2}(1+\delta _{2});\\{\hat {y}}_{1}&amp;=y_{1}(1+\delta _{3});&amp;{\hat {y}}_{2}&amp;=y_{2}(1+\delta _{3}),\\\end{aligned}}}"></span>
</p><p>where
</p><p><span class="mwe-math-element"><span class="mwe-math-mathml-display mwe-math-mathml-a11y" style="display: none;"><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \delta _{n}\leq \mathrm {E} _{\text{mach}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>&#x03B4;<!-- δ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">E</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mtext>mach</mtext>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \delta _{n}\leq \mathrm {E} _{\text{mach}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9dab0eb7295a461df0cef551eb4afd052c966c04" class="mwe-math-fallback-image-display mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:10.999ex; height:2.676ex;" alt="{\displaystyle \delta _{n}\leq \mathrm {E} _{\text{mach}}}"></span>
</p><p>by definition, which is the sum of two slightly perturbed (on the order of Ε<sub>mach</sub>) input data, and so is backward stable. For more realistic examples in <a href="https://en.wikipedia.org/wiki/Numerical_linear_algebra" title="Numerical linear algebra">numerical linear algebra</a>, see Higham 2002<sup id="cite_ref-Higham_2002_63-0" class="reference"><a href="#cite_note-Higham_2002-63"><span class="cite-bracket">&#91;</span>53<span class="cite-bracket">&#93;</span></a></sup> and other references below.
</p>
<div class="mw-heading mw-heading3"><h3 id="Minimizing_the_effect_of_accuracy_problems">Minimizing the effect of accuracy problems</h3></span></div>
<p>Although individual arithmetic operations of IEEE 754 are guaranteed accurate to within half a <a href="https://en.wikipedia.org/wiki/Unit_in_the_last_place" title="Unit in the last place">ULP</a>, more complicated formulae can suffer from larger errors for a variety of reasons. The loss of accuracy can be substantial if a problem or its data are <a href="https://en.wikipedia.org/wiki/Condition_number" title="Condition number">ill-conditioned</a>, meaning that the correct result is hypersensitive to tiny perturbations in its data. However, even functions that are well-conditioned can suffer from large loss of accuracy if an algorithm <a href="https://en.wikipedia.org/wiki/Numerical_stability" title="Numerical stability">numerically unstable</a> for that data is used: apparently equivalent formulations of expressions in a programming language can differ markedly in their numerical stability. One approach to remove the risk of such loss of accuracy is the design and analysis of numerically stable algorithms, which is an aim of the branch of mathematics known as <a href="https://en.wikipedia.org/wiki/Numerical_analysis" title="Numerical analysis">numerical analysis</a>. Another approach that can protect against the risk of numerical instabilities is the computation of intermediate (scratch) values in an algorithm at a higher precision than the final result requires,<sup id="cite_ref-OliveiraStewart_2006_64-0" class="reference"><a href="#cite_note-OliveiraStewart_2006-64"><span class="cite-bracket">&#91;</span>54<span class="cite-bracket">&#93;</span></a></sup> which can remove, or reduce by orders of magnitude,<sup id="cite_ref-Kahan_2005_ARITH17_65-0" class="reference"><a href="#cite_note-Kahan_2005_ARITH17-65"><span class="cite-bracket">&#91;</span>55<span class="cite-bracket">&#93;</span></a></sup> such risk: <a href="https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format" title="Quadruple-precision floating-point format">IEEE 754 quadruple precision</a> and <a href="https://en.wikipedia.org/wiki/Extended_precision" title="Extended precision">extended precision</a> are designed for this purpose when computing at double precision.<sup id="cite_ref-Kahan_2011_Debug_66-0" class="reference"><a href="#cite_note-Kahan_2011_Debug-66"><span class="cite-bracket">&#91;</span>56<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-NB_4_67-0" class="reference"><a href="#cite_note-NB_4-67"><span class="cite-bracket">&#91;</span>nb 11<span class="cite-bracket">&#93;</span></a></sup>
</p><p>For example, the following algorithm is a direct implementation to compute the function <span class="texhtml"><var style="padding-right: 1px;">A</var>(<var style="padding-right: 1px;">x</var>) = (<var style="padding-right: 1px;">x</var>−1) / (exp(<var style="padding-right: 1px;">x</var>−1) − 1)</span> which is well-conditioned at 1.0,<sup id="cite_ref-NB_5_68-0" class="reference"><a href="#cite_note-NB_5-68"><span class="cite-bracket">&#91;</span>nb 12<span class="cite-bracket">&#93;</span></a></sup> however it can be shown to be numerically unstable and lose up to half the significant digits carried by the arithmetic when computed near 1.0.<sup id="cite_ref-Kahan_2001_JavaHurt_69-0" class="reference"><a href="#cite_note-Kahan_2001_JavaHurt-69"><span class="cite-bracket">&#91;</span>57<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-highlight mw-highlight-lang-c mw-content-ltr mw-highlight-lines" dir="ltr"><pre><span></span><span class="linenos" data-line="1"></span><span class="kt">double</span><span class="w"> </span><span class="nf">A</span><span class="p">(</span><span class="kt">double</span><span class="w"> </span><span class="n">X</span><span class="p">)</span>
<span class="linenos" data-line="2"></span><span class="p">{</span>
<span class="hll"><span class="linenos" data-line="3"></span><span class="w">        </span><span class="kt">double</span><span class="w"> </span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">Z</span><span class="p">;</span><span class="w">  </span><span class="c1">// [1]</span>
</span><span class="linenos" data-line="4"></span><span class="w">        </span><span class="n">Y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">1.0</span><span class="p">;</span>
<span class="linenos" data-line="5"></span><span class="w">        </span><span class="n">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">exp</span><span class="p">(</span><span class="n">Y</span><span class="p">);</span>
<span class="linenos" data-line="6"></span><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">Z</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="mf">1.0</span><span class="p">)</span>
<span class="hll"><span class="linenos" data-line="7"></span><span class="w">                </span><span class="n">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Y</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">Z</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span><span class="w"> </span><span class="c1">// [2]</span>
</span><span class="linenos" data-line="8"></span><span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">Z</span><span class="p">;</span>
<span class="linenos" data-line="9"></span><span class="p">}</span>
</pre></div>
<p>If, however, intermediate computations are all performed in extended precision (e.g. by setting line [1] to <a href="https://en.wikipedia.org/wiki/C99" title="C99">C99</a> <code class="mw-highlight mw-highlight-lang-text mw-content-ltr" id="" style="" dir="ltr">long double</code>), then up to full precision in the final double result can be maintained.<sup id="cite_ref-NB_6_70-0" class="reference"><a href="#cite_note-NB_6-70"><span class="cite-bracket">&#91;</span>nb 13<span class="cite-bracket">&#93;</span></a></sup> Alternatively, a numerical analysis of the algorithm reveals that if the following non-obvious change to line [2] is made:
</p>
<div class="mw-highlight mw-highlight-lang-c mw-content-ltr" dir="ltr"><pre><span></span><span class="n">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="n">Z</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mf">1.0</span><span class="p">);</span>
</pre></div>
<p>then the algorithm becomes numerically stable and can compute to full double precision.
</p><p>To maintain the properties of such carefully constructed numerically stable programs, careful handling by the <a href="https://en.wikipedia.org/wiki/Compiler" title="Compiler">compiler</a> is required. Certain "optimizations" that compilers might make (for example, reordering operations) can work against the goals of well-behaved software. There is some controversy about the failings of compilers and language designs in this area: C99 is an example of a language where such optimizations are carefully specified to maintain numerical precision. See the external references at the bottom of this article.
</p><p>A detailed treatment of the techniques for writing high-quality floating-point software is beyond the scope of this article, and the reader is referred to,<sup id="cite_ref-Higham_2002_63-1" class="reference"><a href="#cite_note-Higham_2002-63"><span class="cite-bracket">&#91;</span>53<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Kahan_2000_Marketing_71-0" class="reference"><a href="#cite_note-Kahan_2000_Marketing-71"><span class="cite-bracket">&#91;</span>58<span class="cite-bracket">&#93;</span></a></sup> and the other references at the bottom of this article. Kahan suggests several rules of thumb that can substantially decrease by orders of magnitude<sup id="cite_ref-Kahan_2000_Marketing_71-1" class="reference"><a href="#cite_note-Kahan_2000_Marketing-71"><span class="cite-bracket">&#91;</span>58<span class="cite-bracket">&#93;</span></a></sup> the risk of numerical anomalies, in addition to, or in lieu of, a more careful numerical analysis. These include: as noted above, computing all expressions and intermediate results in the highest precision supported in hardware (a common rule of thumb is to carry twice the precision of the desired result, i.e. compute in double precision for a final single-precision result, or in double extended or quad precision for up to double-precision results<sup id="cite_ref-Kahan_1981_WhyIEEE_72-0" class="reference"><a href="#cite_note-Kahan_1981_WhyIEEE-72"><span class="cite-bracket">&#91;</span>59<span class="cite-bracket">&#93;</span></a></sup>); and rounding input data and results to only the precision required and supported by the input data (carrying excess precision in the final result beyond that required and supported by the input data can be misleading, increases storage cost and decreases speed, and the excess bits can affect convergence of numerical procedures:<sup id="cite_ref-Kahan_2001_LN_73-0" class="reference"><a href="#cite_note-Kahan_2001_LN-73"><span class="cite-bracket">&#91;</span>60<span class="cite-bracket">&#93;</span></a></sup> notably, the first form of the iterative example given below converges correctly when using this rule of thumb). Brief descriptions of several additional issues and techniques follow.
</p><p>As decimal fractions can often not be exactly represented in binary floating-point, such arithmetic is at its best when it is simply being used to measure real-world quantities over a wide range of scales (such as the orbital period of a moon around Saturn or the mass of a <a href="https://en.wikipedia.org/wiki/Proton" title="Proton">proton</a>), and at its worst when it is expected to model the interactions of quantities expressed as decimal strings that are expected to be exact.<sup id="cite_ref-Kahan_2005_ARITH17_65-1" class="reference"><a href="#cite_note-Kahan_2005_ARITH17-65"><span class="cite-bracket">&#91;</span>55<span class="cite-bracket">&#93;</span></a></sup><sup id="cite_ref-Kahan_2000_Marketing_71-2" class="reference"><a href="#cite_note-Kahan_2000_Marketing-71"><span class="cite-bracket">&#91;</span>58<span class="cite-bracket">&#93;</span></a></sup> An example of the latter case is financial calculations. For this reason, financial software tends not to use a binary floating-point number representation.<sup id="cite_ref-Speleotrove_2012_74-0" class="reference"><a href="#cite_note-Speleotrove_2012-74"><span class="cite-bracket">&#91;</span>61<span class="cite-bracket">&#93;</span></a></sup> The "decimal" data type of the <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)" title="C Sharp (programming language)">C#</a> and <a href="https://en.wikipedia.org/wiki/Python_(programming_language)" title="Python (programming language)">Python</a> programming languages, and the decimal formats of the <a href="https://en.wikipedia.org/wiki/IEEE_754-2008" class="mw-redirect" title="IEEE 754-2008">IEEE 754-2008</a> standard, are designed to avoid the problems of binary floating-point representations when applied to human-entered exact decimal values, and make the arithmetic always behave as expected when numbers are printed in decimal.
</p><p>Expectations from mathematics may not be realized in the field of floating-point computation. For example, it is known that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (x+y)(x-y)=x^{2}-y^{2}\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo>+</mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo>&#x2212;<!-- − --></mo>
        <mi>y</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <msup>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mo>&#x2212;<!-- − --></mo>
        <msup>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (x+y)(x-y)=x^{2}-y^{2}\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/42f6b57467359a23ff92ad97626a078c836d5a3e" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:25.194ex; height:3.176ex;" alt="{\displaystyle (x+y)(x-y)=x^{2}-y^{2}\,}"></span>, and that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sin ^{2}{\theta }+\cos ^{2}{\theta }=1\,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>sin</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi>&#x03B8;<!-- θ --></mi>
        </mrow>
        <mo>+</mo>
        <msup>
          <mi>cos</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi>&#x03B8;<!-- θ --></mi>
        </mrow>
        <mo>=</mo>
        <mn>1</mn>
        <mspace width="thinmathspace" />
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sin ^{2}{\theta }+\cos ^{2}{\theta }=1\,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a9d6c234a50e2ecda8445a62785f9c27167a4d34" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.505ex; width:18.519ex; height:2.843ex;" alt="{\displaystyle \sin ^{2}{\theta }+\cos ^{2}{\theta }=1\,}"></span>, however these facts cannot be relied on when the quantities involved are the result of floating-point computation.
</p><p>The use of the equality test (<code>if (x==y) ...</code>) requires care when dealing with floating-point numbers. Even simple expressions like <code>0.6/0.2-3==0</code> will, on most computers, fail to be true<sup id="cite_ref-Christiansen_Perl_75-0" class="reference"><a href="#cite_note-Christiansen_Perl-75"><span class="cite-bracket">&#91;</span>62<span class="cite-bracket">&#93;</span></a></sup> (in IEEE 754 double precision, for example, <code>0.6/0.2 - 3</code> is approximately equal to -4.44089209850063e-16). Consequently, such tests are sometimes replaced with "fuzzy" comparisons (<code>if (abs(x-y) &lt; epsilon) ...</code>, where epsilon is sufficiently small and tailored to the application, such as 1.0E−13). The wisdom of doing this varies greatly, and can require numerical analysis to bound epsilon.<sup id="cite_ref-Higham_2002_63-2" class="reference"><a href="#cite_note-Higham_2002-63"><span class="cite-bracket">&#91;</span>53<span class="cite-bracket">&#93;</span></a></sup> Values derived from the primary data representation and their comparisons should be performed in a wider, extended, precision to minimize the risk of such inconsistencies due to round-off errors.<sup id="cite_ref-Kahan_2000_Marketing_71-3" class="reference"><a href="#cite_note-Kahan_2000_Marketing-71"><span class="cite-bracket">&#91;</span>58<span class="cite-bracket">&#93;</span></a></sup> It is often better to organize the code in such a way that such tests are unnecessary. For example, in <a href="https://en.wikipedia.org/wiki/Computational_geometry" title="Computational geometry">computational geometry</a>, exact tests of whether a point lies off or on a line or plane defined by other points can be performed using adaptive precision or exact arithmetic methods.<sup id="cite_ref-Shewchuk_76-0" class="reference"><a href="#cite_note-Shewchuk-76"><span class="cite-bracket">&#91;</span>63<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Small errors in floating-point arithmetic can grow when mathematical algorithms perform operations an enormous number of times. A few examples are <a href="https://en.wikipedia.org/wiki/Matrix_inversion" class="mw-redirect" title="Matrix inversion">matrix inversion</a>, <a href="https://en.wikipedia.org/wiki/Eigenvector" class="mw-redirect" title="Eigenvector">eigenvector</a> computation, and differential equation solving. These algorithms must be very carefully designed, using numerical approaches such as <a href="https://en.wikipedia.org/wiki/Iterative_refinement" title="Iterative refinement">iterative refinement</a>, if they are to work well.<sup id="cite_ref-Kahan_1997_Cantilever_77-0" class="reference"><a href="#cite_note-Kahan_1997_Cantilever-77"><span class="cite-bracket">&#91;</span>64<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Summation of a vector of floating-point values is a basic algorithm in <a href="https://en.wikipedia.org/wiki/Computational_science" title="Computational science">scientific computing</a>, and so an awareness of when loss of significance can occur is essential. For example, if one is adding a very large number of numbers, the individual addends are very small compared with the sum. This can lead to loss of significance. A typical addition would then be something like
</p>
<pre>3253.671
+  3.141276
-----------
3256.812
</pre>
<p>The low 3 digits of the addends are effectively lost. Suppose, for example, that one needs to add many numbers, all approximately equal to 3. After 1000 of them have been added, the running sum is about 3000; the lost digits are not regained. The <a href="https://en.wikipedia.org/wiki/Kahan_summation_algorithm" title="Kahan summation algorithm">Kahan summation algorithm</a> may be used to reduce the errors.<sup id="cite_ref-Higham_2002_63-3" class="reference"><a href="#cite_note-Higham_2002-63"><span class="cite-bracket">&#91;</span>53<span class="cite-bracket">&#93;</span></a></sup>
</p><p>Round-off error can affect the convergence and accuracy of iterative numerical procedures. As an example, <a href="https://en.wikipedia.org/wiki/Archimedes" title="Archimedes">Archimedes</a> approximated π by calculating the perimeters of polygons inscribing and circumscribing a circle, starting with hexagons, and successively doubling the number of sides. As noted above, computations may be rearranged in a way that is mathematically equivalent but less prone to error (<a href="https://en.wikipedia.org/wiki/Numerical_analysis" title="Numerical analysis">numerical analysis</a>). Two forms of the recurrence formula for the circumscribed polygon are:<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="Not obvious formulas (June 2016)">citation needed</span></a></i>&#93;</sup>
</p>
<ul><li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\textstyle t_{0}={\frac {1}{\sqrt {3}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="false" scriptlevel="0">
        <msub>
          <mi>t</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <msqrt>
              <mn>3</mn>
            </msqrt>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\textstyle t_{0}={\frac {1}{\sqrt {3}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a9a8d68112b0a6f1a41b69213bdc887a4f8bae7d" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.838ex; width:8.019ex; height:4.176ex;" alt="{\textstyle t_{0}={\frac {1}{\sqrt {3}}}}"></span></li>
<li>First form: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\textstyle t_{i+1}={\frac {{\sqrt {t_{i}^{2}+1}}-1}{t_{i}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="false" scriptlevel="0">
        <msub>
          <mi>t</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>+</mo>
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <msqrt>
                  <msubsup>
                    <mi>t</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>i</mi>
                    </mrow>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn>2</mn>
                    </mrow>
                  </msubsup>
                  <mo>+</mo>
                  <mn>1</mn>
                </msqrt>
              </mrow>
              <mo>&#x2212;<!-- − --></mo>
              <mn>1</mn>
            </mrow>
            <msub>
              <mi>t</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\textstyle t_{i+1}={\frac {{\sqrt {t_{i}^{2}+1}}-1}{t_{i}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7b8e42962e073104445e5fb184833851ef480065" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -1.505ex; width:14.944ex; height:5.843ex;" alt="{\textstyle t_{i+1}={\frac {{\sqrt {t_{i}^{2}+1}}-1}{t_{i}}}}"></span></li>
<li>second form: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" alttext="{\textstyle t_{i+1}={\frac {t_{i}}{{\sqrt {t_{i}^{2}+1}}+1}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="false" scriptlevel="0">
        <msub>
          <mi>t</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>+</mo>
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <msub>
              <mi>t</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <msqrt>
                  <msubsup>
                    <mi>t</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>i</mi>
                    </mrow>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn>2</mn>
                    </mrow>
                  </msubsup>
                  <mo>+</mo>
                  <mn>1</mn>
                </msqrt>
              </mrow>
              <mo>+</mo>
              <mn>1</mn>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\textstyle t_{i+1}={\frac {t_{i}}{{\sqrt {t_{i}^{2}+1}}+1}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/171333bbf207a0be4a87530af334d931d755e13d" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -3.171ex; width:14.944ex; height:5.843ex;" alt="{\textstyle t_{i+1}={\frac {t_{i}}{{\sqrt {t_{i}^{2}+1}}+1}}}"></span></li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \pi \sim 6\times 2^{i}\times t_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03C0;<!-- π --></mi>
        <mo>&#x223C;<!-- ∼ --></mo>
        <mn>6</mn>
        <mo>&#x00D7;<!-- × --></mo>
        <msup>
          <mn>2</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msup>
        <mo>&#x00D7;<!-- × --></mo>
        <msub>
          <mi>t</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \pi \sim 6\times 2^{i}\times t_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c19a2c9acbd64b8495a8e1aa2fe018103c500d61" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.671ex; width:14.875ex; height:3.009ex;" alt="{\displaystyle \pi \sim 6\times 2^{i}\times t_{i}}"></span>, converging as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle i\rightarrow \infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>i</mi>
        <mo stretchy="false">&#x2192;<!-- → --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle i\rightarrow \infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9912b98084f3a5fa477e9fbe25597750d2c375fd" class="mwe-math-fallback-image-inline mw-invert skin-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:6.74ex; height:2.176ex;" alt="{\displaystyle i\rightarrow \infty }"></span></li></ul>
<p>Here is a computation using IEEE "double" (a significand with 53 bits of precision) arithmetic:
</p>
<pre> i   6 × 2<sup>i</sup> × t<sub>i</sub>, first form    6 × 2<sup>i</sup> × t<sub>i</sub>, second form
---------------------------------------------------------
 0   <b><span style="color:purple;">3</span></b>.4641016151377543863      <b><span style="color:purple;">3</span></b>.4641016151377543863
 1   <b><span style="color:purple;">3</span></b>.2153903091734710173      <b><span style="color:purple;">3</span></b>.2153903091734723496
 2   <b><span style="color:purple;">3.1</span></b>596599420974940120      <b><span style="color:purple;">3.1</span></b>596599420975006733
 3   <b><span style="color:purple;">3.14</span></b>60862151314012979      <b><span style="color:purple;">3.14</span></b>60862151314352708
 4   <b><span style="color:purple;">3.14</span></b>27145996453136334      <b><span style="color:purple;">3.14</span></b>27145996453689225
 5   <b><span style="color:purple;">3.141</span></b>8730499801259536      <b><span style="color:purple;">3.141</span></b>8730499798241950
 6   <b><span style="color:purple;">3.141</span></b>6627470548084133      <b><span style="color:purple;">3.141</span></b>6627470568494473
 7   <b><span style="color:purple;">3.141</span></b>6101765997805905      <b><span style="color:purple;">3.141</span></b>6101766046906629
 8   <b><span style="color:purple;">3.14159</span></b>70343230776862      <b><span style="color:purple;">3.14159</span></b>70343215275928
 9   <b><span style="color:purple;">3.14159</span></b>37488171150615      <b><span style="color:purple;">3.14159</span></b>37487713536668
10   <b><span style="color:purple;">3.141592</span></b>9278733740748      <b><span style="color:purple;">3.141592</span></b>9273850979885
11   <b><span style="color:purple;">3.141592</span></b>7256228504127      <b><span style="color:purple;">3.141592</span></b>7220386148377
12   <b><span style="color:purple;">3.1415926</span></b>717412858693      <b><span style="color:purple;">3.1415926</span></b>707019992125
13   <b><span style="color:purple;">3.1415926</span></b>189011456060      <b><span style="color:purple;">3.14159265</span></b>78678454728
14   <b><span style="color:purple;">3.1415926</span></b>717412858693      <b><span style="color:purple;">3.14159265</span></b>46593073709
15   <b><span style="color:purple;">3.14159</span></b>19358822321783      <b><span style="color:purple;">3.141592653</span></b>8571730119
16   <b><span style="color:purple;">3.1415926</span></b>717412858693      <b><span style="color:purple;">3.141592653</span></b>6566394222
17   <b><span style="color:purple;">3.1415</span></b>810075796233302      <b><span style="color:purple;">3.141592653</span></b>6065061913
18   <b><span style="color:purple;">3.1415926</span></b>717412858693      <b><span style="color:purple;">3.1415926535</span></b>939728836
19   <b><span style="color:purple;">3.141</span></b>4061547378810956      <b><span style="color:purple;">3.1415926535</span></b>908393901
20   <b><span style="color:purple;">3.14</span></b>05434924008406305      <b><span style="color:purple;">3.1415926535</span></b>900560168
21   <b><span style="color:purple;">3.14</span></b>00068646912273617      <b><span style="color:purple;">3.141592653589</span></b>8608396
22   <b><span style="color:purple;">3.1</span></b>349453756585929919      <b><span style="color:purple;">3.141592653589</span></b>8122118
23   <b><span style="color:purple;">3.14</span></b>00068646912273617      <b><span style="color:purple;">3.14159265358979</span></b>95552
24   <b><span style="color:purple;">3</span></b>.2245152435345525443      <b><span style="color:purple;">3.14159265358979</span></b>68907
25                              <b><span style="color:purple;">3.14159265358979</span></b>62246
26                              <b><span style="color:purple;">3.14159265358979</span></b>62246
27                              <b><span style="color:purple;">3.14159265358979</span></b>62246
28                              <b><span style="color:purple;">3.14159265358979</span></b>62246
              The true value is <b><span style="color:purple;">3.14159265358979323846264338327...</span></b>
</pre>
<p>While the two forms of the recurrence formula are clearly mathematically equivalent,<sup id="cite_ref-NB_7_78-0" class="reference"><a href="#cite_note-NB_7-78"><span class="cite-bracket">&#91;</span>nb 14<span class="cite-bracket">&#93;</span></a></sup> the first subtracts 1 from a number extremely close to 1, leading to an increasingly problematic loss of <a href="https://en.wikipedia.org/wiki/Significant_digit" class="mw-redirect" title="Significant digit">significant digits</a>. As the recurrence is applied repeatedly, the accuracy improves at first, but then it deteriorates. It never gets better than about 8 digits, even though 53-bit arithmetic should be capable of about 16 digits of precision. When the second form of the recurrence is used, the value converges to 15 digits of precision.
</p>
<div class="mw-heading mw-heading3"><h3 id="&quot;Fast_math&quot;_optimization"><span id=".22Fast_math.22_optimization"></span>"Fast math" optimization</h3></span></div>
<p>The aforementioned lack of <a href="https://en.wikipedia.org/wiki/Associative_property" title="Associative property">associativity</a> of floating-point operations in general means that <a href="https://en.wikipedia.org/wiki/Compilers" class="mw-redirect" title="Compilers">compilers</a> cannot as effectively reorder arithmetic expressions as they could with integer and fixed-point arithmetic, presenting a roadblock in optimizations such as <a href="https://en.wikipedia.org/wiki/Common_subexpression_elimination" title="Common subexpression elimination">common subexpression elimination</a> and auto-<a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data" title="Single instruction, multiple data">vectorization</a>.<sup id="cite_ref-Vectorizers_79-0" class="reference"><a href="#cite_note-Vectorizers-79"><span class="cite-bracket">&#91;</span>65<span class="cite-bracket">&#93;</span></a></sup> The "fast math" option on many compilers (ICC, GCC, Clang, MSVC...) turns on reassociation along with unsafe assumptions such as a lack of NaN and infinite numbers in IEEE 754. Some compilers also offer more granular options to only turn on reassociation. In either case, the programmer is exposed to many of the precision pitfalls mentioned above for the portion of the program using "fast" math.<sup id="cite_ref-FPM_80-0" class="reference"><a href="#cite_note-FPM-80"><span class="cite-bracket">&#91;</span>66<span class="cite-bracket">&#93;</span></a></sup>
</p><p>In some compilers (GCC and Clang), turning on "fast" math may cause the program to <a href="https://en.wikipedia.org/wiki/Subnormal_number#Disabling_subnormal_floats_at_the_code_level" title="Subnormal number">disable subnormal floats</a> at startup, affecting the floating-point behavior of not only the generated code, but also any program using such code as a <a href="https://en.wikipedia.org/wiki/Library_(computing)" title="Library (computing)">library</a>.<sup id="cite_ref-harmful_81-0" class="reference"><a href="#cite_note-harmful-81"><span class="cite-bracket">&#91;</span>67<span class="cite-bracket">&#93;</span></a></sup>
</p><p>In most <a href="https://en.wikipedia.org/wiki/Fortran" title="Fortran">Fortran</a> compilers, as allowed by the ISO/IEC 1539-1:2004 Fortran standard, reassociation is the default, with breakage largely prevented by the "protect parens" setting (also on by default). This setting stops the compiler from reassociating beyond the boundaries of parentheses.<sup id="cite_ref-Gen_82-0" class="reference"><a href="#cite_note-Gen-82"><span class="cite-bracket">&#91;</span>68<span class="cite-bracket">&#93;</span></a></sup> <a href="https://en.wikipedia.org/wiki/Intel_Fortran_Compiler" title="Intel Fortran Compiler">Intel Fortran Compiler</a> is a notable outlier.<sup id="cite_ref-zheevd_83-0" class="reference"><a href="#cite_note-zheevd-83"><span class="cite-bracket">&#91;</span>69<span class="cite-bracket">&#93;</span></a></sup>
</p><p>A common problem in "fast" math is that subexpressions may not be optimized identically from place to place, leading to unexpected differences. One interpretation of the issue is that "fast" math as implemented currently has a poorly defined semantics. One attempt at formalizing "fast" math optimizations is seen in <i>Icing</i>, a verified compiler.<sup id="cite_ref-Becker-Darulova-Myreen-Tatlock_2019_84-0" class="reference"><a href="#cite_note-Becker-Darulova-Myreen-Tatlock_2019-84"><span class="cite-bracket">&#91;</span>70<span class="cite-bracket">&#93;</span></a></sup>
</p>
<div class="mw-heading mw-heading2"><h2 id="See_also">See also</h2></span></div>
<style data-mw-deduplicate="TemplateStyles:r1184024115">.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}</style><div class="div-col" style="column-width: 20em;">
<ul><li><a href="https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic" title="Arbitrary-precision arithmetic">Arbitrary-precision arithmetic</a></li>
<li><a href="https://en.wikipedia.org/wiki/C99#IEEE_754_floating-point_support" title="C99">C99</a> for code examples demonstrating access and use of IEEE 754 features.</li>
<li><a href="https://en.wikipedia.org/wiki/Computable_number" title="Computable number">Computable number</a></li>
<li><a href="https://en.wikipedia.org/wiki/Coprocessor" title="Coprocessor">Coprocessor</a></li>
<li><a href="https://en.wikipedia.org/wiki/Decimal_floating_point" title="Decimal floating point">Decimal floating point</a></li>
<li><a href="https://en.wikipedia.org/wiki/Double_precision" class="mw-redirect" title="Double precision">Double precision</a></li>
<li><a href="https://en.wikipedia.org/wiki/Experimental_mathematics" title="Experimental mathematics">Experimental mathematics</a> – utilizes high precision floating-point computations</li>
<li><a href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic" title="Fixed-point arithmetic">Fixed-point arithmetic</a></li>
<li><a href="https://en.wikipedia.org/wiki/Floating-point_error_mitigation" title="Floating-point error mitigation">Floating-point error mitigation</a></li>
<li><a href="https://en.wikipedia.org/wiki/FLOPS" title="FLOPS">FLOPS</a></li>
<li><a href="https://en.wikipedia.org/wiki/Gal%27s_accurate_tables" title="Gal&#39;s accurate tables">Gal's accurate tables</a></li>
<li><a href="https://en.wikipedia.org/wiki/GNU_MPFR" title="GNU MPFR">GNU MPFR</a></li>
<li><a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format" title="Half-precision floating-point format">Half-precision floating-point format</a></li>
<li><a href="https://en.wikipedia.org/wiki/IEEE_754" title="IEEE 754">IEEE 754</a> – Standard for Binary Floating-Point Arithmetic</li>
<li><a href="https://en.wikipedia.org/wiki/IBM_hexadecimal_floating-point" title="IBM hexadecimal floating-point">IBM Floating Point Architecture</a></li>
<li><a href="https://en.wikipedia.org/wiki/Kahan_summation_algorithm" title="Kahan summation algorithm">Kahan summation algorithm</a></li>
<li><a href="https://en.wikipedia.org/wiki/Microsoft_Binary_Format" title="Microsoft Binary Format">Microsoft Binary Format</a> (MBF)</li>
<li><a href="https://en.wikipedia.org/wiki/Minifloat" title="Minifloat">Minifloat</a></li>
<li><a href="https://en.wikipedia.org/wiki/Q_(number_format)" title="Q (number format)">Q (number format)</a> for constant resolution</li>
<li><a href="https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format" title="Quadruple-precision floating-point format">Quadruple-precision floating-point format</a> (including double-double)</li>
<li><a href="https://en.wikipedia.org/wiki/Significant_figures" title="Significant figures">Significant figures</a></li>
<li><a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" title="Single-precision floating-point format">Single-precision floating-point format</a></li></ul>
</div>
<div class="mw-heading mw-heading2"><h2 id="Notes">Notes</h2></span></div>
<style data-mw-deduplicate="TemplateStyles:r1239543626">.mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><div class="reflist">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-NB_Significand-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_Significand_4-0">^</a></b></span> <span class="reference-text"><span class="anchor" id="NB-Significand"></span>The <i><a href="https://en.wikipedia.org/wiki/Significand" title="Significand">significand</a></i> of a floating-point number is also called <i>mantissa</i> by some authors&#8212;not to be confused with the <a href="https://en.wikipedia.org/wiki/Mantissa_(logarithm)" class="mw-redirect" title="Mantissa (logarithm)">mantissa</a> of a <a href="https://en.wikipedia.org/wiki/Logarithm" title="Logarithm">logarithm</a>. Somewhat vague, terms such as <i>coefficient</i> or <i>argument</i> are also used by some. The usage of the term <i>fraction</i> by some authors is potentially misleading as well. The term <i>characteristic</i> (as used e.g. by <a href="https://en.wikipedia.org/wiki/Control_Data_Corporation" title="Control Data Corporation">CDC</a>) is ambiguous, as it was historically also used to specify some form of <a href="#NB-Exponent">exponent</a> of floating-point numbers.</span>
</li>
<li id="cite_note-NB_Exponent-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_Exponent_5-0">^</a></b></span> <span class="reference-text"><span class="anchor" id="NB-Exponent"></span>The <i><a href="https://en.wikipedia.org/wiki/Exponent" class="mw-redirect" title="Exponent">exponent</a></i> of a floating-point number is sometimes also referred to as <i>scale</i>. The term <i>characteristic</i> (for <i><a href="https://en.wikipedia.org/wiki/Biased_exponent" class="mw-redirect" title="Biased exponent">biased exponent</a></i>, <i>exponent bias</i>, or <i>excess n representation</i>) is ambiguous, as it was historically also used to specify the <a href="#NB-Significand">significand</a> of floating-point numbers.</span>
</li>
<li id="cite_note-NB_9-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_9_8-0">^</a></b></span> <span class="reference-text"><a href="https://en.wikipedia.org/wiki/Hexadecimal_floating-point" class="mw-redirect" title="Hexadecimal floating-point">Hexadecimal (base-16) floating-point</a> arithmetic is used in the <a href="https://en.wikipedia.org/wiki/IBM_System_360" class="mw-redirect" title="IBM System 360">IBM System 360</a> (1964) and <a href="https://en.wikipedia.org/wiki/IBM_System_370" class="mw-redirect" title="IBM System 370">370</a> (1970) as well as various newer IBM machines, in the <a href="https://en.wikipedia.org/wiki/RCA_Spectra_70" title="RCA Spectra 70">RCA Spectra 70</a> (1964), the Siemens 4004 (1965), 7.700 (1974), 7.800, 7.500 (1977) series mainframes and successors, the Unidata 7.000 series mainframes, the <a href="https://en.wikipedia.org/wiki/Manchester_MU5" class="mw-redirect" title="Manchester MU5">Manchester MU5</a> (1972), the <a href="https://en.wikipedia.org/wiki/Heterogeneous_Element_Processor" title="Heterogeneous Element Processor">HEP</a> (1982) computers, and in 360/370-compatible mainframe families made by Fujitsu, Amdahl and Hitachi. It is also used in the <a href="https://en.wikipedia.org/wiki/Illinois_ILLIAC_III" class="mw-redirect" title="Illinois ILLIAC III">Illinois ILLIAC III</a> (1966), <a href="https://en.wikipedia.org/wiki/Data_General_Eclipse_S/200" class="mw-redirect" title="Data General Eclipse S/200">Data General Eclipse S/200</a> (ca. 1974), <a href="https://en.wikipedia.org/wiki/Gould_Powernode_9080" class="mw-redirect" title="Gould Powernode 9080">Gould Powernode 9080</a> (1980s), <a href="https://en.wikipedia.org/wiki/Interdata_8/32" class="mw-redirect" title="Interdata 8/32">Interdata 8/32</a> (1970s), the <a href="/w/index.php?title=SEL_System_85&amp;action=edit&amp;redlink=1" class="new" title="SEL System 85 (page does not exist)">SEL Systems 85</a> and <a href="/w/index.php?title=SEL_System_86&amp;action=edit&amp;redlink=1" class="new" title="SEL System 86 (page does not exist)">86</a> as well as the <a href="https://en.wikipedia.org/wiki/SDS_Sigma_5" class="mw-redirect" title="SDS Sigma 5">SDS Sigma 5</a> (1967), <a href="https://en.wikipedia.org/wiki/SDS_Sigma_7" class="mw-redirect" title="SDS Sigma 7">7</a> (1966) and <a href="https://en.wikipedia.org/wiki/Xerox_Sigma_9" title="Xerox Sigma 9">Xerox Sigma 9</a> (1970).</span>
</li>
<li id="cite_note-NB_8-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_8_10-0">^</a></b></span> <span class="reference-text">Octal (base-8) floating-point arithmetic is used in the <a href="https://en.wikipedia.org/wiki/Ferranti_Atlas" class="mw-redirect" title="Ferranti Atlas">Ferranti Atlas</a> (1962), <a href="https://en.wikipedia.org/wiki/Burroughs_B5500" class="mw-redirect" title="Burroughs B5500">Burroughs B5500</a> (1964), <a href="https://en.wikipedia.org/wiki/Burroughs_B5700" class="mw-redirect" title="Burroughs B5700">Burroughs B5700</a> (1971), <a href="https://en.wikipedia.org/wiki/Burroughs_B6700" class="mw-redirect" title="Burroughs B6700">Burroughs B6700</a> (1971) and <a href="https://en.wikipedia.org/wiki/Burroughs_B7700" class="mw-redirect" title="Burroughs B7700">Burroughs B7700</a> (1972) computers.</span>
</li>
<li id="cite_note-NB_11-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_11_12-0">^</a></b></span> <span class="reference-text">Quaternary (base-4) floating-point arithmetic is used in the <a href="https://en.wikipedia.org/wiki/Illinois_ILLIAC_II" class="mw-redirect" title="Illinois ILLIAC II">Illinois ILLIAC II</a> (1962) computer. It is also used in the Digital Field System DFS IV and V high-resolution site survey systems.</span>
</li>
<li id="cite_note-NB_12-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_12_13-0">^</a></b></span> <span class="reference-text">Base-256 floating-point arithmetic is used in the <a href="https://en.wikipedia.org/wiki/Rice_Institute_R1" class="mw-redirect" title="Rice Institute R1">Rice Institute R1</a> computer (since 1958).</span>
</li>
<li id="cite_note-NB_10-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_10_15-0">^</a></b></span> <span class="reference-text">Base-65536 floating-point arithmetic is used in the <a href="https://en.wikipedia.org/wiki/MANIAC_II" title="MANIAC II">MANIAC II</a> (1956) computer.</span>
</li>
<li id="cite_note-NB_1-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_1_41-0">^</a></b></span> <span class="reference-text">Computer hardware does not necessarily compute the exact value; it simply has to produce the equivalent rounded result as though it had computed the infinitely precise result.</span>
</li>
<li id="cite_note-NB_2-54"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_2_54-0">^</a></b></span> <span class="reference-text">The enormous complexity of modern <a href="https://en.wikipedia.org/wiki/Division_algorithm" title="Division algorithm">division algorithms</a> once led to a famous error. An early version of the <a href="https://en.wikipedia.org/wiki/Intel_Pentium" class="mw-redirect" title="Intel Pentium">Intel Pentium</a> chip was shipped with a <a href="https://en.wikipedia.org/wiki/FDIV" class="mw-redirect" title="FDIV">division instruction</a> that, on rare occasions, gave slightly incorrect results. Many computers had been shipped before the error was discovered. Until the defective computers were replaced, patched versions of compilers were developed that could avoid the failing cases. See <i><a href="https://en.wikipedia.org/wiki/Pentium_FDIV_bug" title="Pentium FDIV bug">Pentium FDIV bug</a></i>.</span>
</li>
<li id="cite_note-NB_3-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_3_57-0">^</a></b></span> <span class="reference-text">But an attempted computation of cos(π) yields −1 exactly. Since the derivative is nearly zero near π, the effect of the inaccuracy in the argument is far smaller than the spacing of the floating-point numbers around −1, and the rounded result is exact.</span>
</li>
<li id="cite_note-NB_4-67"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_4_67-0">^</a></b></span> <span class="reference-text"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">William Kahan</a> notes: "Except in extremely uncommon situations, extra-precise arithmetic generally attenuates risks due to roundoff at far less cost than the price of a competent error-analyst."</span>
</li>
<li id="cite_note-NB_5-68"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_5_68-0">^</a></b></span> <span class="reference-text">The <a href="https://en.wikipedia.org/wiki/Taylor_expansion" class="mw-redirect" title="Taylor expansion">Taylor expansion</a> of this function demonstrates that it is well-conditioned near 1: A(x) = 1 − (x−1)/2 + (x−1)^2/12 − (x−1)^4/720 + (x−1)^6/30240 − (x−1)^8/1209600 + ... for &#124;x−1&#124; &lt; π.</span>
</li>
<li id="cite_note-NB_6-70"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_6_70-0">^</a></b></span> <span class="reference-text">If <a href="https://en.wikipedia.org/wiki/Long_double" title="Long double">long double</a> is <a href="https://en.wikipedia.org/wiki/IEEE_quad_precision" class="mw-redirect" title="IEEE quad precision">IEEE quad precision</a> then full double precision is retained; if long double is <a href="https://en.wikipedia.org/wiki/IEEE_double_extended_precision" class="mw-redirect" title="IEEE double extended precision">IEEE double extended precision</a> then additional, but not full precision is retained.</span>
</li>
<li id="cite_note-NB_7-78"><span class="mw-cite-backlink"><b><a href="#cite_ref-NB_7_78-0">^</a></b></span> <span class="reference-text">The equivalence of the two forms can be verified algebraically by noting that the <a href="https://en.wikipedia.org/wiki/Denominator" class="mw-redirect" title="Denominator">denominator</a> of the fraction in the second form is the <a href="https://en.wikipedia.org/wiki/Conjugate_(algebra)" class="mw-redirect" title="Conjugate (algebra)">conjugate</a> of the <a href="https://en.wikipedia.org/wiki/Numerator" class="mw-redirect" title="Numerator">numerator</a> of the first. By multiplying the top and bottom of the first expression by this conjugate, one obtains the second expression.</span>
</li>
</ol></div></div>
<div class="mw-heading mw-heading2"><h2 id="References">References</h2></span></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1239543626"><div class="reflist reflist-columns references-column-width" style="column-width: 30em;">
<ol class="references">
<li id="cite_note-Muller_2010-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-Muller_2010_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Muller_2010_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Muller_2010_1-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Muller_2010_1-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-Muller_2010_1-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-Muller_2010_1-5"><sup><i><b>f</b></i></sup></a></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1238218222">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url("https://upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url("https://upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url("https://upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url("https://upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}</style><cite id="muller_et_al_pg_16" class="citation book cs1">Muller, Jean-Michel; Brisebarre, Nicolas; de Dinechin, Florent; Jeannerod, Claude-Pierre; Lefèvre, Vincent; Melquiond, Guillaume; <a href="https://en.wikipedia.org/wiki/Nathalie_Revol" title="Nathalie Revol">Revol, Nathalie</a>; Stehlé, Damien; Torres, Serge (2010). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=baFvrIOPvncC&amp;pg=PA16"><i>Handbook of Floating-Point Arithmetic</i></a> (1st&#160;ed.). <a href="https://en.wikipedia.org/wiki/Birkh%C3%A4user" title="Birkhäuser">Birkhäuser</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-0-8176-4705-6">10.1007/978-0-8176-4705-6</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-8176-4704-9" title="Special:BookSources/978-0-8176-4704-9"><bdi>978-0-8176-4704-9</bdi></a>. <a href="https://en.wikipedia.org/wiki/LCCN_(identifier)" class="mw-redirect" title="LCCN (identifier)">LCCN</a>&#160;<a rel="nofollow" class="external text" href="https://lccn.loc.gov/2009939668">2009939668</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Handbook+of+Floating-Point+Arithmetic&amp;rft.edition=1st&amp;rft.pub=Birkh%C3%A4user&amp;rft.date=2010&amp;rft_id=info%3Alccn%2F2009939668&amp;rft_id=info%3Adoi%2F10.1007%2F978-0-8176-4705-6&amp;rft.isbn=978-0-8176-4704-9&amp;rft.aulast=Muller&amp;rft.aufirst=Jean-Michel&amp;rft.au=Brisebarre%2C+Nicolas&amp;rft.au=de+Dinechin%2C+Florent&amp;rft.au=Jeannerod%2C+Claude-Pierre&amp;rft.au=Lef%C3%A8vre%2C+Vincent&amp;rft.au=Melquiond%2C+Guillaume&amp;rft.au=Revol%2C+Nathalie&amp;rft.au=Stehl%C3%A9%2C+Damien&amp;rft.au=Torres%2C+Serge&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DbaFvrIOPvncC%26pg%3DPA16&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-sterbenz1974fpcomp-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-sterbenz1974fpcomp_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-sterbenz1974fpcomp_2-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSterbenz1974" class="citation book cs1">Sterbenz, Pat H. (1974). <a rel="nofollow" class="external text" href="https://archive.org/details/SterbenzFloatingPointComputation/mode/2up"><i>Floating-Point Computation</i></a>. Englewood Cliffs, NJ, United States: Prentice-Hall. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-13-322495-3" title="Special:BookSources/0-13-322495-3"><bdi>0-13-322495-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Floating-Point+Computation&amp;rft.place=Englewood+Cliffs%2C+NJ%2C+United+States&amp;rft.pub=Prentice-Hall&amp;rft.date=1974&amp;rft.isbn=0-13-322495-3&amp;rft.aulast=Sterbenz&amp;rft.aufirst=Pat+H.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2FSterbenzFloatingPointComputation%2Fmode%2F2up&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Smith_1997-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-Smith_1997_3-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSmith1997" class="citation book cs1">Smith, Steven W. (1997). <a rel="nofollow" class="external text" href="http://www.dspguide.com/ch28/4.htm">"Chapter 28, Fixed versus Floating Point"</a>. <i>The Scientist and Engineer's Guide to Digital Signal Processing</i>. California Technical Pub. p.&#160;514. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-9660176-3-2" title="Special:BookSources/978-0-9660176-3-2"><bdi>978-0-9660176-3-2</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">2012-12-31</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+28%2C+Fixed+versus+Floating+Point&amp;rft.btitle=The+Scientist+and+Engineer%27s+Guide+to+Digital+Signal+Processing&amp;rft.pages=514&amp;rft.pub=California+Technical+Pub&amp;rft.date=1997&amp;rft.isbn=978-0-9660176-3-2&amp;rft.aulast=Smith&amp;rft.aufirst=Steven+W.&amp;rft_id=http%3A%2F%2Fwww.dspguide.com%2Fch28%2F4.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Zehendner_2008-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-Zehendner_2008_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Zehendner_2008_6-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFZehendner2008" class="citation web cs1 cs1-prop-foreign-lang-source">Zehendner, Eberhard (Summer 2008). <a rel="nofollow" class="external text" href="https://users.fmi.uni-jena.de/~nez/rechnerarithmetik_5/folien/Rechnerarithmetik.2008.05.handout.pdf">"Rechnerarithmetik: Fest- und Gleitkommasysteme"</a> <span class="cs1-format">(PDF)</span> (Lecture script) (in German). <a href="https://en.wikipedia.org/wiki/Friedrich-Schiller-Universit%C3%A4t_Jena" class="mw-redirect" title="Friedrich-Schiller-Universität Jena">Friedrich-Schiller-Universität Jena</a>. p.&#160;2. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20180807062449/https://users.fmi.uni-jena.de/~nez/rechnerarithmetik_5/folien/Rechnerarithmetik.2008.05.handout.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2018-08-07<span class="reference-accessdate">. Retrieved <span class="nowrap">2018-08-07</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Rechnerarithmetik%3A+Fest-+und+Gleitkommasysteme&amp;rft.pages=2&amp;rft.pub=Friedrich-Schiller-Universit%C3%A4t+Jena&amp;rft.date=2008&amp;rft.aulast=Zehendner&amp;rft.aufirst=Eberhard&amp;rft_id=https%3A%2F%2Fusers.fmi.uni-jena.de%2F~nez%2Frechnerarithmetik_5%2Ffolien%2FRechnerarithmetik.2008.05.handout.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> <a rel="nofollow" class="external autonumber" href="https://web.archive.org/web/20180806175620/https://users.fmi.uni-jena.de/~nez/rechnerarithmetik_5/folien/Rechnerarithmetik.2008.komplett.pdf">[1]</a> (NB. This reference incorrectly gives the MANIAC II's floating point base as 256, whereas it actually is 65536.)</span>
</li>
<li id="cite_note-Beebe_2017-7"><span class="mw-cite-backlink">^ <a href="#cite_ref-Beebe_2017_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Beebe_2017_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Beebe_2017_7-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Beebe_2017_7-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBeebe2017" class="citation book cs1">Beebe, Nelson H. F. (2017-08-22). "Chapter H. Historical floating-point architectures". <i>The Mathematical-Function Computation Handbook - Programming Using the MathCW Portable Software Library</i> (1st&#160;ed.). Salt Lake City, UT, USA: <a href="https://en.wikipedia.org/wiki/Springer_International_Publishing_AG" class="mw-redirect" title="Springer International Publishing AG">Springer International Publishing AG</a>. p.&#160;948. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-319-64110-2">10.1007/978-3-319-64110-2</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-319-64109-6" title="Special:BookSources/978-3-319-64109-6"><bdi>978-3-319-64109-6</bdi></a>. <a href="https://en.wikipedia.org/wiki/LCCN_(identifier)" class="mw-redirect" title="LCCN (identifier)">LCCN</a>&#160;<a rel="nofollow" class="external text" href="https://lccn.loc.gov/2017947446">2017947446</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:30244721">30244721</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+H.+Historical+floating-point+architectures&amp;rft.btitle=The+Mathematical-Function+Computation+Handbook+-+Programming+Using+the+MathCW+Portable+Software+Library&amp;rft.place=Salt+Lake+City%2C+UT%2C+USA&amp;rft.pages=948&amp;rft.edition=1st&amp;rft.pub=Springer+International+Publishing+AG&amp;rft.date=2017-08-22&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-64110-2&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A30244721%23id-name%3DS2CID&amp;rft_id=info%3Alccn%2F2017947446&amp;rft.isbn=978-3-319-64109-6&amp;rft.aulast=Beebe&amp;rft.aufirst=Nelson+H.+F.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Savard_2018-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-Savard_2018_9-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSavard2018" class="citation cs2">Savard, John J. G. (2018) [2007], <a rel="nofollow" class="external text" href="http://www.quadibloc.com/comp/cp020302.htm">"The Decimal Floating-Point Standard"</a>, <i>quadibloc</i>, <a rel="nofollow" class="external text" href="https://web.archive.org/web/20180703002322/http://www.quadibloc.com/comp/cp020302.htm">archived</a> from the original on 2018-07-03<span class="reference-accessdate">, retrieved <span class="nowrap">2018-07-16</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=quadibloc&amp;rft.atitle=The+Decimal+Floating-Point+Standard&amp;rft.date=2018&amp;rft.aulast=Savard&amp;rft.aufirst=John+J.+G.&amp;rft_id=http%3A%2F%2Fwww.quadibloc.com%2Fcomp%2Fcp020302.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Parkinson_2000-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-Parkinson_2000_11-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFParkinson2000" class="citation book cs1">Parkinson, Roger (2000-12-07). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=Ocip5vpLD4wC&amp;pg=PA24">"Chapter 2 - High resolution digital site survey systems - Chapter 2.1 - Digital field recording systems"</a>. <i>High Resolution Site Surveys</i> (1st&#160;ed.). <a href="https://en.wikipedia.org/wiki/CRC_Press" title="CRC Press">CRC Press</a>. p.&#160;24. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-20318604-6" title="Special:BookSources/978-0-20318604-6"><bdi>978-0-20318604-6</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">2019-08-18</span></span>. <q>[…] Systems such as the [Digital Field System] DFS IV and DFS V were quaternary floating-point systems and used gain steps of 12&#160;dB. […]</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Chapter+2+-+High+resolution+digital+site+survey+systems+-+Chapter+2.1+-+Digital+field+recording+systems&amp;rft.btitle=High+Resolution+Site+Surveys&amp;rft.pages=24&amp;rft.edition=1st&amp;rft.pub=CRC+Press&amp;rft.date=2000-12-07&amp;rft.isbn=978-0-20318604-6&amp;rft.aulast=Parkinson&amp;rft.aufirst=Roger&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DOcip5vpLD4wC%26pg%3DPA24&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (256 pages)</span>
</li>
<li id="cite_note-Lazarus_1956-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-Lazarus_1956_14-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLazarus1957" class="citation web cs1">Lazarus, Roger B. (1957-01-30) [1956-10-01]. <a rel="nofollow" class="external text" href="http://bitsavers.org/pdf/lanl/LA-2083_MANIAC_II_Oct56.pdf">"MANIAC II"</a> <span class="cs1-format">(PDF)</span>. Los Alamos, NM, USA: Los Alamos Scientific Laboratory of the University of California. p.&#160;14. LA-2083. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20180807200914/http://bitsavers.org/pdf/lanl/LA-2083_MANIAC_II_Oct56.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2018-08-07<span class="reference-accessdate">. Retrieved <span class="nowrap">2018-08-07</span></span>. <q>[…] the Maniac's floating base, which is 2<sup>16</sup> = 65,536. […] The Maniac's large base permits a considerable increase in the speed of floating point arithmetic. Although such a large base implies the possibility of as many as 15 lead zeros, the large word size of 48 bits guarantees adequate significance. […]</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=MANIAC+II&amp;rft.place=Los+Alamos%2C+NM%2C+USA&amp;rft.pages=14&amp;rft.pub=Los+Alamos+Scientific+Laboratory+of+the+University+of+California&amp;rft.date=1957-01-30&amp;rft.aulast=Lazarus&amp;rft.aufirst=Roger+B.&amp;rft_id=http%3A%2F%2Fbitsavers.org%2Fpdf%2Flanl%2FLA-2083_MANIAC_II_Oct56.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text">Torres Quevedo, Leonardo. <a rel="nofollow" class="external text" href="https://quickclick.es/rop/pdf/publico/1914/1914_tomoI_2043_01.pdf">Automática: Complemento de la Teoría de las Máquinas, (pdf)</a>, pp. 575–583, Revista de Obras Públicas, 19 November 1914.</span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text">Ronald T. Kneusel. <i><a rel="nofollow" class="external text" href="https://books.google.com/books?id=eq4ZDgAAQBAJ&amp;dq=leonardo+torres+quevedo++electromechanical+machine+essays&amp;pg=PA84">Numbers and Computers</a>,</i> Springer, pp. 84–85, 2017. <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3319505084" title="Special:BookSources/978-3319505084">978-3319505084</a></span>
</li>
<li id="cite_note-FOOTNOTERandell19826,_11–13-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-FOOTNOTERandell19826,_11–13_18-0">^</a></b></span> <span class="reference-text"><a href="#CITEREFRandell1982">Randell 1982</a>, pp.&#160;6, 11–13.</span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text">Randell, Brian. <a rel="nofollow" class="external text" href="https://dl.acm.org/doi/pdf/10.5555/1074100.1074334">Digital Computers, History of Origins, (pdf)</a>, p. 545, Digital Computers: Origins, Encyclopedia of Computer Science, January 2003.</span>
</li>
<li id="cite_note-Rojas_1997-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-Rojas_1997_20-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFRojas1997" class="citation journal cs1"><a href="https://en.wikipedia.org/wiki/Ra%C3%BAl_Rojas" title="Raúl Rojas">Rojas, Raúl</a> (April–June 1997). <a rel="nofollow" class="external text" href="http://ed-thelen.org/comp-hist/Zuse_Z1_and_Z3.pdf">"Konrad Zuse's Legacy: The Architecture of the Z1 and Z3"</a> <span class="cs1-format">(PDF)</span>. <i><a href="https://en.wikipedia.org/wiki/IEEE_Annals_of_the_History_of_Computing" title="IEEE Annals of the History of Computing">IEEE Annals of the History of Computing</a></i>. <b>19</b> (2): 5–16. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F85.586067">10.1109/85.586067</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20220703082408/http://ed-thelen.org/comp-hist/Zuse_Z1_and_Z3.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2022-07-03<span class="reference-accessdate">. Retrieved <span class="nowrap">2022-07-03</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Annals+of+the+History+of+Computing&amp;rft.atitle=Konrad+Zuse%27s+Legacy%3A+The+Architecture+of+the+Z1+and+Z3&amp;rft.volume=19&amp;rft.issue=2&amp;rft.pages=5-16&amp;rft.date=1997-04%2F1997-06&amp;rft_id=info%3Adoi%2F10.1109%2F85.586067&amp;rft.aulast=Rojas&amp;rft.aufirst=Ra%C3%BAl&amp;rft_id=http%3A%2F%2Fed-thelen.org%2Fcomp-hist%2FZuse_Z1_and_Z3.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (12 pages)</span>
</li>
<li id="cite_note-Rojas_2014-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-Rojas_2014_21-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFRojas2014" class="citation arxiv cs1"><a href="https://en.wikipedia.org/wiki/Ra%C3%BAl_Rojas" title="Raúl Rojas">Rojas, Raúl</a> (2014-06-07). "The Z1: Architecture and Algorithms of Konrad Zuse's First Computer". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/1406.1886">1406.1886</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.AR">cs.AR</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=The+Z1%3A+Architecture+and+Algorithms+of+Konrad+Zuse%27s+First+Computer&amp;rft.date=2014-06-07&amp;rft_id=info%3Aarxiv%2F1406.1886&amp;rft.aulast=Rojas&amp;rft.aufirst=Ra%C3%BAl&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_1997_JVNL-22"><span class="mw-cite-backlink">^ <a href="#cite_ref-Kahan_1997_JVNL_22-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Kahan_1997_JVNL_22-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan1997" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (1997-07-15). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/SIAMjvnl.pdf">"The Baleful Effect of Computer Languages and Benchmarks upon Applied Mathematics, Physics and Chemistry. John von Neumann Lecture"</a> <span class="cs1-format">(PDF)</span>. p.&#160;3. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20080905103125/http://www.cs.berkeley.edu/~wkahan/SIAMjvnl.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2008-09-05.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Baleful+Effect+of+Computer+Languages+and+Benchmarks+upon+Applied+Mathematics%2C+Physics+and+Chemistry.+John+von+Neumann+Lecture&amp;rft.pages=3&amp;rft.date=1997-07-15&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2FSIAMjvnl.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Randell_1982_2-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-Randell_1982_2_23-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFRandell1982" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/Brian_Randell" title="Brian Randell">Randell, Brian</a>, ed. (1982) [1973]. <i>The Origins of Digital Computers: Selected Papers</i> (3rd&#160;ed.). Berlin; New York: <a href="https://en.wikipedia.org/wiki/Springer-Verlag" class="mw-redirect" title="Springer-Verlag">Springer-Verlag</a>. p.&#160;244. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-11319-5" title="Special:BookSources/978-3-540-11319-5"><bdi>978-3-540-11319-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Origins+of+Digital+Computers%3A+Selected+Papers&amp;rft.place=Berlin%3B+New+York&amp;rft.pages=244&amp;rft.edition=3rd&amp;rft.pub=Springer-Verlag&amp;rft.date=1982&amp;rft.isbn=978-3-540-11319-5&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Severance_1998-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-Severance_1998_24-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSeverance1998" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/Charles_Severance_(computer_scientist)" title="Charles Severance (computer scientist)">Severance, Charles</a> (1998-02-20). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/ieee754status/754story.html">"An Interview with the Old Man of Floating-Point"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=An+Interview+with+the+Old+Man+of+Floating-Point&amp;rft.date=1998-02-20&amp;rft.aulast=Severance&amp;rft.aufirst=Charles&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2Fieee754status%2F754story.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-C99-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-C99_25-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation book cs1"><i>ISO/IEC 9899:1999 - Programming languages - C</i>. Iso.org. §F.2, note 307. <q><span class="cs1-kern-left"></span>"Extended" is IEC 60559's double-extended data format. Extended refers to both the common 80-bit and quadruple 128-bit IEC 60559 formats.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=ISO%2FIEC+9899%3A1999+-+Programming+languages+-+C&amp;rft.pages=%C2%A7F.2%2C+note+307&amp;rft.pub=Iso.org&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-MSVC-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-MSVC_26-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://learn.microsoft.com/en-us/cpp/build/ieee-floating-point-representation">"IEEE Floating-Point Representation"</a>. 2021-08-03.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE+Floating-Point+Representation&amp;rft.date=2021-08-03&amp;rft_id=https%3A%2F%2Flearn.microsoft.com%2Fen-us%2Fcpp%2Fbuild%2Fieee-floating-point-representation&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-GCC-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-GCC_27-0">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://gcc.gnu.org/onlinedocs/gcc/i386-and-x86-64-Options.html">Using the GNU Compiler Collection, i386 and x86-64 Options</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20150116065447/http://gcc.gnu.org/onlinedocs/gcc/i386-and-x86-64-Options.html">Archived</a> 2015-01-16 at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>.</span>
</li>
<li id="cite_note-float_128-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-float_128_28-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://stackoverflow.com/questions/13516476">"long double (GCC specific) and __float128"</a>. <i>StackOverflow</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=StackOverflow&amp;rft.atitle=long+double+%28GCC+specific%29+and+&#95;_float128&amp;rft_id=https%3A%2F%2Fstackoverflow.com%2Fquestions%2F13516476&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-ARM_2013_AArch64-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-ARM_2013_AArch64_29-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://infocenter.arm.com/help/topic/com.arm.doc.ihi0055b/IHI0055B_aapcs64.pdf">"Procedure Call Standard for the ARM 64-bit Architecture (AArch64)"</a> <span class="cs1-format">(PDF)</span>. 2013-05-22. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20130731181404/http://infocenter.arm.com/help/topic/com.arm.doc.ihi0055b/IHI0055B_aapcs64.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2013-07-31<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-09-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Procedure+Call+Standard+for+the+ARM+64-bit+Architecture+%28AArch64%29&amp;rft.date=2013-05-22&amp;rft_id=http%3A%2F%2Finfocenter.arm.com%2Fhelp%2Ftopic%2Fcom.arm.doc.ihi0055b%2FIHI0055B_aapcs64.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-ARM_2013_Compiler-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-ARM_2013_Compiler_30-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://infocenter.arm.com/help/topic/com.arm.doc.dui0491i/DUI0491I_arm_compiler_reference.pdf">"ARM Compiler toolchain Compiler Reference, Version 5.03"</a> <span class="cs1-format">(PDF)</span>. 2013. Section 6.3 <i>Basic data types</i>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20150627210618/http://infocenter.arm.com/help/topic/com.arm.doc.dui0491i/DUI0491I_arm_compiler_reference.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2015-06-27<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-11-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=ARM+Compiler+toolchain+Compiler+Reference%2C+Version+5.03&amp;rft.pages=Section+6.3+%27%27Basic+data+types%27%27&amp;rft.date=2013&amp;rft_id=http%3A%2F%2Finfocenter.arm.com%2Fhelp%2Ftopic%2Fcom.arm.doc.dui0491i%2FDUI0491I_arm_compiler_reference.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_2004-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-Kahan_2004_31-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan2004" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (2004-11-20). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/Qdrtcs.pdf">"On the Cost of Floating-Point Computation Without Extra-Precise Arithmetic"</a> <span class="cs1-format">(PDF)</span>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20060525111157/http://www.cs.berkeley.edu/~wkahan/Qdrtcs.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2006-05-25<span class="reference-accessdate">. Retrieved <span class="nowrap">2012-02-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=On+the+Cost+of+Floating-Point+Computation+Without+Extra-Precise+Arithmetic&amp;rft.date=2004-11-20&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2FQdrtcs.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-OpenEXR-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-OpenEXR_32-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20130508221152/http://www.openexr.com/about.html">"openEXR"</a>. openEXR. Archived from <a rel="nofollow" class="external text" href="http://www.openexr.com/about.html">the original</a> on 2013-05-08<span class="reference-accessdate">. Retrieved <span class="nowrap">2012-04-25</span></span>. <q>Since the IEEE-754 floating-point specification does not define a 16-bit format, ILM created the "half" format. Half values have 1 sign bit, 5 exponent bits, and 10 mantissa bits.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=openEXR&amp;rft.pub=openEXR&amp;rft_id=http%3A%2F%2Fwww.openexr.com%2Fabout.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-OpenEXR-half-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-OpenEXR-half_33-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://openexr.com/en/latest/TechnicalIntroduction.html#the-half-data-type">"Technical Introduction to OpenEXR – The half Data Type"</a>. openEXR<span class="reference-accessdate">. Retrieved <span class="nowrap">2024-04-16</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Technical+Introduction+to+OpenEXR+%E2%80%93+The+half+Data+Type&amp;rft.pub=openEXR&amp;rft_id=https%3A%2F%2Fopenexr.com%2Fen%2Flatest%2FTechnicalIntroduction.html%23the-half-data-type&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-IEEE-754_Analysis-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-IEEE-754_Analysis_34-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://christophervickery.com/IEEE-754/">"IEEE-754 Analysis"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2024-08-29</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE-754+Analysis&amp;rft_id=https%3A%2F%2Fchristophervickery.com%2FIEEE-754%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Borland_1994_MBF-35"><span class="mw-cite-backlink">^ <a href="#cite_ref-Borland_1994_MBF_35-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Borland_1994_MBF_35-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBorland_staff1998" class="citation web cs1">Borland staff (1998-07-02) [1994-03-10]. <a rel="nofollow" class="external text" href="https://community.embarcadero.com/index.php/article/technical-articles/162-programming/14799-converting-between-microsoft-binary-and-ieee-forma">"Converting between Microsoft Binary and IEEE formats"</a>. <i>Technical Information Database</i> (TI1431C.txt). <a href="https://en.wikipedia.org/wiki/Embarcadero_USA" class="mw-redirect" title="Embarcadero USA">Embarcadero USA</a> / <a href="https://en.wikipedia.org/wiki/Inprise" class="mw-redirect" title="Inprise">Inprise</a> (originally: <a href="https://en.wikipedia.org/wiki/Borland" title="Borland">Borland</a>). ID 1400. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20190220230417/https://community.embarcadero.com/index.php/article/technical-articles/162-programming/14799-converting-between-microsoft-binary-and-ieee-forma">Archived</a> from the original on 2019-02-20<span class="reference-accessdate">. Retrieved <span class="nowrap">2016-05-30</span></span>. <q>[…] _fmsbintoieee(float *src4, float *dest4) […] MS Binary Format […] byte order =&gt; m3 | m2 | m1 | exponent […] m1 is <a href="https://en.wikipedia.org/wiki/Most_significant_byte" class="mw-redirect" title="Most significant byte">most significant byte</a> =&gt; sbbb|bbbb […] m3 is the <a href="https://en.wikipedia.org/wiki/Least_significant_byte" class="mw-redirect" title="Least significant byte">least significant byte</a> […] m = mantissa byte […] s = sign bit […] b = bit […] MBF is bias 128 and IEEE is bias 127. […] MBF places the <a href="https://en.wikipedia.org/wiki/Decimal_point" class="mw-redirect" title="Decimal point">decimal point</a> before the <a href="https://en.wikipedia.org/wiki/Assumed_bit" class="mw-redirect" title="Assumed bit">assumed bit</a>, while IEEE places the decimal point after the assumed bit. […] ieee_exp = msbin[3] - 2; /* actually, msbin[3]-1-128+127 */ […] _dmsbintoieee(double *src8, double *dest8) […] MS Binary Format […] byte order =&gt;  m7 | m6 | m5 | m4 | m3 | m2 | m1 | exponent […] m1 is most significant byte =&gt; smmm|mmmm […] m7 is the least significant byte […] MBF is bias 128 and IEEE is bias 1023. […] MBF places the decimal point before the assumed bit, while IEEE places the decimal point after the assumed bit. […] ieee_exp = msbin[7] - 128 - 1 + 1023; […]</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Technical+Information+Database&amp;rft.atitle=Converting+between+Microsoft+Binary+and+IEEE+formats&amp;rft.date=1998-07-02&amp;rft.au=Borland+staff&amp;rft_id=https%3A%2F%2Fcommunity.embarcadero.com%2Findex.php%2Farticle%2Ftechnical-articles%2F162-programming%2F14799-converting-between-microsoft-binary-and-ieee-forma&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Steil_2008_6502-36"><span class="mw-cite-backlink">^ <a href="#cite_ref-Steil_2008_6502_36-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Steil_2008_6502_36-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSteil2008" class="citation web cs1">Steil, Michael (2008-10-20). <a rel="nofollow" class="external text" href="http://www.pagetable.com/?p=46">"Create your own Version of Microsoft BASIC for 6502"</a>. pagetable.com. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20160530092603/http://www.pagetable.com/?p=46">Archived</a> from the original on 2016-05-30<span class="reference-accessdate">. Retrieved <span class="nowrap">2016-05-30</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Create+your+own+Version+of+Microsoft+BASIC+for+6502&amp;rft.pub=pagetable.com&amp;rft.date=2008-10-20&amp;rft.aulast=Steil&amp;rft.aufirst=Michael&amp;rft_id=http%3A%2F%2Fwww.pagetable.com%2F%3Fp%3D46&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Microsoft_2006_KB35826-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-Microsoft_2006_KB35826_37-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.betaarchive.com/wiki/index.php/Microsoft_KB_Archive/35826#IEEE_vs._Microsoft_Binary_Format.3B_Rounding_Issues_.28Complete.29">"IEEE vs. Microsoft Binary Format; Rounding Issues (Complete)"</a>. <i>Microsoft Support</i>. <a href="https://en.wikipedia.org/wiki/Microsoft" title="Microsoft">Microsoft</a>. 2006-11-21. Article ID KB35826, Q35826. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20200828130651/https://www.betaarchive.com/wiki/index.php/Microsoft_KB_Archive/35826">Archived</a> from the original on 2020-08-28<span class="reference-accessdate">. Retrieved <span class="nowrap">2010-02-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Microsoft+Support&amp;rft.atitle=IEEE+vs.+Microsoft+Binary+Format%3B+Rounding+Issues+%28Complete%29&amp;rft.date=2006-11-21&amp;rft_id=https%3A%2F%2Fwww.betaarchive.com%2Fwiki%2Findex.php%2FMicrosoft_KB_Archive%2F35826%23IEEE_vs._Microsoft_Binary_Format.3B_Rounding_Issues_.28Complete.29&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kharya_2020-38"><span class="mw-cite-backlink">^ <a href="#cite_ref-Kharya_2020_38-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Kharya_2020_38-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKharya2020" class="citation web cs1">Kharya, Paresh (2020-05-14). <a rel="nofollow" class="external text" href="https://blogs.nvidia.com/blog/2020/05/14/tensorfloat-32-precision-format/">"TensorFloat-32 in the A100 GPU Accelerates AI Training, HPC up to 20x"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2020-05-16</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=TensorFloat-32+in+the+A100+GPU+Accelerates+AI+Training%2C+HPC+up+to+20x&amp;rft.date=2020-05-14&amp;rft.aulast=Kharya&amp;rft.aufirst=Paresh&amp;rft_id=https%3A%2F%2Fblogs.nvidia.com%2Fblog%2F2020%2F05%2F14%2Ftensorfloat-32-precision-format%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-NVIDIA_Hopper-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-NVIDIA_Hopper_39-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/">"NVIDIA Hopper Architecture In-Depth"</a>. 2022-03-22.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=NVIDIA+Hopper+Architecture+In-Depth&amp;rft.date=2022-03-22&amp;rft_id=https%3A%2F%2Fdeveloper.nvidia.com%2Fblog%2Fnvidia-hopper-architecture-in-depth%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Micikevicius_2022-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-Micikevicius_2022_40-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFMicikeviciusStosicBurgessCornea2022" class="citation arxiv cs1">Micikevicius, Paulius; Stosic, Dusan; Burgess, Neil; Cornea, Marius; Dubey, Pradeep; Grisenthwaite, Richard; Ha, Sangwon; Heinecke, Alexander; Judd, Patrick; Kamalu, John; Mellempudi, Naveen; Oberman, Stuart; Shoeybi, Mohammad; Siu, Michael; Wu, Hao (2022-09-12). "FP8 Formats for Deep Learning". <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2209.05433">2209.05433</a></span> [<a rel="nofollow" class="external text" href="https://arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=FP8+Formats+for+Deep+Learning&amp;rft.date=2022-09-12&amp;rft_id=info%3Aarxiv%2F2209.05433&amp;rft.aulast=Micikevicius&amp;rft.aufirst=Paulius&amp;rft.au=Stosic%2C+Dusan&amp;rft.au=Burgess%2C+Neil&amp;rft.au=Cornea%2C+Marius&amp;rft.au=Dubey%2C+Pradeep&amp;rft.au=Grisenthwaite%2C+Richard&amp;rft.au=Ha%2C+Sangwon&amp;rft.au=Heinecke%2C+Alexander&amp;rft.au=Judd%2C+Patrick&amp;rft.au=Kamalu%2C+John&amp;rft.au=Mellempudi%2C+Naveen&amp;rft.au=Oberman%2C+Stuart&amp;rft.au=Shoeybi%2C+Mohammad&amp;rft.au=Siu%2C+Michael&amp;rft.au=Wu%2C+Hao&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_2006_Mindless-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-Kahan_2006_Mindless_42-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan2006" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (2006-01-11). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/Mindless.pdf">"How Futile are Mindless Assessments of Roundoff in Floating-Point Computation?"</a> <span class="cs1-format">(PDF)</span>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20041221020332/http://www.cs.berkeley.edu/~wkahan/Mindless.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2004-12-21.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=How+Futile+are+Mindless+Assessments+of+Roundoff+in+Floating-Point+Computation%3F&amp;rft.date=2006-01-11&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2FMindless.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Gay_1990-43"><span class="mw-cite-backlink">^ <a href="#cite_ref-Gay_1990_43-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Gay_1990_43-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFGay1990" class="citation techreport cs1">Gay, David M. (1990). <i>Correctly Rounded Binary-Decimal and Decimal-Binary Conversions</i> (Technical report). NUMERICAL ANALYSIS MANUSCRIPT 90-10, AT&amp;T BELL LABORATORIES. <a href="https://en.wikipedia.org/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.4049">10.1.1.31.4049</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=Correctly+Rounded+Binary-Decimal+and+Decimal-Binary+Conversions&amp;rft.pub=NUMERICAL+ANALYSIS+MANUSCRIPT+90-10%2C+AT%26T+BELL+LABORATORIES&amp;rft.date=1990&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.31.4049%23id-name%3DCiteSeerX&amp;rft.aulast=Gay&amp;rft.aufirst=David+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (<a rel="nofollow" class="external text" href="http://www.netlib.org/fp/dtoa.c">dtoa.c in netlab</a>)</span>
</li>
<li id="cite_note-Loitsch_2010-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-Loitsch_2010_44-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLoitsch2010" class="citation conference cs1">Loitsch, Florian (2010). <a rel="nofollow" class="external text" href="https://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf">"Printing floating-point numbers quickly and accurately with integers"</a> <span class="cs1-format">(PDF)</span>. <i>Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation</i>. PLDI '10: ACM SIGPLAN Conference on Programming Language Design and Implementation. pp.&#160;233–243. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F1806596.1806623">10.1145/1806596.1806623</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-45030019-3" title="Special:BookSources/978-1-45030019-3"><bdi>978-1-45030019-3</bdi></a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:910409">910409</a>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20140729005717/http://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2014-07-29.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Printing+floating-point+numbers+quickly+and+accurately+with+integers&amp;rft.btitle=Proceedings+of+the+31st+ACM+SIGPLAN+Conference+on+Programming+Language+Design+and+Implementation&amp;rft.pages=233-243&amp;rft.date=2010&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A910409%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1145%2F1806596.1806623&amp;rft.isbn=978-1-45030019-3&amp;rft.aulast=Loitsch&amp;rft.aufirst=Florian&amp;rft_id=https%3A%2F%2Fwww.cs.tufts.edu%2F~nr%2Fcs257%2Farchive%2Fflorian-loitsch%2Fprintf.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-mazong-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-mazong_45-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/dotnet/coreclr/pull/14646">"Added Grisu3 algorithm support for double.ToString(). by mazong1123 · Pull Request #14646 · dotnet/coreclr"</a>. <i>GitHub</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=Added+Grisu3+algorithm+support+for+double.ToString%28%29.+by+mazong1123+%C2%B7+Pull+Request+%2314646+%C2%B7+dotnet%2Fcoreclr&amp;rft_id=https%3A%2F%2Fgithub.com%2Fdotnet%2Fcoreclr%2Fpull%2F14646&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Adams_2018-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-Adams_2018_46-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFAdams2018" class="citation journal cs1">Adams, Ulf (2018-12-02). <a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F3296979.3192369">"Ryū: fast float-to-string conversion"</a>. <i>ACM SIGPLAN Notices</i>. <b>53</b> (4): 270–282. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F3296979.3192369">10.1145/3296979.3192369</a></span>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:218472153">218472153</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+SIGPLAN+Notices&amp;rft.atitle=Ry%C5%AB%3A+fast+float-to-string+conversion&amp;rft.volume=53&amp;rft.issue=4&amp;rft.pages=270-282&amp;rft.date=2018-12-02&amp;rft_id=info%3Adoi%2F10.1145%2F3296979.3192369&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A218472153%23id-name%3DS2CID&amp;rft.aulast=Adams&amp;rft.aufirst=Ulf&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1145%252F3296979.3192369&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Giulietti-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-Giulietti_47-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFGiulietti" class="citation web cs1">Giulietti, Rafaello. <a rel="nofollow" class="external text" href="https://drive.google.com/file/d/1IEeATSVnEE6TkrHlCYNY2GjaraBjOT4f">"The Schubfach way to render doubles"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Schubfach+way+to+render+doubles&amp;rft.aulast=Giulietti&amp;rft.aufirst=Rafaello&amp;rft_id=https%3A%2F%2Fdrive.google.com%2Ffile%2Fd%2F1IEeATSVnEE6TkrHlCYNY2GjaraBjOT4f&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-abolz-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-abolz_48-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/abolz/Drachennest">"abolz/Drachennest"</a>. <i><a href="https://en.wikipedia.org/wiki/GitHub" title="GitHub">GitHub</a></i>. 2022-11-10.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=abolz%2FDrachennest&amp;rft.date=2022-11-10&amp;rft_id=https%3A%2F%2Fgithub.com%2Fabolz%2FDrachennest&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-double_conversion_2020-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-double_conversion_2020_49-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/google/double-conversion">"google/double-conversion"</a>. <i><a href="https://en.wikipedia.org/wiki/GitHub" title="GitHub">GitHub</a></i>. 2020-09-21.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=google%2Fdouble-conversion&amp;rft.date=2020-09-21&amp;rft_id=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdouble-conversion&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Lemire_2021-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-Lemire_2021_50-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFLemire2021" class="citation journal cs1">Lemire, Daniel (2021-03-22). "Number parsing at a gigabyte per second". <i>Software: Practice and Experience</i>. <b>51</b> (8): 1700–1727. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/2101.11408">2101.11408</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1002%2Fspe.2984">10.1002/spe.2984</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:231718830">231718830</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Software%3A+Practice+and+Experience&amp;rft.atitle=Number+parsing+at+a+gigabyte+per+second&amp;rft.volume=51&amp;rft.issue=8&amp;rft.pages=1700-1727&amp;rft.date=2021-03-22&amp;rft_id=info%3Aarxiv%2F2101.11408&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A231718830%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1002%2Fspe.2984&amp;rft.aulast=Lemire&amp;rft.aufirst=Daniel&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Goldberg_1991-51"><span class="mw-cite-backlink">^ <a href="#cite_ref-Goldberg_1991_51-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Goldberg_1991_51-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Goldberg_1991_51-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFGoldberg1991" class="citation journal cs1"><a href="/w/index.php?title=David_Goldberg_(PARC)&amp;action=edit&amp;redlink=1" class="new" title="David Goldberg (PARC) (page does not exist)">Goldberg, David</a> (March 1991). <a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F103162.103163">"What Every Computer Scientist Should Know About Floating-Point Arithmetic"</a>. <i><a href="https://en.wikipedia.org/wiki/ACM_Computing_Surveys" title="ACM Computing Surveys">ACM Computing Surveys</a></i>. <b>23</b> (1): 5–48. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F103162.103163">10.1145/103162.103163</a></span>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:222008826">222008826</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+Computing+Surveys&amp;rft.atitle=What+Every+Computer+Scientist+Should+Know+About+Floating-Point+Arithmetic&amp;rft.volume=23&amp;rft.issue=1&amp;rft.pages=5-48&amp;rft.date=1991-03&amp;rft_id=info%3Adoi%2F10.1145%2F103162.103163&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A222008826%23id-name%3DS2CID&amp;rft.aulast=Goldberg&amp;rft.aufirst=David&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1145%252F103162.103163&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (With the addendum "Differences Among IEEE 754 Implementations": <a rel="nofollow" class="external autonumber" href="https://web.archive.org/web/20171011072644/http://www.cse.msu.edu/~cse320/Documents/FloatingPoint.pdf">[2]</a>, <a rel="nofollow" class="external autonumber" href="https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html">[3]</a>)</span>
</li>
<li id="cite_note-Patterson-Hennessy_2014-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-Patterson-Hennessy_2014_52-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFPattersonHennessy2014" class="citation book cs1">Patterson, David A.; Hennessy, John L. (2014). <i>Computer Organization and Design, The Hardware/Software Interface</i>. The Morgan Kaufmann series in computer architecture and design (5th&#160;ed.). Waltham, Massachusetts, USA: Elsevier. p.&#160;793. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-9-86605267-5" title="Special:BookSources/978-9-86605267-5"><bdi>978-9-86605267-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computer+Organization+and+Design%2C+The+Hardware%2FSoftware+Interface&amp;rft.place=Waltham%2C+Massachusetts%2C+USA&amp;rft.series=The+Morgan+Kaufmann+series+in+computer+architecture+and+design&amp;rft.pages=793&amp;rft.edition=5th&amp;rft.pub=Elsevier&amp;rft.date=2014&amp;rft.isbn=978-9-86605267-5&amp;rft.aulast=Patterson&amp;rft.aufirst=David+A.&amp;rft.au=Hennessy%2C+John+L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Sierra_1962-53"><span class="mw-cite-backlink">^ <a href="#cite_ref-Sierra_1962_53-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Sierra_1962_53-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1041539562">.mw-parser-output .citation{word-wrap:break-word}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}</style><span class="citation patent" id="harv"><a rel="nofollow" class="external text" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US3037701A">US&#32;patent 3037701A</a>,&#32;Huberto M Sierra,&#32;"Floating decimal point arithmetic control means for calculator",&#32;issued 1962-06-05</span><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=3037701A&amp;rft.cc=US&amp;rft.title=Floating+decimal+point+arithmetic+control+means+for+calculator&amp;rft.inventor=Huberto+M+Sierra&amp;rft.date=1962-06-05"><span style="display: none;">&#160;</span></span></span>
</li>
<li id="cite_note-Kahan_1997_Status-55"><span class="mw-cite-backlink">^ <a href="#cite_ref-Kahan_1997_Status_55-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Kahan_1997_Status_55-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan1997" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (1997-10-01). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF">"Lecture Notes on the Status of IEEE Standard 754 for Binary Floating-Point Arithmetic"</a> <span class="cs1-format">(PDF)</span>. p.&#160;9. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20020622093102/http://www.cs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2002-06-22.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lecture+Notes+on+the+Status+of+IEEE+Standard+754+for+Binary+Floating-Point+Arithmetic&amp;rft.pages=9&amp;rft.date=1997-10-01&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2Fieee754status%2FIEEE754.PDF&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Intel-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-Intel_56-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation book cs1"><a rel="nofollow" class="external text" href="http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html">"D.3.2.1"</a>. <i>Intel 64 and IA-32 Architectures Software Developers' Manuals</i>. Vol.&#160;1.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=D.3.2.1&amp;rft.btitle=Intel+64+and+IA-32+Architectures+Software+Developers%27+Manuals&amp;rft_id=http%3A%2F%2Fwww.intel.com%2Fcontent%2Fwww%2Fus%2Fen%2Fprocessors%2Farchitectures-software-developer-manuals.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Harris-58"><span class="mw-cite-backlink"><b><a href="#cite_ref-Harris_58-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFHarris2010" class="citation journal cs1">Harris, Richard (October 2010). <a rel="nofollow" class="external text" href="http://accu.org/index.php/journals/1702">"You're Going To Have To Think!"</a>. <i><a href="https://en.wikipedia.org/wiki/Overload_(magazine)" title="Overload (magazine)">Overload</a></i> (99): 5–10. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" class="mw-redirect" title="ISSN (identifier)">ISSN</a>&#160;<a rel="nofollow" class="external text" href="https://search.worldcat.org/issn/1354-3172">1354-3172</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2011-09-24</span></span>. <q>Far more worrying is cancellation error which can yield catastrophic loss of precision.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Overload&amp;rft.atitle=You%27re+Going+To+Have+To+Think%21&amp;rft.issue=99&amp;rft.pages=5-10&amp;rft.date=2010-10&amp;rft.issn=1354-3172&amp;rft.aulast=Harris&amp;rft.aufirst=Richard&amp;rft_id=http%3A%2F%2Faccu.org%2Findex.php%2Fjournals%2F1702&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> <a rel="nofollow" class="external autonumber" href="http://accu.org/var/uploads/journals/overload99.pdf">[4]</a></span>
</li>
<li id="cite_note-Barker-59"><span class="mw-cite-backlink"><b><a href="#cite_ref-Barker_59-0">^</a></b></span> <span class="reference-text">Christopher Barker: <a rel="nofollow" class="external text" href="https://www.python.org/dev/peps/pep-0485/"><i>PEP 485 -- A Function for testing approximate equality</i></a></span>
</li>
<li id="cite_note-GAO_report_IMTEC_92-26-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-GAO_report_IMTEC_92-26_60-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.gao.gov/products/IMTEC-92-26">"Patriot missile defense, Software problem led to system failure at Dharhan, Saudi Arabia"</a>. <a href="https://en.wikipedia.org/wiki/US_Government_Accounting_Office" class="mw-redirect" title="US Government Accounting Office">US Government Accounting Office</a>. GAO report IMTEC 92-26.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Patriot+missile+defense%2C+Software+problem+led+to+system+failure+at+Dharhan%2C+Saudi+Arabia&amp;rft.pub=US+Government+Accounting+Office&amp;rft_id=http%3A%2F%2Fwww.gao.gov%2Fproducts%2FIMTEC-92-26&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-RalstonReilly2003-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-RalstonReilly2003_61-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFWilkinson2003" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/James_Hardy_Wilkinson" class="mw-redirect" title="James Hardy Wilkinson">Wilkinson, James Hardy</a> (2003-09-08). "Error Analysis". In Ralston, Anthony; Reilly, Edwin D.; Hemmendinger, David (eds.). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=OLRwQgAACAAJ"><i>Encyclopedia of Computer Science</i></a>. <a href="https://en.wikipedia.org/wiki/Wiley_(publisher)" title="Wiley (publisher)">Wiley</a>. pp.&#160;669–674. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-470-86412-8" title="Special:BookSources/978-0-470-86412-8"><bdi>978-0-470-86412-8</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">2013-05-14</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Error+Analysis&amp;rft.btitle=Encyclopedia+of+Computer+Science&amp;rft.pages=669-674&amp;rft.pub=Wiley&amp;rft.date=2003-09-08&amp;rft.isbn=978-0-470-86412-8&amp;rft.aulast=Wilkinson&amp;rft.aufirst=James+Hardy&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DOLRwQgAACAAJ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Einarsson_2005-62"><span class="mw-cite-backlink"><b><a href="#cite_ref-Einarsson_2005_62-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFEinarsson2005" class="citation book cs1">Einarsson, Bo (2005). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=sh4orx_qB_QC&amp;pg=PA50"><i>Accuracy and reliability in scientific computing</i></a>. <a href="https://en.wikipedia.org/wiki/Society_for_Industrial_and_Applied_Mathematics" title="Society for Industrial and Applied Mathematics">Society for Industrial and Applied Mathematics</a> (SIAM). pp.&#160;50–. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-89871-815-7" title="Special:BookSources/978-0-89871-815-7"><bdi>978-0-89871-815-7</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">2013-05-14</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Accuracy+and+reliability+in+scientific+computing&amp;rft.pages=50-&amp;rft.pub=Society+for+Industrial+and+Applied+Mathematics+%28SIAM%29&amp;rft.date=2005&amp;rft.isbn=978-0-89871-815-7&amp;rft.aulast=Einarsson&amp;rft.aufirst=Bo&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3Dsh4orx_qB_QC%26pg%3DPA50&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Higham_2002-63"><span class="mw-cite-backlink">^ <a href="#cite_ref-Higham_2002_63-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Higham_2002_63-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Higham_2002_63-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Higham_2002_63-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFHigham2002" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/Nicholas_Higham" title="Nicholas Higham">Higham, Nicholas John</a> (2002). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=epilvM5MMxwC"><i>Accuracy and Stability of Numerical Algorithms</i></a> (2nd&#160;ed.). <a href="https://en.wikipedia.org/wiki/Society_for_Industrial_and_Applied_Mathematics" title="Society for Industrial and Applied Mathematics">Society for Industrial and Applied Mathematics</a> (SIAM). pp.&#160;27–28, 110–123, 493. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-89871-521-7" title="Special:BookSources/978-0-89871-521-7"><bdi>978-0-89871-521-7</bdi></a>. 0-89871-355-2.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Accuracy+and+Stability+of+Numerical+Algorithms&amp;rft.pages=27-28%2C+110-123%2C+493&amp;rft.edition=2nd&amp;rft.pub=Society+for+Industrial+and+Applied+Mathematics+%28SIAM%29&amp;rft.date=2002&amp;rft.isbn=978-0-89871-521-7&amp;rft.aulast=Higham&amp;rft.aufirst=Nicholas+John&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DepilvM5MMxwC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-OliveiraStewart_2006-64"><span class="mw-cite-backlink"><b><a href="#cite_ref-OliveiraStewart_2006_64-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFOliveiraStewart2006" class="citation book cs1">Oliveira, Suely; Stewart, David E. (2006-09-07). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=E6a8oZOS8noC&amp;pg=PA10"><i>Writing Scientific Software: A Guide to Good Style</i></a>. <a href="https://en.wikipedia.org/wiki/Cambridge_University_Press" title="Cambridge University Press">Cambridge University Press</a>. pp.&#160;10–. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-139-45862-7" title="Special:BookSources/978-1-139-45862-7"><bdi>978-1-139-45862-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Writing+Scientific+Software%3A+A+Guide+to+Good+Style&amp;rft.pages=10-&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2006-09-07&amp;rft.isbn=978-1-139-45862-7&amp;rft.aulast=Oliveira&amp;rft.aufirst=Suely&amp;rft.au=Stewart%2C+David+E.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DE6a8oZOS8noC%26pg%3DPA10&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_2005_ARITH17-65"><span class="mw-cite-backlink">^ <a href="#cite_ref-Kahan_2005_ARITH17_65-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Kahan_2005_ARITH17_65-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan2005" class="citation conference cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (2005-07-15). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/ARITH_17.pdf"><i>Floating-Point Arithmetic Besieged by "Business Decisions"</i></a> <span class="cs1-format">(PDF)</span>. IEEE-sponsored <a href="https://en.wikipedia.org/wiki/ARITH_17" class="mw-redirect" title="ARITH 17">ARITH 17</a>, Symposium on Computer Arithmetic (Keynote Address). pp.&#160;6, 18. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20060317103619/http://www.cs.berkeley.edu/~wkahan/ARITH_17.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2006-03-17<span class="reference-accessdate">. Retrieved <span class="nowrap">2013-05-23</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Floating-Point+Arithmetic+Besieged+by+%22Business+Decisions%22&amp;rft.pages=6%2C+18&amp;rft.date=2005-07-15&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2FARITH_17.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (NB. Kahan estimates that the incidence of excessively inaccurate results near singularities is reduced by a factor of approx. 1/2000 using the 11 extra bits of precision of <a href="https://en.wikipedia.org/wiki/Extended_precision" title="Extended precision">double extended</a>.)</span>
</li>
<li id="cite_note-Kahan_2011_Debug-66"><span class="mw-cite-backlink"><b><a href="#cite_ref-Kahan_2011_Debug_66-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan2011" class="citation conference cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (2011-08-03). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/Boulder.pdf"><i>Desperately Needed Remedies for the Undebuggability of Large Floating-Point Computations in Science and Engineering</i></a> <span class="cs1-format">(PDF)</span>. IFIP/SIAM/NIST Working Conference on Uncertainty Quantification in Scientific Computing, Boulder, CO. p.&#160;33. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20130620140729/http://www.eecs.berkeley.edu/~wkahan/Boulder.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2013-06-20.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Desperately+Needed+Remedies+for+the+Undebuggability+of+Large+Floating-Point+Computations+in+Science+and+Engineering&amp;rft.pages=33&amp;rft.date=2011-08-03&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2FBoulder.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_2001_JavaHurt-69"><span class="mw-cite-backlink"><b><a href="#cite_ref-Kahan_2001_JavaHurt_69-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahanDarcy2001" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a>; Darcy, Joseph (2001) [1998-03-01]. <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/JAVAhurt.pdf">"How Java's floating-point hurts everyone everywhere"</a> <span class="cs1-format">(PDF)</span>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20000816043653/http://www.cs.berkeley.edu/~wkahan/JAVAhurt.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2000-08-16<span class="reference-accessdate">. Retrieved <span class="nowrap">2003-09-05</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=How+Java%27s+floating-point+hurts+everyone+everywhere&amp;rft.date=2001&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft.au=Darcy%2C+Joseph&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2FJAVAhurt.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_2000_Marketing-71"><span class="mw-cite-backlink">^ <a href="#cite_ref-Kahan_2000_Marketing_71-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Kahan_2000_Marketing_71-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Kahan_2000_Marketing_71-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-Kahan_2000_Marketing_71-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan2000" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (2000-08-27). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/MktgMath.pdf">"Marketing versus Mathematics"</a> <span class="cs1-format">(PDF)</span>. pp.&#160;15, 35, 47. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20030815150333/http://www.cs.berkeley.edu/~wkahan/MktgMath.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2003-08-15.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Marketing+versus+Mathematics&amp;rft.pages=15%2C+35%2C+47&amp;rft.date=2000-08-27&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2FMktgMath.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_1981_WhyIEEE-72"><span class="mw-cite-backlink"><b><a href="#cite_ref-Kahan_1981_WhyIEEE_72-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan1981" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (1981-02-12). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/ieee754status/why-ieee.pdf">"Why do we need a floating-point arithmetic standard?"</a> <span class="cs1-format">(PDF)</span>. p.&#160;26. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20041204070746/http://www.cs.berkeley.edu/~wkahan/ieee754status/why-ieee.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2004-12-04.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Why+do+we+need+a+floating-point+arithmetic+standard%3F&amp;rft.pages=26&amp;rft.date=1981-02-12&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2Fieee754status%2Fwhy-ieee.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_2001_LN-73"><span class="mw-cite-backlink"><b><a href="#cite_ref-Kahan_2001_LN_73-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahan2001" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a> (2001-06-04). Bindel, David (ed.). <a rel="nofollow" class="external text" href="http://www.cims.nyu.edu/~dbindel/class/cs279/notes-06-04.pdf">"Lecture notes of System Support for Scientific Computation"</a> <span class="cs1-format">(PDF)</span>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20130517181356/http://www.cims.nyu.edu/~dbindel/class/cs279/notes-06-04.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2013-05-17.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lecture+notes+of+System+Support+for+Scientific+Computation&amp;rft.date=2001-06-04&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft_id=http%3A%2F%2Fwww.cims.nyu.edu%2F~dbindel%2Fclass%2Fcs279%2Fnotes-06-04.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Speleotrove_2012-74"><span class="mw-cite-backlink"><b><a href="#cite_ref-Speleotrove_2012_74-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://speleotrove.com/decimal/">"General Decimal Arithmetic"</a>. Speleotrove.com<span class="reference-accessdate">. Retrieved <span class="nowrap">2012-04-25</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=General+Decimal+Arithmetic&amp;rft.pub=Speleotrove.com&amp;rft_id=https%3A%2F%2Fspeleotrove.com%2Fdecimal%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Christiansen_Perl-75"><span class="mw-cite-backlink"><b><a href="#cite_ref-Christiansen_Perl_75-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFChristiansenTorkington2006" class="citation web cs1">Christiansen, Tom; Torkington, Nathan; et&#160;al. (2006). <a rel="nofollow" class="external text" href="https://perldoc.perl.org/5.8.8/perlfaq4#Why-is-int()-broken?">"perlfaq4 / Why is int() broken?"</a>. perldoc.perl.org<span class="reference-accessdate">. Retrieved <span class="nowrap">2011-01-11</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=perlfaq4+%2F+Why+is+int%28%29+broken%3F&amp;rft.pub=perldoc.perl.org&amp;rft.date=2006&amp;rft.aulast=Christiansen&amp;rft.aufirst=Tom&amp;rft.au=Torkington%2C+Nathan&amp;rft_id=https%3A%2F%2Fperldoc.perl.org%2F5.8.8%2Fperlfaq4%23Why-is-int%28%29-broken%3F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Shewchuk-76"><span class="mw-cite-backlink"><b><a href="#cite_ref-Shewchuk_76-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFShewchuk1997" class="citation journal cs1">Shewchuk, Jonathan Richard (1997). <a rel="nofollow" class="external text" href="https://doi.org/10.1007%2FPL00009321">"Adaptive Precision Floating-Point Arithmetic and Fast Robust Geometric Predicates"</a>. <i><a href="https://en.wikipedia.org/wiki/Discrete_%26_Computational_Geometry" title="Discrete &amp; Computational Geometry">Discrete &amp; Computational Geometry</a></i>. <b>18</b> (3): 305–363. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1007%2FPL00009321">10.1007/PL00009321</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Discrete+%26+Computational+Geometry&amp;rft.atitle=Adaptive+Precision+Floating-Point+Arithmetic+and+Fast+Robust+Geometric+Predicates&amp;rft.volume=18&amp;rft.issue=3&amp;rft.pages=305-363&amp;rft.date=1997&amp;rft_id=info%3Adoi%2F10.1007%2FPL00009321&amp;rft.aulast=Shewchuk&amp;rft.aufirst=Jonathan+Richard&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1007%252FPL00009321&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Kahan_1997_Cantilever-77"><span class="mw-cite-backlink"><b><a href="#cite_ref-Kahan_1997_Cantilever_77-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKahanIvory1997" class="citation web cs1"><a href="https://en.wikipedia.org/wiki/William_Morton_Kahan" class="mw-redirect" title="William Morton Kahan">Kahan, William Morton</a>; Ivory, Melody Y. (1997-07-03). <a rel="nofollow" class="external text" href="https://people.eecs.berkeley.edu/~wkahan/Cantilever.pdf">"Roundoff Degrades an Idealized Cantilever"</a> <span class="cs1-format">(PDF)</span>. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20031205191038/http://www.cs.berkeley.edu/~wkahan/Cantilever.pdf">Archived</a> <span class="cs1-format">(PDF)</span> from the original on 2003-12-05.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Roundoff+Degrades+an+Idealized+Cantilever&amp;rft.date=1997-07-03&amp;rft.aulast=Kahan&amp;rft.aufirst=William+Morton&amp;rft.au=Ivory%2C+Melody+Y.&amp;rft_id=https%3A%2F%2Fpeople.eecs.berkeley.edu%2F~wkahan%2FCantilever.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Vectorizers-79"><span class="mw-cite-backlink"><b><a href="#cite_ref-Vectorizers_79-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://llvm.org/docs/Vectorizers.html">"Auto-Vectorization in LLVM"</a>. <i>LLVM 13 documentation</i>. <q>We support floating point reduction operations when -ffast-math is used.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=LLVM+13+documentation&amp;rft.atitle=Auto-Vectorization+in+LLVM&amp;rft_id=https%3A%2F%2Fllvm.org%2Fdocs%2FVectorizers.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-FPM-80"><span class="mw-cite-backlink"><b><a href="#cite_ref-FPM_80-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://gcc.gnu.org/wiki/FloatingPointMath">"FloatingPointMath"</a>. <i>GCC Wiki</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GCC+Wiki&amp;rft.atitle=FloatingPointMath&amp;rft_id=https%3A%2F%2Fgcc.gnu.org%2Fwiki%2FFloatingPointMath&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-harmful-81"><span class="mw-cite-backlink"><b><a href="#cite_ref-harmful_81-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55522">"55522 – -funsafe-math-optimizations is unexpectedly harmful, especially w/ -shared"</a>. <i>gcc.gnu.org</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=gcc.gnu.org&amp;rft.atitle=55522+%E2%80%93+-funsafe-math-optimizations+is+unexpectedly+harmful%2C+especially+w%2F+-shared&amp;rft_id=https%3A%2F%2Fgcc.gnu.org%2Fbugzilla%2Fshow_bug.cgi%3Fid%3D55522&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Gen-82"><span class="mw-cite-backlink"><b><a href="#cite_ref-Gen_82-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://gcc.gnu.org/onlinedocs/gfortran/Code-Gen-Options.html">"Code Gen Options (The GNU Fortran Compiler)"</a>. <i>gcc.gnu.org</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=gcc.gnu.org&amp;rft.atitle=Code+Gen+Options+%28The+GNU+Fortran+Compiler%29&amp;rft_id=https%3A%2F%2Fgcc.gnu.org%2Fonlinedocs%2Fgfortran%2FCode-Gen-Options.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-zheevd-83"><span class="mw-cite-backlink"><b><a href="#cite_ref-zheevd_83-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://github.com/Reference-LAPACK/lapack/issues/43">"Bug in zheevd · Issue #43 · Reference-LAPACK/lapack"</a>. <i>GitHub</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GitHub&amp;rft.atitle=Bug+in+zheevd+%C2%B7+Issue+%2343+%C2%B7+Reference-LAPACK%2Flapack&amp;rft_id=https%3A%2F%2Fgithub.com%2FReference-LAPACK%2Flapack%2Fissues%2F43&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
<li id="cite_note-Becker-Darulova-Myreen-Tatlock_2019-84"><span class="mw-cite-backlink"><b><a href="#cite_ref-Becker-Darulova-Myreen-Tatlock_2019_84-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBeckerDarulovaMyreenTatlock2019" class="citation conference cs1">Becker, Heiko; Darulova, Eva; Myreen, Magnus O.; Tatlock, Zachary (2019). <i>Icing: Supporting Fast-Math Style Optimizations in a Verified Compiler</i>. CAV 2019: Computer Aided Verification. Vol.&#160;11562. pp.&#160;155–173. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-030-25543-5_10">10.1007/978-3-030-25543-5_10</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Icing%3A+Supporting+Fast-Math+Style+Optimizations+in+a+Verified+Compiler&amp;rft.pages=155-173&amp;rft.date=2019&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-030-25543-5_10&amp;rft.aulast=Becker&amp;rft.aufirst=Heiko&amp;rft.au=Darulova%2C+Eva&amp;rft.au=Myreen%2C+Magnus+O.&amp;rft.au=Tatlock%2C+Zachary&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></span>
</li>
</ol></div>
<div class="mw-heading mw-heading2"><h2 id="Further_reading">Further reading</h2></span></div>
<ul><li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFWilkinson1963" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/James_Hardy_Wilkinson" class="mw-redirect" title="James Hardy Wilkinson">Wilkinson, James Hardy</a> (1963). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=yFogU9Ot-qsC"><i>Rounding Errors in Algebraic Processes</i></a> (1st&#160;ed.). Englewood Cliffs, New Jersey, USA: <a href="https://en.wikipedia.org/wiki/Prentice-Hall,_Inc." class="mw-redirect" title="Prentice-Hall, Inc.">Prentice-Hall, Inc.</a> <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780486679990" title="Special:BookSources/9780486679990"><bdi>9780486679990</bdi></a>. <a href="https://en.wikipedia.org/wiki/MR_(identifier)" class="mw-redirect" title="MR (identifier)">MR</a>&#160;<a rel="nofollow" class="external text" href="https://mathscinet.ams.org/mathscinet-getitem?mr=0161456">0161456</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Rounding+Errors+in+Algebraic+Processes&amp;rft.place=Englewood+Cliffs%2C+New+Jersey%2C+USA&amp;rft.edition=1st&amp;rft.pub=Prentice-Hall%2C+Inc.&amp;rft.date=1963&amp;rft.isbn=9780486679990&amp;rft_id=https%3A%2F%2Fmathscinet.ams.org%2Fmathscinet-getitem%3Fmr%3D161456%23id-name%3DMR&amp;rft.aulast=Wilkinson&amp;rft.aufirst=James+Hardy&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DyFogU9Ot-qsC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (NB. Classic influential treatises on floating-point arithmetic.)</li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFWilkinson1965" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/James_Hardy_Wilkinson" class="mw-redirect" title="James Hardy Wilkinson">Wilkinson, James Hardy</a> (1965). <a rel="nofollow" class="external text" href="https://books.google.com/books?id=N98IAQAAIAAJ&amp;q=editions:ISBN0198534183"><i>The Algebraic Eigenvalue Problem</i></a>. Monographs on Numerical Analysis (1st&#160;ed.). <a href="https://en.wikipedia.org/wiki/Oxford_University_Press" title="Oxford University Press">Oxford University Press</a> / <a href="https://en.wikipedia.org/wiki/Clarendon_Press" class="mw-redirect" title="Clarendon Press">Clarendon Press</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780198534037" title="Special:BookSources/9780198534037"><bdi>9780198534037</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">2016-02-11</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Algebraic+Eigenvalue+Problem&amp;rft.series=Monographs+on+Numerical+Analysis&amp;rft.edition=1st&amp;rft.pub=Oxford+University+Press+%2F+Clarendon+Press&amp;rft.date=1965&amp;rft.isbn=9780198534037&amp;rft.aulast=Wilkinson&amp;rft.aufirst=James+Hardy&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DN98IAQAAIAAJ%26q%3Deditions%3A&#73;SBN0198534183&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSterbenz1974" class="citation book cs1">Sterbenz, Pat H. (1974). <i>Floating-Point Computation</i>. Prentice-Hall Series in Automatic Computation (1st&#160;ed.). Englewood Cliffs, New Jersey, USA: <a href="https://en.wikipedia.org/wiki/Prentice_Hall" title="Prentice Hall">Prentice Hall</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-13-322495-5" title="Special:BookSources/978-0-13-322495-5"><bdi>978-0-13-322495-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Floating-Point+Computation&amp;rft.place=Englewood+Cliffs%2C+New+Jersey%2C+USA&amp;rft.series=Prentice-Hall+Series+in+Automatic+Computation&amp;rft.edition=1st&amp;rft.pub=Prentice+Hall&amp;rft.date=1974&amp;rft.isbn=978-0-13-322495-5&amp;rft.aulast=Sterbenz&amp;rft.aufirst=Pat+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFGolubvan_Loan1986" class="citation book cs1">Golub, Gene F.; van Loan, Charles F. (1986). <i>Matrix Computations</i> (3rd&#160;ed.). <a href="https://en.wikipedia.org/wiki/Johns_Hopkins_University_Press" title="Johns Hopkins University Press">Johns Hopkins University Press</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-8018-5413-2" title="Special:BookSources/978-0-8018-5413-2"><bdi>978-0-8018-5413-2</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Matrix+Computations&amp;rft.edition=3rd&amp;rft.pub=Johns+Hopkins+University+Press&amp;rft.date=1986&amp;rft.isbn=978-0-8018-5413-2&amp;rft.aulast=Golub&amp;rft.aufirst=Gene+F.&amp;rft.au=van+Loan%2C+Charles+F.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFPressTeukolskyVetterlingFlannery2007" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/William_Henry_Press" class="mw-redirect" title="William Henry Press">Press, William Henry</a>; <a href="https://en.wikipedia.org/wiki/Saul_A._Teukolsky" class="mw-redirect" title="Saul A. Teukolsky">Teukolsky, Saul A.</a>; <a href="https://en.wikipedia.org/wiki/William_T._Vetterling" class="mw-redirect" title="William T. Vetterling">Vetterling, William T.</a>; <a href="https://en.wikipedia.org/wiki/Brian_P._Flannery" title="Brian P. Flannery">Flannery, Brian P.</a> (2007) [1986]. <a href="https://en.wikipedia.org/wiki/Numerical_Recipes" title="Numerical Recipes"><i>Numerical Recipes - The Art of Scientific Computing</i></a> (3rd&#160;ed.). <a href="https://en.wikipedia.org/wiki/Cambridge_University_Press" title="Cambridge University Press">Cambridge University Press</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-88407-5" title="Special:BookSources/978-0-521-88407-5"><bdi>978-0-521-88407-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Numerical+Recipes+-+The+Art+of+Scientific+Computing&amp;rft.edition=3rd&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2007&amp;rft.isbn=978-0-521-88407-5&amp;rft.aulast=Press&amp;rft.aufirst=William+Henry&amp;rft.au=Teukolsky%2C+Saul+A.&amp;rft.au=Vetterling%2C+William+T.&amp;rft.au=Flannery%2C+Brian+P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (NB. Edition with source code CD-ROM.)</li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFKnuth1997" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/Donald_Ervin_Knuth" class="mw-redirect" title="Donald Ervin Knuth">Knuth, Donald Ervin</a> (1997). "Section 4.2: Floating-Point Arithmetic". <i><a href="https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming" title="The Art of Computer Programming">The Art of Computer Programming</a></i>, Vol. 2: <i>Seminumerical Algorithms</i> (3rd&#160;ed.). <a href="https://en.wikipedia.org/wiki/Addison-Wesley" title="Addison-Wesley">Addison-Wesley</a>. pp.&#160;214–264. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-201-89684-8" title="Special:BookSources/978-0-201-89684-8"><bdi>978-0-201-89684-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Section+4.2%3A+Floating-Point+Arithmetic&amp;rft.btitle=The+Art+of+Computer+Programming%2C+Vol.+2%3A+Seminumerical+Algorithms&amp;rft.pages=214-264&amp;rft.edition=3rd&amp;rft.pub=Addison-Wesley&amp;rft.date=1997&amp;rft.isbn=978-0-201-89684-8&amp;rft.aulast=Knuth&amp;rft.aufirst=Donald+Ervin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFBlaauwBrooks,_Jr.1997" class="citation book cs1"><a href="https://en.wikipedia.org/wiki/Gerrit_Anne_Blaauw" class="mw-redirect" title="Gerrit Anne Blaauw">Blaauw, Gerrit Anne</a>; <a href="https://en.wikipedia.org/wiki/Frederick_Phillips_Brooks,_Jr." class="mw-redirect" title="Frederick Phillips Brooks, Jr.">Brooks, Jr., Frederick Phillips</a> (1997). <i>Computer Architecture: Concepts and Evolution</i> (1st&#160;ed.). <a href="https://en.wikipedia.org/wiki/Addison-Wesley" title="Addison-Wesley">Addison-Wesley</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-201-10557-8" title="Special:BookSources/0-201-10557-8"><bdi>0-201-10557-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computer+Architecture%3A+Concepts+and+Evolution&amp;rft.edition=1st&amp;rft.pub=Addison-Wesley&amp;rft.date=1997&amp;rft.isbn=0-201-10557-8&amp;rft.aulast=Blaauw&amp;rft.aufirst=Gerrit+Anne&amp;rft.au=Brooks%2C+Jr.%2C+Frederick+Phillips&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (1213 pages) (NB. This is a single-volume edition. This work was also available in a two-volume version.)</li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFSavard2018" class="citation cs2">Savard, John J. G. (2018) [2005], <a rel="nofollow" class="external text" href="http://www.quadibloc.com/comp/cp0201.htm">"Floating-Point Formats"</a>, <i>quadibloc</i>, <a rel="nofollow" class="external text" href="https://web.archive.org/web/20180703001709/http://www.quadibloc.com/comp/cp0201.htm">archived</a> from the original on 2018-07-03<span class="reference-accessdate">, retrieved <span class="nowrap">2018-07-16</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=quadibloc&amp;rft.atitle=Floating-Point+Formats&amp;rft.date=2018&amp;rft.aulast=Savard&amp;rft.aufirst=John+J.+G.&amp;rft_id=http%3A%2F%2Fwww.quadibloc.com%2Fcomp%2Fcp0201.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFMullerBruniede_DinechinJeannerod2018" class="citation book cs1">Muller, Jean-Michel; Brunie, Nicolas; de Dinechin, Florent; Jeannerod, Claude-Pierre; Joldes, Mioara; Lefèvre, Vincent; Melquiond, Guillaume; <a href="https://en.wikipedia.org/wiki/Nathalie_Revol" title="Nathalie Revol">Revol, Nathalie</a>; Torres, Serge (2018) [2010]. <a rel="nofollow" class="external text" href="https://books.google.com/books?id=h3ZZDwAAQBAJ"><i>Handbook of Floating-Point Arithmetic</i></a> (2nd&#160;ed.). <a href="https://en.wikipedia.org/wiki/Birkh%C3%A4user" title="Birkhäuser">Birkhäuser</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-319-76526-6">10.1007/978-3-319-76526-6</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-319-76525-9" title="Special:BookSources/978-3-319-76525-9"><bdi>978-3-319-76525-9</bdi></a>. <a href="https://en.wikipedia.org/wiki/LCCN_(identifier)" class="mw-redirect" title="LCCN (identifier)">LCCN</a>&#160;<a rel="nofollow" class="external text" href="https://lccn.loc.gov/2018935254">2018935254</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Handbook+of+Floating-Point+Arithmetic&amp;rft.edition=2nd&amp;rft.pub=Birkh%C3%A4user&amp;rft.date=2018&amp;rft_id=info%3Alccn%2F2018935254&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-76526-6&amp;rft.isbn=978-3-319-76525-9&amp;rft.aulast=Muller&amp;rft.aufirst=Jean-Michel&amp;rft.au=Brunie%2C+Nicolas&amp;rft.au=de+Dinechin%2C+Florent&amp;rft.au=Jeannerod%2C+Claude-Pierre&amp;rft.au=Joldes%2C+Mioara&amp;rft.au=Lef%C3%A8vre%2C+Vincent&amp;rft.au=Melquiond%2C+Guillaume&amp;rft.au=Revol%2C+Nathalie&amp;rft.au=Torres%2C+Serge&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3Dh3ZZDwAAQBAJ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></li></ul>
<div class="mw-heading mw-heading2"><h2 id="External_links">External links</h2></span></div>
<ul><li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.mrob.com/pub/math/floatformats.html">"Survey of Floating-Point Formats"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Survey+of+Floating-Point+Formats&amp;rft_id=http%3A%2F%2Fwww.mrob.com%2Fpub%2Fmath%2Ffloatformats.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (NB. This page gives a very brief summary of floating-point formats that have been used over the years.)</li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFMonniaux2008" class="citation journal cs1">Monniaux, David (May 2008). <a rel="nofollow" class="external text" href="https://hal.science/hal-00128124/en/">"The pitfalls of verifying floating-point computations"</a>. <i>ACM Transactions on Programming Languages and Systems</i>. <b>30</b> (3). <a href="https://en.wikipedia.org/wiki/Association_for_Computing_Machinery" title="Association for Computing Machinery">Association for Computing Machinery</a> (ACM) Transactions on programming languages and systems (TOPLAS): 1–41. <a href="https://en.wikipedia.org/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://arxiv.org/abs/cs/0701192">cs/0701192</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F1353445.1353446">10.1145/1353445.1353446</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:218578808">218578808</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+Transactions+on+Programming+Languages+and+Systems&amp;rft.atitle=The+pitfalls+of+verifying+floating-point+computations&amp;rft.volume=30&amp;rft.issue=3&amp;rft.pages=1-41&amp;rft.date=2008-05&amp;rft_id=info%3Aarxiv%2Fcs%2F0701192&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A218578808%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1145%2F1353445.1353446&amp;rft.aulast=Monniaux&amp;rft.aufirst=David&amp;rft_id=https%3A%2F%2Fhal.science%2Fhal-00128124%2Fen%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span> (NB. A compendium of non-intuitive behaviors of floating point on popular architectures, with implications for program verification and testing.)</li>
<li><a rel="nofollow" class="external text" href="https://opencores.org/">OpenCores</a>. (NB. This website contains open source floating-point IP cores for the implementation of floating-point operators in FPGA or ASIC devices. The project <i>double_fpu</i> contains verilog source code of a double-precision floating-point unit. The project <i>fpuvhdl</i> contains vhdl source code of a single-precision floating-point unit.)</li>
<li><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1238218222"><cite id="CITEREFFleegal2004" class="citation web cs1">Fleegal, Eric (2004). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20170706020455/http://msdn.microsoft.com/en-us/library/aa289157(v=vs.71).aspx">"Microsoft Visual C++ Floating-Point Optimization"</a>. <a href="https://en.wikipedia.org/wiki/Microsoft_Developer_Network" title="Microsoft Developer Network">Microsoft Developer Network</a>. Archived from <a rel="nofollow" class="external text" href="http://msdn.microsoft.com/en-us/library/aa289157(v=vs.71).aspx">the original</a> on 2017-07-06.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Microsoft+Visual+C%2B%2B+Floating-Point+Optimization&amp;rft.pub=Microsoft+Developer+Network&amp;rft.date=2004&amp;rft.aulast=Fleegal&amp;rft.aufirst=Eric&amp;rft_id=http%3A%2F%2Fmsdn.microsoft.com%2Fen-us%2Flibrary%2Faa289157%28v%3Dvs.71%29.aspx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFloating-point+arithmetic" class="Z3988"></span></li></ul>
<div class="navbox-styles"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><style data-mw-deduplicate="TemplateStyles:r1236075235">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}</style></div><div role="navigation" class="navbox" aria-labelledby="Data_types" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1239400231"><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="https://en.wikipedia.org/wiki/Template:Data_types" title="Template:Data types"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="https://en.wikipedia.org/wiki/Template_talk:Data_types" title="Template talk:Data types"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a href="https://en.wikipedia.org/wiki/Special:EditPage/Template:Data_types" title="Special:EditPage/Template:Data types"><abbr title="Edit this template">e</abbr></a></li></ul></div><div id="Data_types" style="font-size:114%;margin:0 4em"><a href="https://en.wikipedia.org/wiki/Data_type" title="Data type">Data types</a></div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Units_of_information" title="Units of information">Uninterpreted</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Bit" title="Bit">Bit</a></li>
<li><a href="https://en.wikipedia.org/wiki/Byte" title="Byte">Byte</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ternary_numeral_system" title="Ternary numeral system">Trit</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ternary_numeral_system#Tryte" title="Ternary numeral system">Tryte</a></li>
<li><a href="https://en.wikipedia.org/wiki/Word_(computer_architecture)" title="Word (computer architecture)">Word</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bit_array" title="Bit array">Bit array</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Numeric</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic" title="Arbitrary-precision arithmetic">Arbitrary-precision or bignum</a></li>
<li><a href="https://en.wikipedia.org/wiki/Complex_data_type" title="Complex data type">Complex</a></li>
<li><a href="https://en.wikipedia.org/wiki/Decimal_data_type" title="Decimal data type">Decimal</a></li>
<li><a href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic" title="Fixed-point arithmetic">Fixed point</a></li>
<li><a class="mw-selflink selflink">Floating point</a>
<ul><li>Reduced precision
<ul><li><a href="https://en.wikipedia.org/wiki/Minifloat" title="Minifloat">Minifloat</a></li>
<li><a href="https://en.wikipedia.org/wiki/Half-precision_floating-point_format" title="Half-precision floating-point format">Half precision</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bfloat16_floating-point_format" title="Bfloat16 floating-point format">bfloat16</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" title="Single-precision floating-point format">Single precision</a></li>
<li><a href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format" title="Double-precision floating-point format">Double precision</a></li>
<li><a href="https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format" title="Quadruple-precision floating-point format">Quadruple precision</a></li>
<li><a href="https://en.wikipedia.org/wiki/Octuple-precision_floating-point_format" title="Octuple-precision floating-point format">Octuple precision</a></li>
<li><a href="https://en.wikipedia.org/wiki/Extended_precision" title="Extended precision">Extended precision</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Long_double" title="Long double">Long double</a></li></ul></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Integer_(computer_science)" title="Integer (computer science)">Integer</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Signedness" title="Signedness">signedness</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Interval_arithmetic#Implementations" title="Interval arithmetic">Interval</a></li>
<li><a href="https://en.wikipedia.org/wiki/Rational_data_type" title="Rational data type">Rational</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Pointer_(computer_programming)" title="Pointer (computer programming)">Pointer</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Memory_address" title="Memory address">Address</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Physical_address" title="Physical address">physical</a></li>
<li><a href="https://en.wikipedia.org/wiki/Virtual_address_space" title="Virtual address space">virtual</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Reference_(computer_science)" title="Reference (computer science)">Reference</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Plain_text" title="Plain text">Text</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Character_(computing)" title="Character (computing)">Character</a></li>
<li><a href="https://en.wikipedia.org/wiki/String_(computer_science)" title="String (computer science)">String</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Null-terminated_string" title="Null-terminated string">null-terminated</a></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="https://en.wikipedia.org/wiki/Composite_data_type" title="Composite data type">Composite</a></th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Algebraic_data_type" title="Algebraic data type">Algebraic data type</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type" title="Generalized algebraic data type">generalized</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Array_data_type" class="mw-redirect" title="Array data type">Array</a></li>
<li><a href="https://en.wikipedia.org/wiki/Associative_array" title="Associative array">Associative array</a></li>
<li><a href="https://en.wikipedia.org/wiki/Class_(computer_programming)" title="Class (computer programming)">Class</a></li>
<li><a href="https://en.wikipedia.org/wiki/Dependent_type" title="Dependent type">Dependent</a></li>
<li><a href="https://en.wikipedia.org/wiki/Intuitionistic_type_theory#Equality_type" title="Intuitionistic type theory">Equality</a></li>
<li><a href="https://en.wikipedia.org/wiki/Inductive_type" title="Inductive type">Inductive</a></li>
<li><a href="https://en.wikipedia.org/wiki/Intersection_type" title="Intersection type">Intersection</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_(abstract_data_type)" title="List (abstract data type)">List</a></li>
<li><a href="https://en.wikipedia.org/wiki/Object_(computer_science)" title="Object (computer science)">Object</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Metaobject" title="Metaobject">metaobject</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Option_type" title="Option type">Option type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Product_type" title="Product type">Product</a></li>
<li><a href="https://en.wikipedia.org/wiki/Record_(computer_science)" title="Record (computer science)">Record or Struct</a></li>
<li><a href="https://en.wikipedia.org/wiki/Refinement_type" title="Refinement type">Refinement</a></li>
<li><a href="https://en.wikipedia.org/wiki/Set_(abstract_data_type)" title="Set (abstract data type)">Set</a></li>
<li><a href="https://en.wikipedia.org/wiki/Union_type" title="Union type">Union</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Tagged_union" title="Tagged union">tagged</a></li></ul></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Other</th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Boolean_data_type" title="Boolean data type">Boolean</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bottom_type" title="Bottom type">Bottom type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Container_(abstract_data_type)" title="Container (abstract data type)">Collection</a></li>
<li><a href="https://en.wikipedia.org/wiki/Enumerated_type" title="Enumerated type">Enumerated type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Exception_handling" title="Exception handling">Exception</a></li>
<li><a href="https://en.wikipedia.org/wiki/Function_type" title="Function type">Function type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Opaque_data_type" title="Opaque data type">Opaque data type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Recursive_data_type" title="Recursive data type">Recursive data type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semaphore_(programming)" title="Semaphore (programming)">Semaphore</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stream_(computing)" title="Stream (computing)">Stream</a></li>
<li><a href="https://en.wikipedia.org/wiki/Strongly_typed_identifier" title="Strongly typed identifier">Strongly typed identifier</a></li>
<li><a href="https://en.wikipedia.org/wiki/Top_type" title="Top type">Top type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Type_class" title="Type class">Type class</a></li>
<li><a href="https://en.wikipedia.org/wiki/Empty_type" title="Empty type">Empty type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Unit_type" title="Unit type">Unit type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Void_type" title="Void type">Void</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Related<br />topics</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="https://en.wikipedia.org/wiki/Abstract_data_type" title="Abstract data type">Abstract data type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Boxing_(computer_science)" class="mw-redirect" title="Boxing (computer science)">Boxing</a></li>
<li><a href="https://en.wikipedia.org/wiki/Data_structure" title="Data structure">Data structure</a></li>
<li><a href="https://en.wikipedia.org/wiki/Generic_programming" title="Generic programming">Generic</a></li>
<li><a href="https://en.wikipedia.org/wiki/Kind_(type_theory)" title="Kind (type theory)">Kind</a>
<ul><li><a href="https://en.wikipedia.org/wiki/Metaclass" title="Metaclass">metaclass</a></li></ul></li>
<li><a href="https://en.wikipedia.org/wiki/Parametric_polymorphism" title="Parametric polymorphism">Parametric polymorphism</a></li>
<li><a href="https://en.wikipedia.org/wiki/Primitive_data_type" title="Primitive data type">Primitive data type</a></li>
<li><a href="https://en.wikipedia.org/wiki/Interface_(object-oriented_programming)" title="Interface (object-oriented programming)">Interface</a></li>
<li><a href="https://en.wikipedia.org/wiki/Subtyping" title="Subtyping">Subtyping</a></li>
<li><a href="https://en.wikipedia.org/wiki/Type_constructor" title="Type constructor">Type constructor</a></li>
<li><a href="https://en.wikipedia.org/wiki/Type_conversion" title="Type conversion">Type conversion</a></li>
<li><a href="https://en.wikipedia.org/wiki/Type_system" title="Type system">Type system</a></li>
<li><a href="https://en.wikipedia.org/wiki/Type_theory" title="Type theory">Type theory</a></li>
<li><a href="https://en.wikipedia.org/wiki/Variable_(computer_science)" title="Variable (computer science)">Variable</a></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw‐api‐ext.codfw.main‐74b55b79b8‐c2c99
Cached time: 20240920153654
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 1.335 seconds
Real time usage: 1.713 seconds
Preprocessor visited node count: 11312/1000000
Post‐expand include size: 208027/2097152 bytes
Template argument size: 11100/2097152 bytes
Highest expansion depth: 18/100
Expensive parser function count: 11/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 304225/5000000 bytes
Lua time usage: 0.741/10.000 seconds
Lua memory usage: 12342298/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 1368.312      1 -total
 39.72%  543.486      2 Template:Reflist
 13.74%  187.956     21 Template:Cite_book
 12.40%  169.663     38 Template:Cite_web
  6.74%   92.157      1 Template:Floating-point
  6.60%   90.289      1 Template:Sidebar
  5.57%   76.198      1 Template:Short_description
  5.52%   75.493      1 Template:Sfn
  3.71%   50.785      3 Template:Citation_needed
  3.67%   50.198      2 Template:Pagetype
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:11376-0!canonical and timestamp 20240920153654 and revision id 1243001710. Rendering was triggered because: unknown
 -->
</div>